{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook I aim to change the noise input of the generator to a low resolution galaxy image instead\n",
    "\n",
    "By Shooby, started: July 25 <br>\n",
    "last edited: July 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from astropy.convolution import convolve_fft as convolve\n",
    "import astropy.io.fits as pyfits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "Random Seed:  9307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1131f0070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing parameters:\n",
    "\n",
    "dataroot='gals/'\n",
    "device = torch.device(\"cuda:0\") # If GPU then use \"cuda:0\"\n",
    "ngpu = 3 #number of GPUs to use \n",
    "ngf = 64\n",
    "ndf = 64\n",
    "workers = 8 #number of data loading workers\n",
    "batchSize = 64 #input batch size\n",
    "imageSize = 64 #the height / width of the input image to network\n",
    "nz = (imageSize//2)*(imageSize//2) #size of the latent z vector\n",
    "niter = 10 #number of epochs to train for\n",
    "lr = 0.0002 #learning rate, default=0.0002\n",
    "beta1 = 0.5 #beta1 for adam. default=0.5\n",
    "outf='outputs' #folder to output images and model checkpoints\n",
    "print(nz)\n",
    "\n",
    "manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.MNIST(root=dataroot, download=True,\n",
    "                     transform=transforms.Compose([transforms.Resize(imageSize),transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),]))\n",
    "nc=1\n",
    "\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=int(workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shemmati/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/Users/shemmati/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([1, 1, 63, 63])\n",
      "torch.Size([64, 1, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shemmati/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in log10\n",
      "/Users/shemmati/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in log10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c243306d8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "psf = pyfits.getdata('psf_h.fits')\n",
    "psf = np.asarray(psf[20:-20,20:-20],dtype='d')\n",
    "\n",
    "\n",
    "psfh = np.repeat(psf[:,:, np.newaxis], 1, axis=2)\n",
    "psfh = np.repeat(psfh[:,:,:,np.newaxis],1,axis = 3)\n",
    "kernel = torch.Tensor(psfh)\n",
    "kernel = kernel.permute(2,3,0,1)\n",
    "kernel = F.upsample(kernel,scale_factor=0.5,mode='bilinear')\n",
    "kernel =  kernel.float()\n",
    "\n",
    "\n",
    "test_im = pyfits.getdata('gal_cutout.fits')\n",
    "test_im = np.asarray(test_im,dtype=float)\n",
    "data = np.repeat(test_im[:, :, np.newaxis], batchSize, axis=2)\n",
    "data = np.repeat(data[:,:,:,np.newaxis],1,axis = 3)\n",
    "data = torch.Tensor(data)\n",
    "data = data.permute(2,3,0,1)\n",
    "\n",
    "output = F.conv2d(data, kernel,padding=int(((kernel.shape[3])-1)/2))\n",
    "\n",
    "print(data.shape)\n",
    "print(kernel.shape)\n",
    "print(output.shape)\n",
    "\n",
    "convolved = output.data.numpy()\n",
    "im = convolved[1,0,:,:]\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.log10(test_im),origin='lower')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.log10(im),origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "netG = Generator(ngpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "#if netG != '':\n",
    "#    netG.load_state_dict(torch.load(netG))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "#if netD != '':\n",
    "#    netD.load_state_dict(torch.load(netD))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10][0/95] Loss_D: 0.0764 Loss_G: 4.8337 D(x): 0.9669 D(G(z)): 0.0144 / 0.0098\n",
      "[0/10][1/95] Loss_D: 0.1686 Loss_G: 28.4416 D(x): 1.0000 D(G(z)): 0.1500 / 0.0000\n",
      "[0/10][2/95] Loss_D: 0.0927 Loss_G: 32.8316 D(x): 0.9657 D(G(z)): 0.0000 / 0.0000\n",
      "[0/10][3/95] Loss_D: 0.0004 Loss_G: 34.6452 D(x): 0.9996 D(G(z)): 0.0000 / 0.0000\n",
      "[0/10][4/95] Loss_D: 0.1197 Loss_G: 27.5526 D(x): 0.9469 D(G(z)): 0.0000 / 0.0000\n",
      "[0/10][5/95] Loss_D: 0.0000 Loss_G: 15.6698 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/10][6/95] Loss_D: 0.0257 Loss_G: 9.7350 D(x): 1.0000 D(G(z)): 0.0253 / 0.0001\n",
      "[0/10][7/95] Loss_D: 3.3662 Loss_G: 38.1987 D(x): 0.9858 D(G(z)): 0.9625 / 0.0000\n",
      "[0/10][8/95] Loss_D: 6.8510 Loss_G: 29.5129 D(x): 0.0081 D(G(z)): 0.0000 / 0.0000\n",
      "[0/10][9/95] Loss_D: 0.0004 Loss_G: 19.9114 D(x): 0.9996 D(G(z)): 0.0000 / 0.0000\n",
      "[0/10][10/95] Loss_D: 0.0154 Loss_G: 2.7188 D(x): 1.0000 D(G(z)): 0.0152 / 0.0742\n",
      "[0/10][11/95] Loss_D: 10.4263 Loss_G: 17.3656 D(x): 1.0000 D(G(z)): 1.0000 / 0.0000\n",
      "[0/10][12/95] Loss_D: 0.3971 Loss_G: 14.8698 D(x): 0.8163 D(G(z)): 0.0017 / 0.0000\n",
      "[0/10][13/95] Loss_D: 1.4898 Loss_G: 0.0760 D(x): 0.3795 D(G(z)): 0.0024 / 0.9269\n",
      "[0/10][14/95] Loss_D: 5.4172 Loss_G: 12.8643 D(x): 0.9999 D(G(z)): 0.9955 / 0.0000\n",
      "[0/10][15/95] Loss_D: 0.2683 Loss_G: 12.5052 D(x): 0.8843 D(G(z)): 0.0068 / 0.0000\n",
      "[0/10][16/95] Loss_D: 0.6740 Loss_G: 3.6406 D(x): 0.6750 D(G(z)): 0.0074 / 0.0265\n",
      "[0/10][17/95] Loss_D: 4.1097 Loss_G: 20.0119 D(x): 0.8623 D(G(z)): 0.9453 / 0.0000\n",
      "[0/10][18/95] Loss_D: 8.7813 Loss_G: 3.9839 D(x): 0.0071 D(G(z)): 0.0000 / 0.0199\n",
      "[0/10][19/95] Loss_D: 2.7893 Loss_G: 13.0206 D(x): 0.9730 D(G(z)): 0.9352 / 0.0000\n",
      "[0/10][20/95] Loss_D: 3.1612 Loss_G: 1.7430 D(x): 0.1179 D(G(z)): 0.0009 / 0.1802\n",
      "[0/10][21/95] Loss_D: 3.9203 Loss_G: 12.0018 D(x): 0.9731 D(G(z)): 0.9791 / 0.0000\n",
      "[0/10][22/95] Loss_D: 2.3331 Loss_G: 3.4323 D(x): 0.2062 D(G(z)): 0.0010 / 0.0336\n",
      "[0/10][23/95] Loss_D: 1.4923 Loss_G: 10.1109 D(x): 0.9093 D(G(z)): 0.7359 / 0.0001\n",
      "[0/10][24/95] Loss_D: 2.5031 Loss_G: 0.5296 D(x): 0.1586 D(G(z)): 0.0031 / 0.5919\n",
      "[0/10][25/95] Loss_D: 3.0543 Loss_G: 9.9706 D(x): 0.9580 D(G(z)): 0.9489 / 0.0001\n",
      "[0/10][26/95] Loss_D: 2.3319 Loss_G: 2.3933 D(x): 0.1941 D(G(z)): 0.0016 / 0.0957\n",
      "[0/10][27/95] Loss_D: 1.4325 Loss_G: 8.2906 D(x): 0.9388 D(G(z)): 0.7379 / 0.0003\n",
      "[0/10][28/95] Loss_D: 0.7289 Loss_G: 5.0085 D(x): 0.5834 D(G(z)): 0.0072 / 0.0109\n",
      "[0/10][29/95] Loss_D: 0.6635 Loss_G: 1.0130 D(x): 0.6967 D(G(z)): 0.1136 / 0.3738\n",
      "[0/10][30/95] Loss_D: 2.1894 Loss_G: 10.5954 D(x): 0.8157 D(G(z)): 0.8502 / 0.0000\n",
      "[0/10][31/95] Loss_D: 3.4821 Loss_G: 1.7728 D(x): 0.0774 D(G(z)): 0.0004 / 0.1793\n",
      "[0/10][32/95] Loss_D: 1.1574 Loss_G: 5.7016 D(x): 0.9372 D(G(z)): 0.6558 / 0.0047\n",
      "[0/10][33/95] Loss_D: 1.0774 Loss_G: 1.4963 D(x): 0.4636 D(G(z)): 0.0297 / 0.2302\n",
      "[0/10][34/95] Loss_D: 1.2073 Loss_G: 8.1774 D(x): 0.9508 D(G(z)): 0.6684 / 0.0059\n",
      "[0/10][35/95] Loss_D: 2.3085 Loss_G: 1.6173 D(x): 0.2006 D(G(z)): 0.0027 / 0.2080\n",
      "[0/10][36/95] Loss_D: 1.1821 Loss_G: 6.0330 D(x): 0.8971 D(G(z)): 0.6424 / 0.0029\n",
      "[0/10][37/95] Loss_D: 1.0205 Loss_G: 2.0255 D(x): 0.4746 D(G(z)): 0.0196 / 0.1450\n",
      "[0/10][38/95] Loss_D: 0.7853 Loss_G: 6.7943 D(x): 0.9754 D(G(z)): 0.5144 / 0.0023\n",
      "[0/10][39/95] Loss_D: 0.7634 Loss_G: 3.4339 D(x): 0.5788 D(G(z)): 0.0097 / 0.0370\n",
      "[0/10][40/95] Loss_D: 0.6238 Loss_G: 2.1785 D(x): 0.7668 D(G(z)): 0.2300 / 0.1304\n",
      "[0/10][41/95] Loss_D: 0.8264 Loss_G: 9.2252 D(x): 0.9342 D(G(z)): 0.5134 / 0.0002\n",
      "[0/10][42/95] Loss_D: 1.5010 Loss_G: 2.7416 D(x): 0.3307 D(G(z)): 0.0014 / 0.0750\n",
      "[0/10][43/95] Loss_D: 0.8899 Loss_G: 6.7170 D(x): 0.9618 D(G(z)): 0.5359 / 0.0065\n",
      "[0/10][44/95] Loss_D: 1.0077 Loss_G: 1.9631 D(x): 0.4939 D(G(z)): 0.0418 / 0.1646\n",
      "[0/10][45/95] Loss_D: 1.8951 Loss_G: 12.0248 D(x): 0.9964 D(G(z)): 0.8312 / 0.0104\n",
      "[0/10][46/95] Loss_D: 6.1524 Loss_G: 2.6805 D(x): 0.0069 D(G(z)): 0.0003 / 0.0782\n",
      "[0/10][47/95] Loss_D: 1.4356 Loss_G: 5.0441 D(x): 0.7888 D(G(z)): 0.6827 / 0.0074\n",
      "[0/10][48/95] Loss_D: 0.7038 Loss_G: 3.6213 D(x): 0.6500 D(G(z)): 0.1224 / 0.0396\n",
      "[0/10][49/95] Loss_D: 0.6028 Loss_G: 5.6073 D(x): 0.8667 D(G(z)): 0.3358 / 0.0074\n",
      "[0/10][50/95] Loss_D: 0.2391 Loss_G: 5.1174 D(x): 0.8667 D(G(z)): 0.0753 / 0.0092\n",
      "[0/10][51/95] Loss_D: 0.6072 Loss_G: 5.3666 D(x): 0.9605 D(G(z)): 0.1229 / 0.0056\n",
      "[0/10][52/95] Loss_D: 1.2742 Loss_G: 0.5053 D(x): 0.3965 D(G(z)): 0.1409 / 0.6065\n",
      "[0/10][53/95] Loss_D: 2.7997 Loss_G: 13.3142 D(x): 0.9577 D(G(z)): 0.9354 / 0.0000\n",
      "[0/10][54/95] Loss_D: 5.6436 Loss_G: 5.4840 D(x): 0.0166 D(G(z)): 0.0001 / 0.0045\n",
      "[0/10][55/95] Loss_D: 0.3229 Loss_G: 1.4334 D(x): 0.8890 D(G(z)): 0.1419 / 0.2431\n",
      "[0/10][56/95] Loss_D: 2.3258 Loss_G: 9.2400 D(x): 0.9439 D(G(z)): 0.8906 / 0.0001\n",
      "[0/10][57/95] Loss_D: 1.1012 Loss_G: 6.0972 D(x): 0.4151 D(G(z)): 0.0037 / 0.0040\n",
      "[0/10][58/95] Loss_D: 0.2644 Loss_G: 3.0293 D(x): 0.8996 D(G(z)): 0.0868 / 0.0601\n",
      "[0/10][59/95] Loss_D: 1.5680 Loss_G: 4.7368 D(x): 0.5947 D(G(z)): 0.5809 / 0.0094\n",
      "[0/10][60/95] Loss_D: 0.2412 Loss_G: 5.5583 D(x): 0.9030 D(G(z)): 0.1219 / 0.0052\n",
      "[0/10][61/95] Loss_D: 0.9286 Loss_G: 1.1128 D(x): 0.4792 D(G(z)): 0.0420 / 0.3310\n",
      "[0/10][62/95] Loss_D: 1.7289 Loss_G: 6.3772 D(x): 0.7688 D(G(z)): 0.7579 / 0.0018\n",
      "[0/10][63/95] Loss_D: 1.9784 Loss_G: 1.5623 D(x): 0.2272 D(G(z)): 0.0112 / 0.2110\n",
      "[0/10][64/95] Loss_D: 1.6646 Loss_G: 5.8189 D(x): 0.9756 D(G(z)): 0.6103 / 0.0058\n",
      "[0/10][65/95] Loss_D: 0.3113 Loss_G: 5.3429 D(x): 0.7636 D(G(z)): 0.0154 / 0.0050\n",
      "[0/10][66/95] Loss_D: 0.4849 Loss_G: 1.7359 D(x): 0.6881 D(G(z)): 0.0334 / 0.1776\n",
      "[0/10][67/95] Loss_D: 0.9240 Loss_G: 6.1970 D(x): 0.9838 D(G(z)): 0.5937 / 0.0043\n",
      "[0/10][68/95] Loss_D: 1.1298 Loss_G: 2.5487 D(x): 0.4327 D(G(z)): 0.0128 / 0.0815\n",
      "[0/10][69/95] Loss_D: 0.4693 Loss_G: 3.7929 D(x): 0.9580 D(G(z)): 0.3464 / 0.0228\n",
      "[0/10][70/95] Loss_D: 0.5623 Loss_G: 2.5784 D(x): 0.7137 D(G(z)): 0.1190 / 0.0762\n",
      "[0/10][71/95] Loss_D: 0.4462 Loss_G: 4.7864 D(x): 0.9485 D(G(z)): 0.3171 / 0.0084\n",
      "[0/10][72/95] Loss_D: 0.5085 Loss_G: 2.6948 D(x): 0.6753 D(G(z)): 0.0421 / 0.0682\n",
      "[0/10][73/95] Loss_D: 0.5173 Loss_G: 3.0191 D(x): 0.8376 D(G(z)): 0.2583 / 0.0490\n",
      "[0/10][74/95] Loss_D: 0.2391 Loss_G: 5.0347 D(x): 0.9789 D(G(z)): 0.1953 / 0.0066\n",
      "[0/10][75/95] Loss_D: 0.2747 Loss_G: 3.9879 D(x): 0.8125 D(G(z)): 0.0299 / 0.0197\n",
      "[0/10][76/95] Loss_D: 0.4145 Loss_G: 1.5703 D(x): 0.7389 D(G(z)): 0.0550 / 0.2084\n",
      "[0/10][77/95] Loss_D: 0.6291 Loss_G: 6.1890 D(x): 0.9888 D(G(z)): 0.4606 / 0.0021\n",
      "[0/10][78/95] Loss_D: 0.5899 Loss_G: 4.2843 D(x): 0.6130 D(G(z)): 0.0062 / 0.0138\n",
      "[0/10][79/95] Loss_D: 0.2538 Loss_G: 1.8117 D(x): 0.8468 D(G(z)): 0.0569 / 0.1641\n",
      "[0/10][80/95] Loss_D: 0.6803 Loss_G: 6.0709 D(x): 0.9862 D(G(z)): 0.4863 / 0.0023\n",
      "[0/10][81/95] Loss_D: 0.1250 Loss_G: 6.5772 D(x): 0.8964 D(G(z)): 0.0115 / 0.0014\n",
      "[0/10][82/95] Loss_D: 0.1982 Loss_G: 4.6537 D(x): 0.8363 D(G(z)): 0.0071 / 0.0097\n",
      "[0/10][83/95] Loss_D: 0.1069 Loss_G: 3.1041 D(x): 0.9419 D(G(z)): 0.0446 / 0.0456\n",
      "[0/10][84/95] Loss_D: 0.3065 Loss_G: 3.0672 D(x): 0.8806 D(G(z)): 0.1609 / 0.0471\n",
      "[0/10][85/95] Loss_D: 0.1975 Loss_G: 4.7032 D(x): 0.9932 D(G(z)): 0.1727 / 0.0099\n",
      "[0/10][86/95] Loss_D: 1.0170 Loss_G: 1.0923 D(x): 0.4418 D(G(z)): 0.0170 / 0.3372\n",
      "[0/10][87/95] Loss_D: 0.9207 Loss_G: 6.6322 D(x): 0.9993 D(G(z)): 0.6002 / 0.0018\n",
      "[0/10][88/95] Loss_D: 0.5021 Loss_G: 5.7561 D(x): 0.6399 D(G(z)): 0.0047 / 0.0055\n",
      "[0/10][89/95] Loss_D: 0.0332 Loss_G: 4.6041 D(x): 0.9791 D(G(z)): 0.0114 / 0.0131\n",
      "[0/10][90/95] Loss_D: 0.1728 Loss_G: 3.1768 D(x): 0.8612 D(G(z)): 0.0161 / 0.0421\n",
      "[0/10][91/95] Loss_D: 0.1901 Loss_G: 2.9987 D(x): 0.9952 D(G(z)): 0.1628 / 0.0591\n",
      "[0/10][92/95] Loss_D: 0.1930 Loss_G: 3.2583 D(x): 0.8870 D(G(z)): 0.0653 / 0.0397\n",
      "[0/10][93/95] Loss_D: 0.4186 Loss_G: 1.6094 D(x): 0.7302 D(G(z)): 0.0669 / 0.2025\n",
      "[0/10][94/95] Loss_D: 0.4678 Loss_G: 4.1092 D(x): 0.9734 D(G(z)): 0.3548 / 0.0171\n",
      "[1/10][0/95] Loss_D: 0.1467 Loss_G: 4.6662 D(x): 0.8990 D(G(z)): 0.0360 / 0.0105\n",
      "[1/10][1/95] Loss_D: 0.3598 Loss_G: 2.4103 D(x): 0.7525 D(G(z)): 0.0361 / 0.1068\n",
      "[1/10][2/95] Loss_D: 0.4124 Loss_G: 4.6340 D(x): 0.9701 D(G(z)): 0.3021 / 0.0131\n",
      "[1/10][3/95] Loss_D: 0.1439 Loss_G: 5.3860 D(x): 0.9602 D(G(z)): 0.0928 / 0.0071\n",
      "[1/10][4/95] Loss_D: 1.2182 Loss_G: 0.6154 D(x): 0.3675 D(G(z)): 0.0280 / 0.5557\n",
      "[1/10][5/95] Loss_D: 3.2802 Loss_G: 11.0448 D(x): 0.9973 D(G(z)): 0.9551 / 0.0000\n",
      "[1/10][6/95] Loss_D: 2.1067 Loss_G: 6.9627 D(x): 0.1643 D(G(z)): 0.0007 / 0.0011\n",
      "[1/10][7/95] Loss_D: 0.8864 Loss_G: 6.6099 D(x): 0.8130 D(G(z)): 0.4583 / 0.0014\n",
      "[1/10][8/95] Loss_D: 0.5497 Loss_G: 5.1064 D(x): 0.7430 D(G(z)): 0.1252 / 0.0064\n",
      "[1/10][9/95] Loss_D: 0.3106 Loss_G: 6.4504 D(x): 0.9459 D(G(z)): 0.2154 / 0.0017\n",
      "[1/10][10/95] Loss_D: 0.2104 Loss_G: 5.6150 D(x): 0.8941 D(G(z)): 0.0362 / 0.0039\n",
      "[1/10][11/95] Loss_D: 0.0854 Loss_G: 5.1505 D(x): 0.9812 D(G(z)): 0.0608 / 0.0074\n",
      "[1/10][12/95] Loss_D: 1.2670 Loss_G: 0.9993 D(x): 0.5038 D(G(z)): 0.0458 / 0.3784\n",
      "[1/10][13/95] Loss_D: 1.0456 Loss_G: 8.5951 D(x): 0.9808 D(G(z)): 0.6288 / 0.0002\n",
      "[1/10][14/95] Loss_D: 0.1475 Loss_G: 9.1487 D(x): 0.8819 D(G(z)): 0.0025 / 0.0001\n",
      "[1/10][15/95] Loss_D: 1.2571 Loss_G: 0.9379 D(x): 0.4685 D(G(z)): 0.1440 / 0.3942\n",
      "[1/10][16/95] Loss_D: 2.0819 Loss_G: 7.9390 D(x): 0.9012 D(G(z)): 0.8359 / 0.0004\n",
      "[1/10][17/95] Loss_D: 1.9241 Loss_G: 2.7719 D(x): 0.2020 D(G(z)): 0.0016 / 0.0644\n",
      "[1/10][18/95] Loss_D: 0.3135 Loss_G: 1.7509 D(x): 0.9181 D(G(z)): 0.1978 / 0.1779\n",
      "[1/10][19/95] Loss_D: 0.9860 Loss_G: 6.1300 D(x): 0.9825 D(G(z)): 0.6150 / 0.0033\n",
      "[1/10][20/95] Loss_D: 0.8183 Loss_G: 4.1299 D(x): 0.5476 D(G(z)): 0.0133 / 0.0177\n",
      "[1/10][21/95] Loss_D: 0.4442 Loss_G: 2.3420 D(x): 0.8019 D(G(z)): 0.1825 / 0.0978\n",
      "[1/10][22/95] Loss_D: 0.7852 Loss_G: 5.0150 D(x): 0.8027 D(G(z)): 0.4140 / 0.0070\n",
      "[1/10][23/95] Loss_D: 1.7412 Loss_G: 1.2634 D(x): 0.2688 D(G(z)): 0.0857 / 0.2851\n",
      "[1/10][24/95] Loss_D: 1.5926 Loss_G: 8.1022 D(x): 0.9039 D(G(z)): 0.7512 / 0.0004\n",
      "[1/10][25/95] Loss_D: 1.2719 Loss_G: 4.6686 D(x): 0.3398 D(G(z)): 0.0055 / 0.0114\n",
      "[1/10][26/95] Loss_D: 0.6488 Loss_G: 3.5088 D(x): 0.8548 D(G(z)): 0.3362 / 0.0321\n",
      "[1/10][27/95] Loss_D: 1.1930 Loss_G: 8.2030 D(x): 0.9450 D(G(z)): 0.6343 / 0.0003\n",
      "[1/10][28/95] Loss_D: 2.0425 Loss_G: 1.0506 D(x): 0.2214 D(G(z)): 0.0355 / 0.3597\n",
      "[1/10][29/95] Loss_D: 1.4616 Loss_G: 3.1261 D(x): 0.7892 D(G(z)): 0.6670 / 0.0505\n",
      "[1/10][30/95] Loss_D: 1.1972 Loss_G: 2.3604 D(x): 0.5416 D(G(z)): 0.2682 / 0.1161\n",
      "[1/10][31/95] Loss_D: 1.4265 Loss_G: 4.5996 D(x): 0.8599 D(G(z)): 0.6906 / 0.0172\n",
      "[1/10][32/95] Loss_D: 3.2746 Loss_G: 1.0025 D(x): 0.0822 D(G(z)): 0.0205 / 0.4408\n",
      "[1/10][33/95] Loss_D: 2.8547 Loss_G: 1.8520 D(x): 0.5357 D(G(z)): 0.7991 / 0.1726\n",
      "[1/10][34/95] Loss_D: 2.6388 Loss_G: 3.5832 D(x): 0.7280 D(G(z)): 0.8493 / 0.0326\n",
      "[1/10][35/95] Loss_D: 2.4780 Loss_G: 0.3797 D(x): 0.1263 D(G(z)): 0.0913 / 0.7014\n",
      "[1/10][36/95] Loss_D: 2.3388 Loss_G: 1.9306 D(x): 0.9338 D(G(z)): 0.8536 / 0.1624\n",
      "[1/10][37/95] Loss_D: 4.4647 Loss_G: 0.4210 D(x): 0.0296 D(G(z)): 0.4229 / 0.6659\n",
      "[1/10][38/95] Loss_D: 2.6552 Loss_G: 1.1320 D(x): 0.5391 D(G(z)): 0.8078 / 0.3617\n",
      "[1/10][39/95] Loss_D: 1.9652 Loss_G: 0.7795 D(x): 0.4035 D(G(z)): 0.5138 / 0.5098\n",
      "[1/10][40/95] Loss_D: 4.3372 Loss_G: 0.2164 D(x): 0.1429 D(G(z)): 0.8369 / 0.8198\n",
      "[1/10][41/95] Loss_D: 2.5548 Loss_G: 0.9447 D(x): 0.5393 D(G(z)): 0.7430 / 0.4459\n",
      "[1/10][42/95] Loss_D: 2.4421 Loss_G: 2.1799 D(x): 0.5121 D(G(z)): 0.7119 / 0.1418\n",
      "[1/10][43/95] Loss_D: 1.3344 Loss_G: 1.3739 D(x): 0.4793 D(G(z)): 0.1022 / 0.2926\n",
      "[1/10][44/95] Loss_D: 1.4007 Loss_G: 0.6437 D(x): 0.5362 D(G(z)): 0.4527 / 0.5669\n",
      "[1/10][45/95] Loss_D: 1.9702 Loss_G: 3.1075 D(x): 0.8526 D(G(z)): 0.6866 / 0.0599\n",
      "[1/10][46/95] Loss_D: 3.0392 Loss_G: 0.2437 D(x): 0.0720 D(G(z)): 0.0747 / 0.7960\n",
      "[1/10][47/95] Loss_D: 2.6643 Loss_G: 0.7121 D(x): 0.7835 D(G(z)): 0.8705 / 0.5187\n",
      "[1/10][48/95] Loss_D: 1.3858 Loss_G: 2.0059 D(x): 0.6040 D(G(z)): 0.5201 / 0.1575\n",
      "[1/10][49/95] Loss_D: 2.4671 Loss_G: 0.3072 D(x): 0.1337 D(G(z)): 0.2037 / 0.7536\n",
      "[1/10][50/95] Loss_D: 2.3188 Loss_G: 0.7691 D(x): 0.7653 D(G(z)): 0.8233 / 0.4943\n",
      "[1/10][51/95] Loss_D: 1.5402 Loss_G: 1.6522 D(x): 0.5463 D(G(z)): 0.5412 / 0.2261\n",
      "[1/10][52/95] Loss_D: 1.2923 Loss_G: 0.9641 D(x): 0.4017 D(G(z)): 0.1775 / 0.4027\n",
      "[1/10][53/95] Loss_D: 2.0133 Loss_G: 0.4550 D(x): 0.5004 D(G(z)): 0.6782 / 0.6520\n",
      "[1/10][54/95] Loss_D: 1.3183 Loss_G: 1.6116 D(x): 0.6135 D(G(z)): 0.4872 / 0.2226\n",
      "[1/10][55/95] Loss_D: 1.0951 Loss_G: 0.8842 D(x): 0.4767 D(G(z)): 0.2226 / 0.4310\n",
      "[1/10][56/95] Loss_D: 1.0615 Loss_G: 1.2974 D(x): 0.6933 D(G(z)): 0.4444 / 0.3040\n",
      "[1/10][57/95] Loss_D: 1.1885 Loss_G: 1.8563 D(x): 0.7313 D(G(z)): 0.4535 / 0.1747\n",
      "[1/10][58/95] Loss_D: 1.7554 Loss_G: 1.1374 D(x): 0.4717 D(G(z)): 0.5482 / 0.3356\n",
      "[1/10][59/95] Loss_D: 1.7726 Loss_G: 0.3185 D(x): 0.2867 D(G(z)): 0.1998 / 0.7408\n",
      "[1/10][60/95] Loss_D: 1.4168 Loss_G: 3.6217 D(x): 0.8827 D(G(z)): 0.7025 / 0.0280\n",
      "[1/10][61/95] Loss_D: 0.6662 Loss_G: 2.4847 D(x): 0.6527 D(G(z)): 0.1031 / 0.0908\n",
      "[1/10][62/95] Loss_D: 1.3669 Loss_G: 0.5125 D(x): 0.3027 D(G(z)): 0.0793 / 0.6076\n",
      "[1/10][63/95] Loss_D: 1.3612 Loss_G: 2.0073 D(x): 0.9371 D(G(z)): 0.7024 / 0.1710\n",
      "[1/10][64/95] Loss_D: 1.3305 Loss_G: 3.3920 D(x): 0.8434 D(G(z)): 0.4882 / 0.0529\n",
      "[1/10][65/95] Loss_D: 3.2686 Loss_G: 0.5859 D(x): 0.0641 D(G(z)): 0.0596 / 0.5759\n",
      "[1/10][66/95] Loss_D: 1.8587 Loss_G: 0.6515 D(x): 0.6012 D(G(z)): 0.6898 / 0.5362\n",
      "[1/10][67/95] Loss_D: 1.6186 Loss_G: 1.9085 D(x): 0.7149 D(G(z)): 0.6882 / 0.1594\n",
      "[1/10][68/95] Loss_D: 1.1687 Loss_G: 2.3930 D(x): 0.6596 D(G(z)): 0.3148 / 0.0989\n",
      "[1/10][69/95] Loss_D: 1.4536 Loss_G: 0.9968 D(x): 0.3838 D(G(z)): 0.2292 / 0.3959\n",
      "[1/10][70/95] Loss_D: 1.9653 Loss_G: 0.3475 D(x): 0.3039 D(G(z)): 0.3789 / 0.7197\n",
      "[1/10][71/95] Loss_D: 2.1275 Loss_G: 0.6864 D(x): 0.6641 D(G(z)): 0.7743 / 0.5388\n",
      "[1/10][72/95] Loss_D: 2.1009 Loss_G: 1.0223 D(x): 0.4683 D(G(z)): 0.6657 / 0.4121\n",
      "[1/10][73/95] Loss_D: 1.2707 Loss_G: 1.6783 D(x): 0.5462 D(G(z)): 0.3992 / 0.1963\n",
      "[1/10][74/95] Loss_D: 1.6880 Loss_G: 0.5124 D(x): 0.3456 D(G(z)): 0.4148 / 0.6086\n",
      "[1/10][75/95] Loss_D: 1.0590 Loss_G: 1.7882 D(x): 0.7396 D(G(z)): 0.5160 / 0.1733\n",
      "[1/10][76/95] Loss_D: 0.8435 Loss_G: 1.7704 D(x): 0.6561 D(G(z)): 0.3283 / 0.1770\n",
      "[1/10][77/95] Loss_D: 1.7960 Loss_G: 0.4117 D(x): 0.2978 D(G(z)): 0.3233 / 0.6661\n",
      "[1/10][78/95] Loss_D: 1.8049 Loss_G: 1.2659 D(x): 0.7877 D(G(z)): 0.7754 / 0.3015\n",
      "[1/10][79/95] Loss_D: 1.9413 Loss_G: 1.7616 D(x): 0.4157 D(G(z)): 0.3800 / 0.1856\n",
      "[1/10][80/95] Loss_D: 1.8111 Loss_G: 0.5200 D(x): 0.2837 D(G(z)): 0.3465 / 0.6005\n",
      "[1/10][81/95] Loss_D: 1.5685 Loss_G: 1.1776 D(x): 0.6727 D(G(z)): 0.6584 / 0.3124\n",
      "[1/10][82/95] Loss_D: 1.5094 Loss_G: 0.8145 D(x): 0.3626 D(G(z)): 0.2773 / 0.4488\n",
      "[1/10][83/95] Loss_D: 1.0156 Loss_G: 1.8533 D(x): 0.7266 D(G(z)): 0.4779 / 0.1585\n",
      "[1/10][84/95] Loss_D: 0.6762 Loss_G: 1.9930 D(x): 0.6986 D(G(z)): 0.2444 / 0.1403\n",
      "[1/10][85/95] Loss_D: 1.5080 Loss_G: 0.5643 D(x): 0.3151 D(G(z)): 0.1441 / 0.5714\n",
      "[1/10][86/95] Loss_D: 1.4762 Loss_G: 1.1083 D(x): 0.8120 D(G(z)): 0.7080 / 0.3707\n",
      "[1/10][87/95] Loss_D: 1.2132 Loss_G: 2.0555 D(x): 0.6764 D(G(z)): 0.5313 / 0.1380\n",
      "[1/10][88/95] Loss_D: 1.4589 Loss_G: 0.8989 D(x): 0.3347 D(G(z)): 0.2469 / 0.4265\n",
      "[1/10][89/95] Loss_D: 1.3071 Loss_G: 1.2137 D(x): 0.6212 D(G(z)): 0.5119 / 0.3115\n",
      "[1/10][90/95] Loss_D: 1.5210 Loss_G: 0.7732 D(x): 0.4534 D(G(z)): 0.4631 / 0.4731\n",
      "[1/10][91/95] Loss_D: 1.0822 Loss_G: 1.3515 D(x): 0.6651 D(G(z)): 0.4750 / 0.2882\n",
      "[1/10][92/95] Loss_D: 1.5419 Loss_G: 0.6598 D(x): 0.4033 D(G(z)): 0.4153 / 0.5315\n",
      "[1/10][93/95] Loss_D: 1.4453 Loss_G: 1.2857 D(x): 0.6457 D(G(z)): 0.6003 / 0.2789\n",
      "[1/10][94/95] Loss_D: 1.3451 Loss_G: 0.8321 D(x): 0.3194 D(G(z)): 0.1641 / 0.4435\n",
      "[2/10][0/95] Loss_D: 2.0278 Loss_G: 2.0613 D(x): 0.7860 D(G(z)): 0.7304 / 0.1319\n",
      "[2/10][1/95] Loss_D: 1.0808 Loss_G: 1.3942 D(x): 0.4477 D(G(z)): 0.2076 / 0.2596\n",
      "[2/10][2/95] Loss_D: 1.0779 Loss_G: 0.9180 D(x): 0.5916 D(G(z)): 0.3895 / 0.4227\n",
      "[2/10][3/95] Loss_D: 1.4124 Loss_G: 1.1759 D(x): 0.6323 D(G(z)): 0.5870 / 0.3418\n",
      "[2/10][4/95] Loss_D: 0.8896 Loss_G: 1.4783 D(x): 0.5493 D(G(z)): 0.1895 / 0.2385\n",
      "[2/10][5/95] Loss_D: 1.2378 Loss_G: 1.1264 D(x): 0.7329 D(G(z)): 0.5810 / 0.3326\n",
      "[2/10][6/95] Loss_D: 0.8096 Loss_G: 1.5101 D(x): 0.6730 D(G(z)): 0.3217 / 0.2258\n",
      "[2/10][7/95] Loss_D: 1.2468 Loss_G: 1.5466 D(x): 0.6339 D(G(z)): 0.5069 / 0.2403\n",
      "[2/10][8/95] Loss_D: 1.7945 Loss_G: 0.6700 D(x): 0.3366 D(G(z)): 0.4135 / 0.5172\n",
      "[2/10][9/95] Loss_D: 1.7773 Loss_G: 3.0679 D(x): 0.7225 D(G(z)): 0.7428 / 0.0474\n",
      "[2/10][10/95] Loss_D: 1.9103 Loss_G: 0.6621 D(x): 0.1882 D(G(z)): 0.0829 / 0.5182\n",
      "[2/10][11/95] Loss_D: 1.3561 Loss_G: 0.8303 D(x): 0.5747 D(G(z)): 0.4584 / 0.4406\n",
      "[2/10][12/95] Loss_D: 1.3301 Loss_G: 2.2819 D(x): 0.7907 D(G(z)): 0.6593 / 0.1256\n",
      "[2/10][13/95] Loss_D: 1.3730 Loss_G: 1.1487 D(x): 0.3891 D(G(z)): 0.2849 / 0.3245\n",
      "[2/10][14/95] Loss_D: 0.9851 Loss_G: 1.0414 D(x): 0.5363 D(G(z)): 0.2634 / 0.3616\n",
      "[2/10][15/95] Loss_D: 1.4857 Loss_G: 1.3258 D(x): 0.6624 D(G(z)): 0.6222 / 0.2732\n",
      "[2/10][16/95] Loss_D: 0.8924 Loss_G: 1.7675 D(x): 0.6364 D(G(z)): 0.3338 / 0.1851\n",
      "[2/10][17/95] Loss_D: 1.1317 Loss_G: 0.7096 D(x): 0.4172 D(G(z)): 0.1530 / 0.4982\n",
      "[2/10][18/95] Loss_D: 1.2445 Loss_G: 1.5260 D(x): 0.7796 D(G(z)): 0.6229 / 0.2227\n",
      "[2/10][19/95] Loss_D: 1.0610 Loss_G: 1.7543 D(x): 0.6039 D(G(z)): 0.4111 / 0.1750\n",
      "[2/10][20/95] Loss_D: 1.3383 Loss_G: 0.7140 D(x): 0.3964 D(G(z)): 0.2652 / 0.4912\n",
      "[2/10][21/95] Loss_D: 1.1283 Loss_G: 2.0646 D(x): 0.7124 D(G(z)): 0.5317 / 0.1308\n",
      "[2/10][22/95] Loss_D: 0.7957 Loss_G: 1.3065 D(x): 0.5819 D(G(z)): 0.1936 / 0.2751\n",
      "[2/10][23/95] Loss_D: 0.8557 Loss_G: 1.4131 D(x): 0.7143 D(G(z)): 0.3948 / 0.2527\n",
      "[2/10][24/95] Loss_D: 1.0129 Loss_G: 2.5698 D(x): 0.7849 D(G(z)): 0.5287 / 0.0894\n",
      "[2/10][25/95] Loss_D: 1.4315 Loss_G: 1.1831 D(x): 0.4070 D(G(z)): 0.3462 / 0.3194\n",
      "[2/10][26/95] Loss_D: 2.2876 Loss_G: 0.4191 D(x): 0.3131 D(G(z)): 0.5852 / 0.6618\n",
      "[2/10][27/95] Loss_D: 0.6539 Loss_G: 2.5977 D(x): 0.7340 D(G(z)): 0.2666 / 0.0763\n",
      "[2/10][28/95] Loss_D: 1.4383 Loss_G: 4.0894 D(x): 0.7839 D(G(z)): 0.6874 / 0.0187\n",
      "[2/10][29/95] Loss_D: 1.4782 Loss_G: 1.7970 D(x): 0.2742 D(G(z)): 0.0496 / 0.1749\n",
      "[2/10][30/95] Loss_D: 0.5349 Loss_G: 1.6275 D(x): 0.8180 D(G(z)): 0.2784 / 0.2106\n",
      "[2/10][31/95] Loss_D: 1.3676 Loss_G: 1.3911 D(x): 0.5542 D(G(z)): 0.4865 / 0.2832\n",
      "[2/10][32/95] Loss_D: 0.9982 Loss_G: 2.6736 D(x): 0.7443 D(G(z)): 0.4883 / 0.0800\n",
      "[2/10][33/95] Loss_D: 1.1782 Loss_G: 1.3536 D(x): 0.4011 D(G(z)): 0.1475 / 0.2673\n",
      "[2/10][34/95] Loss_D: 1.1781 Loss_G: 0.9846 D(x): 0.6463 D(G(z)): 0.4972 / 0.3896\n",
      "[2/10][35/95] Loss_D: 0.7527 Loss_G: 1.5855 D(x): 0.6869 D(G(z)): 0.2988 / 0.2186\n",
      "[2/10][36/95] Loss_D: 0.9776 Loss_G: 1.3606 D(x): 0.6666 D(G(z)): 0.4128 / 0.2652\n",
      "[2/10][37/95] Loss_D: 1.0488 Loss_G: 1.5101 D(x): 0.6467 D(G(z)): 0.4244 / 0.2294\n",
      "[2/10][38/95] Loss_D: 1.4299 Loss_G: 0.8663 D(x): 0.4363 D(G(z)): 0.3994 / 0.4233\n",
      "[2/10][39/95] Loss_D: 1.5443 Loss_G: 1.8765 D(x): 0.7291 D(G(z)): 0.6809 / 0.1695\n",
      "[2/10][40/95] Loss_D: 1.2574 Loss_G: 1.2067 D(x): 0.4381 D(G(z)): 0.2826 / 0.3115\n",
      "[2/10][41/95] Loss_D: 1.4740 Loss_G: 1.7567 D(x): 0.5714 D(G(z)): 0.5533 / 0.1745\n",
      "[2/10][42/95] Loss_D: 1.2069 Loss_G: 1.7389 D(x): 0.5683 D(G(z)): 0.4328 / 0.1783\n",
      "[2/10][43/95] Loss_D: 1.4060 Loss_G: 0.6112 D(x): 0.3667 D(G(z)): 0.1801 / 0.5445\n",
      "[2/10][44/95] Loss_D: 1.6464 Loss_G: 2.3858 D(x): 0.8408 D(G(z)): 0.7598 / 0.1002\n",
      "[2/10][45/95] Loss_D: 1.1974 Loss_G: 1.9036 D(x): 0.4892 D(G(z)): 0.2367 / 0.1552\n",
      "[2/10][46/95] Loss_D: 1.2757 Loss_G: 1.7916 D(x): 0.5762 D(G(z)): 0.4706 / 0.1754\n",
      "[2/10][47/95] Loss_D: 1.3491 Loss_G: 1.8223 D(x): 0.4699 D(G(z)): 0.3874 / 0.1698\n",
      "[2/10][48/95] Loss_D: 1.3058 Loss_G: 1.0758 D(x): 0.4768 D(G(z)): 0.3839 / 0.3586\n",
      "[2/10][49/95] Loss_D: 1.1808 Loss_G: 2.6121 D(x): 0.6968 D(G(z)): 0.5352 / 0.0904\n",
      "[2/10][50/95] Loss_D: 0.9865 Loss_G: 1.3933 D(x): 0.5066 D(G(z)): 0.1853 / 0.2691\n",
      "[2/10][51/95] Loss_D: 0.8166 Loss_G: 2.2540 D(x): 0.8337 D(G(z)): 0.4469 / 0.1198\n",
      "[2/10][52/95] Loss_D: 1.1049 Loss_G: 1.5204 D(x): 0.5904 D(G(z)): 0.3366 / 0.2443\n",
      "[2/10][53/95] Loss_D: 0.8263 Loss_G: 2.0122 D(x): 0.7465 D(G(z)): 0.3950 / 0.1683\n",
      "[2/10][54/95] Loss_D: 0.9339 Loss_G: 2.2147 D(x): 0.6724 D(G(z)): 0.3494 / 0.1234\n",
      "[2/10][55/95] Loss_D: 0.9733 Loss_G: 3.4121 D(x): 0.6381 D(G(z)): 0.3789 / 0.0369\n",
      "[2/10][56/95] Loss_D: 1.1192 Loss_G: 1.2126 D(x): 0.5222 D(G(z)): 0.2762 / 0.2996\n",
      "[2/10][57/95] Loss_D: 1.4979 Loss_G: 3.9981 D(x): 0.7340 D(G(z)): 0.6609 / 0.0244\n",
      "[2/10][58/95] Loss_D: 2.8011 Loss_G: 0.1248 D(x): 0.1181 D(G(z)): 0.0848 / 0.8837\n",
      "[2/10][59/95] Loss_D: 2.9862 Loss_G: 3.4126 D(x): 0.9340 D(G(z)): 0.9424 / 0.0460\n",
      "[2/10][60/95] Loss_D: 1.4771 Loss_G: 1.3567 D(x): 0.3275 D(G(z)): 0.1413 / 0.2614\n",
      "[2/10][61/95] Loss_D: 1.1177 Loss_G: 1.7342 D(x): 0.6399 D(G(z)): 0.4643 / 0.1808\n",
      "[2/10][62/95] Loss_D: 1.2814 Loss_G: 1.4322 D(x): 0.4932 D(G(z)): 0.3252 / 0.2470\n",
      "[2/10][63/95] Loss_D: 1.1755 Loss_G: 1.6932 D(x): 0.5207 D(G(z)): 0.3700 / 0.1988\n",
      "[2/10][64/95] Loss_D: 0.8368 Loss_G: 2.9664 D(x): 0.7799 D(G(z)): 0.4200 / 0.0593\n",
      "[2/10][65/95] Loss_D: 0.7327 Loss_G: 1.8697 D(x): 0.6106 D(G(z)): 0.1662 / 0.1762\n",
      "[2/10][66/95] Loss_D: 0.8174 Loss_G: 1.7115 D(x): 0.7076 D(G(z)): 0.3435 / 0.2102\n",
      "[2/10][67/95] Loss_D: 1.3582 Loss_G: 2.8461 D(x): 0.7072 D(G(z)): 0.6146 / 0.0695\n",
      "[2/10][68/95] Loss_D: 1.4931 Loss_G: 0.8587 D(x): 0.3319 D(G(z)): 0.1939 / 0.4273\n",
      "[2/10][69/95] Loss_D: 0.9013 Loss_G: 3.8017 D(x): 0.8054 D(G(z)): 0.4592 / 0.0271\n",
      "[2/10][70/95] Loss_D: 0.6678 Loss_G: 2.3583 D(x): 0.6586 D(G(z)): 0.1581 / 0.1072\n",
      "[2/10][71/95] Loss_D: 0.8960 Loss_G: 1.3224 D(x): 0.6270 D(G(z)): 0.3121 / 0.2732\n",
      "[2/10][72/95] Loss_D: 1.0812 Loss_G: 2.1681 D(x): 0.7682 D(G(z)): 0.5486 / 0.1225\n",
      "[2/10][73/95] Loss_D: 0.7280 Loss_G: 2.9911 D(x): 0.7513 D(G(z)): 0.3191 / 0.0512\n",
      "[2/10][74/95] Loss_D: 1.4158 Loss_G: 0.8502 D(x): 0.3936 D(G(z)): 0.2626 / 0.4304\n",
      "[2/10][75/95] Loss_D: 1.3590 Loss_G: 3.8325 D(x): 0.8604 D(G(z)): 0.6876 / 0.0222\n",
      "[2/10][76/95] Loss_D: 1.4481 Loss_G: 1.3975 D(x): 0.3399 D(G(z)): 0.0882 / 0.2585\n",
      "[2/10][77/95] Loss_D: 1.8200 Loss_G: 4.2237 D(x): 0.8175 D(G(z)): 0.7721 / 0.0151\n",
      "[2/10][78/95] Loss_D: 2.4386 Loss_G: 0.5554 D(x): 0.1714 D(G(z)): 0.1346 / 0.5964\n",
      "[2/10][79/95] Loss_D: 2.1724 Loss_G: 4.4013 D(x): 0.8620 D(G(z)): 0.8584 / 0.0217\n",
      "[2/10][80/95] Loss_D: 1.6789 Loss_G: 2.3608 D(x): 0.3136 D(G(z)): 0.1040 / 0.1329\n",
      "[2/10][81/95] Loss_D: 1.1154 Loss_G: 2.6910 D(x): 0.6345 D(G(z)): 0.4475 / 0.0860\n",
      "[2/10][82/95] Loss_D: 1.4247 Loss_G: 1.3891 D(x): 0.4287 D(G(z)): 0.2921 / 0.2545\n",
      "[2/10][83/95] Loss_D: 0.9580 Loss_G: 3.9560 D(x): 0.7125 D(G(z)): 0.4446 / 0.0195\n",
      "[2/10][84/95] Loss_D: 0.2914 Loss_G: 4.0419 D(x): 0.8537 D(G(z)): 0.1189 / 0.0184\n",
      "[2/10][85/95] Loss_D: 0.4852 Loss_G: 2.5676 D(x): 0.6986 D(G(z)): 0.0641 / 0.0792\n",
      "[2/10][86/95] Loss_D: 0.5900 Loss_G: 2.2162 D(x): 0.7934 D(G(z)): 0.2752 / 0.1174\n",
      "[2/10][87/95] Loss_D: 0.6350 Loss_G: 3.1539 D(x): 0.8315 D(G(z)): 0.3440 / 0.0586\n",
      "[2/10][88/95] Loss_D: 0.7428 Loss_G: 2.4748 D(x): 0.6836 D(G(z)): 0.2320 / 0.1159\n",
      "[2/10][89/95] Loss_D: 0.7859 Loss_G: 3.7087 D(x): 0.7779 D(G(z)): 0.3856 / 0.0295\n",
      "[2/10][90/95] Loss_D: 1.1878 Loss_G: 3.0709 D(x): 0.5690 D(G(z)): 0.4020 / 0.0511\n",
      "[2/10][91/95] Loss_D: 0.4347 Loss_G: 3.4353 D(x): 0.7499 D(G(z)): 0.1032 / 0.0343\n",
      "[2/10][92/95] Loss_D: 1.3738 Loss_G: 1.6553 D(x): 0.5103 D(G(z)): 0.4008 / 0.1965\n",
      "[2/10][93/95] Loss_D: 1.3769 Loss_G: 6.3405 D(x): 0.8148 D(G(z)): 0.6627 / 0.0023\n",
      "[2/10][94/95] Loss_D: 3.5848 Loss_G: 0.0607 D(x): 0.0352 D(G(z)): 0.0043 / 0.9415\n",
      "[3/10][0/95] Loss_D: 3.2729 Loss_G: 3.7973 D(x): 0.9631 D(G(z)): 0.9476 / 0.0297\n",
      "[3/10][1/95] Loss_D: 0.9044 Loss_G: 3.5848 D(x): 0.6296 D(G(z)): 0.2508 / 0.0354\n",
      "[3/10][2/95] Loss_D: 1.3276 Loss_G: 1.5506 D(x): 0.5109 D(G(z)): 0.3074 / 0.2292\n",
      "[3/10][3/95] Loss_D: 2.4775 Loss_G: 4.7874 D(x): 0.6429 D(G(z)): 0.7672 / 0.0088\n",
      "[3/10][4/95] Loss_D: 2.2386 Loss_G: 1.0765 D(x): 0.2008 D(G(z)): 0.1999 / 0.3719\n",
      "[3/10][5/95] Loss_D: 2.1348 Loss_G: 1.5479 D(x): 0.5275 D(G(z)): 0.7205 / 0.2218\n",
      "[3/10][6/95] Loss_D: 1.0926 Loss_G: 3.7788 D(x): 0.7154 D(G(z)): 0.5098 / 0.0263\n",
      "[3/10][7/95] Loss_D: 2.0036 Loss_G: 1.0832 D(x): 0.1810 D(G(z)): 0.0812 / 0.3435\n",
      "[3/10][8/95] Loss_D: 1.7098 Loss_G: 1.0875 D(x): 0.6335 D(G(z)): 0.6841 / 0.3396\n",
      "[3/10][9/95] Loss_D: 1.1852 Loss_G: 1.8246 D(x): 0.5735 D(G(z)): 0.4311 / 0.1646\n",
      "[3/10][10/95] Loss_D: 0.7406 Loss_G: 1.9490 D(x): 0.6834 D(G(z)): 0.2702 / 0.1505\n",
      "[3/10][11/95] Loss_D: 0.9243 Loss_G: 1.2292 D(x): 0.5806 D(G(z)): 0.2577 / 0.2987\n",
      "[3/10][12/95] Loss_D: 1.0017 Loss_G: 1.9660 D(x): 0.8275 D(G(z)): 0.5457 / 0.1614\n",
      "[3/10][13/95] Loss_D: 0.7147 Loss_G: 2.0071 D(x): 0.6331 D(G(z)): 0.1967 / 0.1457\n",
      "[3/10][14/95] Loss_D: 0.6720 Loss_G: 2.1056 D(x): 0.8575 D(G(z)): 0.3998 / 0.1259\n",
      "[3/10][15/95] Loss_D: 0.5174 Loss_G: 2.5835 D(x): 0.7258 D(G(z)): 0.1602 / 0.0775\n",
      "[3/10][16/95] Loss_D: 1.0634 Loss_G: 1.1311 D(x): 0.5079 D(G(z)): 0.2807 / 0.3349\n",
      "[3/10][17/95] Loss_D: 0.9677 Loss_G: 2.1082 D(x): 0.7376 D(G(z)): 0.4306 / 0.1428\n",
      "[3/10][18/95] Loss_D: 0.9842 Loss_G: 1.8225 D(x): 0.5685 D(G(z)): 0.2860 / 0.1944\n",
      "[3/10][19/95] Loss_D: 1.1502 Loss_G: 1.0313 D(x): 0.5475 D(G(z)): 0.3625 / 0.3672\n",
      "[3/10][20/95] Loss_D: 1.2204 Loss_G: 2.2138 D(x): 0.8473 D(G(z)): 0.5827 / 0.1165\n",
      "[3/10][21/95] Loss_D: 0.8988 Loss_G: 2.1034 D(x): 0.6146 D(G(z)): 0.2957 / 0.1309\n",
      "[3/10][22/95] Loss_D: 1.1325 Loss_G: 1.0820 D(x): 0.4840 D(G(z)): 0.2613 / 0.3528\n",
      "[3/10][23/95] Loss_D: 1.2724 Loss_G: 2.5932 D(x): 0.7270 D(G(z)): 0.5877 / 0.0791\n",
      "[3/10][24/95] Loss_D: 0.8077 Loss_G: 2.1625 D(x): 0.5347 D(G(z)): 0.1326 / 0.1198\n",
      "[3/10][25/95] Loss_D: 1.0070 Loss_G: 2.7295 D(x): 0.7220 D(G(z)): 0.4751 / 0.0760\n",
      "[3/10][26/95] Loss_D: 0.8158 Loss_G: 1.6881 D(x): 0.5959 D(G(z)): 0.2079 / 0.2099\n",
      "[3/10][27/95] Loss_D: 0.6732 Loss_G: 1.5560 D(x): 0.7244 D(G(z)): 0.2683 / 0.2337\n",
      "[3/10][28/95] Loss_D: 0.8577 Loss_G: 2.0488 D(x): 0.7938 D(G(z)): 0.4373 / 0.1538\n",
      "[3/10][29/95] Loss_D: 0.6451 Loss_G: 2.2813 D(x): 0.6776 D(G(z)): 0.1519 / 0.1443\n",
      "[3/10][30/95] Loss_D: 0.5399 Loss_G: 2.1560 D(x): 0.7873 D(G(z)): 0.2399 / 0.1463\n",
      "[3/10][31/95] Loss_D: 0.4625 Loss_G: 2.7042 D(x): 0.8498 D(G(z)): 0.2302 / 0.0807\n",
      "[3/10][32/95] Loss_D: 0.9057 Loss_G: 2.1874 D(x): 0.6633 D(G(z)): 0.1723 / 0.1201\n",
      "[3/10][33/95] Loss_D: 0.9028 Loss_G: 1.9629 D(x): 0.7375 D(G(z)): 0.4170 / 0.1480\n",
      "[3/10][34/95] Loss_D: 1.0642 Loss_G: 1.8332 D(x): 0.5887 D(G(z)): 0.3579 / 0.1803\n",
      "[3/10][35/95] Loss_D: 1.4421 Loss_G: 1.2479 D(x): 0.3886 D(G(z)): 0.2892 / 0.2966\n",
      "[3/10][36/95] Loss_D: 1.3821 Loss_G: 4.2331 D(x): 0.8382 D(G(z)): 0.6841 / 0.0191\n",
      "[3/10][37/95] Loss_D: 1.8833 Loss_G: 1.0447 D(x): 0.2047 D(G(z)): 0.0378 / 0.3643\n",
      "[3/10][38/95] Loss_D: 1.3955 Loss_G: 1.3386 D(x): 0.7376 D(G(z)): 0.6420 / 0.2745\n",
      "[3/10][39/95] Loss_D: 0.9476 Loss_G: 2.0709 D(x): 0.6492 D(G(z)): 0.3639 / 0.1369\n",
      "[3/10][40/95] Loss_D: 0.4583 Loss_G: 3.1177 D(x): 0.8952 D(G(z)): 0.2887 / 0.0473\n",
      "[3/10][41/95] Loss_D: 0.8184 Loss_G: 1.6132 D(x): 0.5446 D(G(z)): 0.0801 / 0.2148\n",
      "[3/10][42/95] Loss_D: 0.6619 Loss_G: 2.6259 D(x): 0.8765 D(G(z)): 0.3916 / 0.0915\n",
      "[3/10][43/95] Loss_D: 0.5832 Loss_G: 3.2263 D(x): 0.7283 D(G(z)): 0.1960 / 0.0558\n",
      "[3/10][44/95] Loss_D: 0.6178 Loss_G: 3.3482 D(x): 0.8195 D(G(z)): 0.2980 / 0.0535\n",
      "[3/10][45/95] Loss_D: 0.8122 Loss_G: 1.8410 D(x): 0.5818 D(G(z)): 0.1559 / 0.1800\n",
      "[3/10][46/95] Loss_D: 0.7377 Loss_G: 2.3017 D(x): 0.8230 D(G(z)): 0.4098 / 0.1080\n",
      "[3/10][47/95] Loss_D: 0.5153 Loss_G: 3.0720 D(x): 0.8185 D(G(z)): 0.2530 / 0.0498\n",
      "[3/10][48/95] Loss_D: 0.7456 Loss_G: 2.5274 D(x): 0.6794 D(G(z)): 0.2491 / 0.0831\n",
      "[3/10][49/95] Loss_D: 0.9054 Loss_G: 3.7824 D(x): 0.7652 D(G(z)): 0.3979 / 0.0261\n",
      "[3/10][50/95] Loss_D: 1.7265 Loss_G: 1.5023 D(x): 0.2683 D(G(z)): 0.1745 / 0.2282\n",
      "[3/10][51/95] Loss_D: 1.3738 Loss_G: 3.9959 D(x): 0.7933 D(G(z)): 0.6617 / 0.0214\n",
      "[3/10][52/95] Loss_D: 1.9965 Loss_G: 0.5303 D(x): 0.2293 D(G(z)): 0.1142 / 0.5920\n",
      "[3/10][53/95] Loss_D: 1.2028 Loss_G: 2.1265 D(x): 0.8700 D(G(z)): 0.6458 / 0.1269\n",
      "[3/10][54/95] Loss_D: 0.6204 Loss_G: 3.5526 D(x): 0.8253 D(G(z)): 0.3258 / 0.0312\n",
      "[3/10][55/95] Loss_D: 0.8941 Loss_G: 1.5804 D(x): 0.4825 D(G(z)): 0.0749 / 0.2112\n",
      "[3/10][56/95] Loss_D: 0.7314 Loss_G: 3.0917 D(x): 0.9017 D(G(z)): 0.4585 / 0.0474\n",
      "[3/10][57/95] Loss_D: 0.5531 Loss_G: 2.8933 D(x): 0.6957 D(G(z)): 0.1106 / 0.0571\n",
      "[3/10][58/95] Loss_D: 0.3117 Loss_G: 3.1536 D(x): 0.8809 D(G(z)): 0.1629 / 0.0435\n",
      "[3/10][59/95] Loss_D: 0.4934 Loss_G: 2.4646 D(x): 0.7594 D(G(z)): 0.1664 / 0.0886\n",
      "[3/10][60/95] Loss_D: 0.5240 Loss_G: 2.5937 D(x): 0.7921 D(G(z)): 0.2258 / 0.0797\n",
      "[3/10][61/95] Loss_D: 0.6249 Loss_G: 2.5635 D(x): 0.7066 D(G(z)): 0.2040 / 0.0816\n",
      "[3/10][62/95] Loss_D: 0.4529 Loss_G: 3.3431 D(x): 0.8396 D(G(z)): 0.2265 / 0.0381\n",
      "[3/10][63/95] Loss_D: 0.6421 Loss_G: 2.3169 D(x): 0.6416 D(G(z)): 0.1406 / 0.1059\n",
      "[3/10][64/95] Loss_D: 0.8024 Loss_G: 4.0743 D(x): 0.8357 D(G(z)): 0.4332 / 0.0216\n",
      "[3/10][65/95] Loss_D: 0.6886 Loss_G: 2.5967 D(x): 0.5743 D(G(z)): 0.0714 / 0.0943\n",
      "[3/10][66/95] Loss_D: 0.6238 Loss_G: 3.9533 D(x): 0.8447 D(G(z)): 0.3442 / 0.0248\n",
      "[3/10][67/95] Loss_D: 0.5641 Loss_G: 3.7595 D(x): 0.7464 D(G(z)): 0.1981 / 0.0293\n",
      "[3/10][68/95] Loss_D: 0.4381 Loss_G: 3.5907 D(x): 0.7939 D(G(z)): 0.1712 / 0.0338\n",
      "[3/10][69/95] Loss_D: 0.6919 Loss_G: 3.0393 D(x): 0.7147 D(G(z)): 0.2350 / 0.0524\n",
      "[3/10][70/95] Loss_D: 0.6845 Loss_G: 5.5989 D(x): 0.8076 D(G(z)): 0.3407 / 0.0051\n",
      "[3/10][71/95] Loss_D: 1.0299 Loss_G: 0.5092 D(x): 0.4431 D(G(z)): 0.0409 / 0.6158\n",
      "[3/10][72/95] Loss_D: 2.1816 Loss_G: 8.5652 D(x): 0.9765 D(G(z)): 0.8696 / 0.0016\n",
      "[3/10][73/95] Loss_D: 1.0414 Loss_G: 5.7308 D(x): 0.4003 D(G(z)): 0.0051 / 0.0099\n",
      "[3/10][74/95] Loss_D: 0.3284 Loss_G: 2.3879 D(x): 0.8229 D(G(z)): 0.0861 / 0.1402\n",
      "[3/10][75/95] Loss_D: 2.4449 Loss_G: 10.8406 D(x): 0.9576 D(G(z)): 0.8968 / 0.0000\n",
      "[3/10][76/95] Loss_D: 3.6945 Loss_G: 2.2114 D(x): 0.0450 D(G(z)): 0.0032 / 0.1410\n",
      "[3/10][77/95] Loss_D: 1.3750 Loss_G: 3.4028 D(x): 0.7298 D(G(z)): 0.6243 / 0.0407\n",
      "[3/10][78/95] Loss_D: 1.1159 Loss_G: 3.4411 D(x): 0.5751 D(G(z)): 0.3652 / 0.0352\n",
      "[3/10][79/95] Loss_D: 1.2523 Loss_G: 1.4023 D(x): 0.4645 D(G(z)): 0.2930 / 0.2491\n",
      "[3/10][80/95] Loss_D: 1.4175 Loss_G: 6.9350 D(x): 0.8903 D(G(z)): 0.7203 / 0.0016\n",
      "[3/10][81/95] Loss_D: 2.9097 Loss_G: 1.9509 D(x): 0.0844 D(G(z)): 0.0118 / 0.1561\n",
      "[3/10][82/95] Loss_D: 0.7056 Loss_G: 1.9679 D(x): 0.8468 D(G(z)): 0.3952 / 0.1403\n",
      "[3/10][83/95] Loss_D: 0.9916 Loss_G: 4.4628 D(x): 0.9071 D(G(z)): 0.5835 / 0.0121\n",
      "[3/10][84/95] Loss_D: 0.9634 Loss_G: 2.7941 D(x): 0.4814 D(G(z)): 0.0447 / 0.0637\n",
      "[3/10][85/95] Loss_D: 0.7380 Loss_G: 1.3439 D(x): 0.6651 D(G(z)): 0.2418 / 0.2736\n",
      "[3/10][86/95] Loss_D: 0.8868 Loss_G: 3.4543 D(x): 0.9296 D(G(z)): 0.5382 / 0.0328\n",
      "[3/10][87/95] Loss_D: 0.6634 Loss_G: 2.7589 D(x): 0.6182 D(G(z)): 0.1034 / 0.0639\n",
      "[3/10][88/95] Loss_D: 0.4140 Loss_G: 3.3810 D(x): 0.9332 D(G(z)): 0.2901 / 0.0380\n",
      "[3/10][89/95] Loss_D: 0.4980 Loss_G: 3.0731 D(x): 0.7564 D(G(z)): 0.1733 / 0.0511\n",
      "[3/10][90/95] Loss_D: 0.2991 Loss_G: 3.8151 D(x): 0.9254 D(G(z)): 0.1964 / 0.0248\n",
      "[3/10][91/95] Loss_D: 0.7893 Loss_G: 2.0624 D(x): 0.5774 D(G(z)): 0.1262 / 0.1290\n",
      "[3/10][92/95] Loss_D: 0.8954 Loss_G: 4.8067 D(x): 0.8692 D(G(z)): 0.5169 / 0.0118\n",
      "[3/10][93/95] Loss_D: 0.4120 Loss_G: 4.6580 D(x): 0.7171 D(G(z)): 0.0372 / 0.0136\n",
      "[3/10][94/95] Loss_D: 0.3353 Loss_G: 2.9880 D(x): 0.8240 D(G(z)): 0.1140 / 0.0711\n",
      "[4/10][0/95] Loss_D: 0.3645 Loss_G: 3.7558 D(x): 0.9755 D(G(z)): 0.2532 / 0.0389\n",
      "[4/10][1/95] Loss_D: 0.3209 Loss_G: 3.8284 D(x): 0.8611 D(G(z)): 0.1434 / 0.0264\n",
      "[4/10][2/95] Loss_D: 0.8453 Loss_G: 3.5924 D(x): 0.7524 D(G(z)): 0.3559 / 0.0298\n",
      "[4/10][3/95] Loss_D: 0.8122 Loss_G: 7.3224 D(x): 0.8810 D(G(z)): 0.4655 / 0.0007\n",
      "[4/10][4/95] Loss_D: 4.1375 Loss_G: 0.1374 D(x): 0.0248 D(G(z)): 0.0166 / 0.8737\n",
      "[4/10][5/95] Loss_D: 3.0450 Loss_G: 2.8102 D(x): 0.9671 D(G(z)): 0.9372 / 0.0705\n",
      "[4/10][6/95] Loss_D: 1.3432 Loss_G: 2.3043 D(x): 0.4173 D(G(z)): 0.2543 / 0.1113\n",
      "[4/10][7/95] Loss_D: 2.9281 Loss_G: 0.1650 D(x): 0.1196 D(G(z)): 0.3133 / 0.8498\n",
      "[4/10][8/95] Loss_D: 3.0040 Loss_G: 4.9847 D(x): 0.8764 D(G(z)): 0.9361 / 0.0094\n",
      "[4/10][9/95] Loss_D: 2.3114 Loss_G: 0.6644 D(x): 0.1578 D(G(z)): 0.1735 / 0.5245\n",
      "[4/10][10/95] Loss_D: 1.1310 Loss_G: 2.0009 D(x): 0.8583 D(G(z)): 0.6082 / 0.1527\n",
      "[4/10][11/95] Loss_D: 1.6875 Loss_G: 4.2131 D(x): 0.9023 D(G(z)): 0.7716 / 0.0276\n",
      "[4/10][12/95] Loss_D: 5.5632 Loss_G: 0.3229 D(x): 0.0085 D(G(z)): 0.2714 / 0.7356\n",
      "[4/10][13/95] Loss_D: 1.8599 Loss_G: 0.4269 D(x): 0.4338 D(G(z)): 0.5655 / 0.6894\n",
      "[4/10][14/95] Loss_D: 2.7197 Loss_G: 0.9345 D(x): 0.6507 D(G(z)): 0.8577 / 0.4456\n",
      "[4/10][15/95] Loss_D: 1.2853 Loss_G: 2.3594 D(x): 0.6310 D(G(z)): 0.4773 / 0.1376\n",
      "[4/10][16/95] Loss_D: 1.4418 Loss_G: 1.0629 D(x): 0.3813 D(G(z)): 0.2090 / 0.4093\n",
      "[4/10][17/95] Loss_D: 1.4627 Loss_G: 1.5418 D(x): 0.6925 D(G(z)): 0.5703 / 0.2815\n",
      "[4/10][18/95] Loss_D: 1.7199 Loss_G: 2.9713 D(x): 0.6320 D(G(z)): 0.6148 / 0.0612\n",
      "[4/10][19/95] Loss_D: 2.1634 Loss_G: 0.4613 D(x): 0.1658 D(G(z)): 0.1047 / 0.6656\n",
      "[4/10][20/95] Loss_D: 2.4394 Loss_G: 3.4181 D(x): 0.8036 D(G(z)): 0.8741 / 0.0356\n",
      "[4/10][21/95] Loss_D: 2.7633 Loss_G: 0.6845 D(x): 0.0834 D(G(z)): 0.0864 / 0.5096\n",
      "[4/10][22/95] Loss_D: 1.6199 Loss_G: 0.6267 D(x): 0.5993 D(G(z)): 0.6516 / 0.5383\n",
      "[4/10][23/95] Loss_D: 1.2526 Loss_G: 0.6074 D(x): 0.3960 D(G(z)): 0.2492 / 0.5529\n",
      "[4/10][24/95] Loss_D: 1.4953 Loss_G: 2.2614 D(x): 0.8218 D(G(z)): 0.7030 / 0.1088\n",
      "[4/10][25/95] Loss_D: 1.4282 Loss_G: 1.6350 D(x): 0.5872 D(G(z)): 0.5480 / 0.2099\n",
      "[4/10][26/95] Loss_D: 1.8961 Loss_G: 0.7531 D(x): 0.2070 D(G(z)): 0.1405 / 0.4743\n",
      "[4/10][27/95] Loss_D: 1.4259 Loss_G: 0.3818 D(x): 0.4942 D(G(z)): 0.4865 / 0.6856\n",
      "[4/10][28/95] Loss_D: 1.5706 Loss_G: 1.2247 D(x): 0.8328 D(G(z)): 0.7430 / 0.3050\n",
      "[4/10][29/95] Loss_D: 0.9026 Loss_G: 1.8051 D(x): 0.6090 D(G(z)): 0.3049 / 0.1775\n",
      "[4/10][30/95] Loss_D: 1.0473 Loss_G: 1.3259 D(x): 0.6832 D(G(z)): 0.4355 / 0.2792\n",
      "[4/10][31/95] Loss_D: 0.9187 Loss_G: 2.1974 D(x): 0.7350 D(G(z)): 0.4351 / 0.1181\n",
      "[4/10][32/95] Loss_D: 1.1954 Loss_G: 1.1262 D(x): 0.4586 D(G(z)): 0.2859 / 0.3295\n",
      "[4/10][33/95] Loss_D: 1.3545 Loss_G: 0.5806 D(x): 0.3844 D(G(z)): 0.2780 / 0.5826\n",
      "[4/10][34/95] Loss_D: 1.4335 Loss_G: 1.6034 D(x): 0.7706 D(G(z)): 0.6724 / 0.2122\n",
      "[4/10][35/95] Loss_D: 1.4844 Loss_G: 1.1576 D(x): 0.4025 D(G(z)): 0.3368 / 0.3443\n",
      "[4/10][36/95] Loss_D: 1.4249 Loss_G: 0.6929 D(x): 0.4250 D(G(z)): 0.3489 / 0.5193\n",
      "[4/10][37/95] Loss_D: 2.9031 Loss_G: 2.3987 D(x): 0.8351 D(G(z)): 0.9174 / 0.1567\n",
      "[4/10][38/95] Loss_D: 2.1801 Loss_G: 1.2801 D(x): 0.2117 D(G(z)): 0.2371 / 0.3159\n",
      "[4/10][39/95] Loss_D: 1.8692 Loss_G: 0.3900 D(x): 0.3488 D(G(z)): 0.4604 / 0.6826\n",
      "[4/10][40/95] Loss_D: 1.8948 Loss_G: 0.9385 D(x): 0.6376 D(G(z)): 0.7238 / 0.4022\n",
      "[4/10][41/95] Loss_D: 1.4679 Loss_G: 1.3413 D(x): 0.4415 D(G(z)): 0.4215 / 0.2644\n",
      "[4/10][42/95] Loss_D: 1.6370 Loss_G: 0.6277 D(x): 0.3508 D(G(z)): 0.3747 / 0.5401\n",
      "[4/10][43/95] Loss_D: 1.5396 Loss_G: 0.8211 D(x): 0.6055 D(G(z)): 0.6220 / 0.4441\n",
      "[4/10][44/95] Loss_D: 1.2972 Loss_G: 1.3253 D(x): 0.6041 D(G(z)): 0.5228 / 0.2799\n",
      "[4/10][45/95] Loss_D: 1.2532 Loss_G: 1.0759 D(x): 0.5123 D(G(z)): 0.3909 / 0.3513\n",
      "[4/10][46/95] Loss_D: 1.4163 Loss_G: 0.9046 D(x): 0.5201 D(G(z)): 0.4970 / 0.4153\n",
      "[4/10][47/95] Loss_D: 1.3050 Loss_G: 1.0506 D(x): 0.5311 D(G(z)): 0.4564 / 0.3582\n",
      "[4/10][48/95] Loss_D: 1.1967 Loss_G: 0.9939 D(x): 0.5393 D(G(z)): 0.4025 / 0.3785\n",
      "[4/10][49/95] Loss_D: 1.1708 Loss_G: 1.4245 D(x): 0.6406 D(G(z)): 0.4937 / 0.2504\n",
      "[4/10][50/95] Loss_D: 1.6165 Loss_G: 1.4366 D(x): 0.5017 D(G(z)): 0.5124 / 0.2473\n",
      "[4/10][51/95] Loss_D: 1.4860 Loss_G: 1.0163 D(x): 0.4117 D(G(z)): 0.3947 / 0.3739\n",
      "[4/10][52/95] Loss_D: 0.9753 Loss_G: 1.2518 D(x): 0.6324 D(G(z)): 0.3629 / 0.3004\n",
      "[4/10][53/95] Loss_D: 1.4661 Loss_G: 1.4872 D(x): 0.6942 D(G(z)): 0.6416 / 0.2351\n",
      "[4/10][54/95] Loss_D: 1.2542 Loss_G: 1.4397 D(x): 0.4645 D(G(z)): 0.3402 / 0.2504\n",
      "[4/10][55/95] Loss_D: 1.5500 Loss_G: 1.1907 D(x): 0.5991 D(G(z)): 0.6133 / 0.3106\n",
      "[4/10][56/95] Loss_D: 1.7232 Loss_G: 1.1369 D(x): 0.3955 D(G(z)): 0.5014 / 0.3340\n",
      "[4/10][57/95] Loss_D: 1.9167 Loss_G: 0.7082 D(x): 0.3201 D(G(z)): 0.4873 / 0.5233\n",
      "[4/10][58/95] Loss_D: 1.7524 Loss_G: 1.1743 D(x): 0.5911 D(G(z)): 0.6887 / 0.3146\n",
      "[4/10][59/95] Loss_D: 1.2402 Loss_G: 1.8906 D(x): 0.5358 D(G(z)): 0.4309 / 0.1591\n",
      "[4/10][60/95] Loss_D: 1.2325 Loss_G: 0.9894 D(x): 0.4286 D(G(z)): 0.2796 / 0.3796\n",
      "[4/10][61/95] Loss_D: 0.9748 Loss_G: 1.6652 D(x): 0.6944 D(G(z)): 0.4438 / 0.1947\n",
      "[4/10][62/95] Loss_D: 1.1269 Loss_G: 0.8041 D(x): 0.4358 D(G(z)): 0.2380 / 0.4561\n",
      "[4/10][63/95] Loss_D: 2.3277 Loss_G: 3.4727 D(x): 0.8852 D(G(z)): 0.8817 / 0.0361\n",
      "[4/10][64/95] Loss_D: 2.2024 Loss_G: 0.9274 D(x): 0.1515 D(G(z)): 0.0838 / 0.4034\n",
      "[4/10][65/95] Loss_D: 1.6266 Loss_G: 0.9737 D(x): 0.6622 D(G(z)): 0.6888 / 0.3950\n",
      "[4/10][66/95] Loss_D: 1.4102 Loss_G: 1.2959 D(x): 0.5092 D(G(z)): 0.4986 / 0.2793\n",
      "[4/10][67/95] Loss_D: 1.3508 Loss_G: 1.0037 D(x): 0.4778 D(G(z)): 0.4368 / 0.3698\n",
      "[4/10][68/95] Loss_D: 1.3140 Loss_G: 0.9950 D(x): 0.5222 D(G(z)): 0.4663 / 0.3737\n",
      "[4/10][69/95] Loss_D: 1.5346 Loss_G: 1.1838 D(x): 0.5541 D(G(z)): 0.5791 / 0.3187\n",
      "[4/10][70/95] Loss_D: 1.6334 Loss_G: 0.7121 D(x): 0.3791 D(G(z)): 0.4199 / 0.4927\n",
      "[4/10][71/95] Loss_D: 1.4263 Loss_G: 0.9539 D(x): 0.5974 D(G(z)): 0.5810 / 0.3866\n",
      "[4/10][72/95] Loss_D: 1.2763 Loss_G: 1.2034 D(x): 0.5759 D(G(z)): 0.5007 / 0.3044\n",
      "[4/10][73/95] Loss_D: 1.2084 Loss_G: 1.0649 D(x): 0.4845 D(G(z)): 0.3629 / 0.3496\n",
      "[4/10][74/95] Loss_D: 1.5914 Loss_G: 1.1077 D(x): 0.4399 D(G(z)): 0.5032 / 0.3335\n",
      "[4/10][75/95] Loss_D: 1.0826 Loss_G: 1.2192 D(x): 0.6013 D(G(z)): 0.4204 / 0.2996\n",
      "[4/10][76/95] Loss_D: 1.0702 Loss_G: 1.2871 D(x): 0.5969 D(G(z)): 0.4010 / 0.2805\n",
      "[4/10][77/95] Loss_D: 1.1017 Loss_G: 1.1498 D(x): 0.6160 D(G(z)): 0.4317 / 0.3231\n",
      "[4/10][78/95] Loss_D: 0.9843 Loss_G: 1.5200 D(x): 0.6419 D(G(z)): 0.3867 / 0.2257\n",
      "[4/10][79/95] Loss_D: 1.1972 Loss_G: 1.1846 D(x): 0.5528 D(G(z)): 0.4258 / 0.3093\n",
      "[4/10][80/95] Loss_D: 1.3490 Loss_G: 0.9362 D(x): 0.5141 D(G(z)): 0.4476 / 0.3988\n",
      "[4/10][81/95] Loss_D: 1.2536 Loss_G: 1.1677 D(x): 0.5950 D(G(z)): 0.4857 / 0.3185\n",
      "[4/10][82/95] Loss_D: 1.4223 Loss_G: 0.9023 D(x): 0.4947 D(G(z)): 0.4593 / 0.4109\n",
      "[4/10][83/95] Loss_D: 1.5866 Loss_G: 0.9861 D(x): 0.5670 D(G(z)): 0.6215 / 0.3794\n",
      "[4/10][84/95] Loss_D: 1.5409 Loss_G: 1.2388 D(x): 0.5015 D(G(z)): 0.5357 / 0.2977\n",
      "[4/10][85/95] Loss_D: 1.4711 Loss_G: 0.8412 D(x): 0.3781 D(G(z)): 0.3418 / 0.4339\n",
      "[4/10][86/95] Loss_D: 1.4257 Loss_G: 0.9784 D(x): 0.5532 D(G(z)): 0.5469 / 0.3841\n",
      "[4/10][87/95] Loss_D: 1.2139 Loss_G: 1.0112 D(x): 0.5036 D(G(z)): 0.3836 / 0.3756\n",
      "[4/10][88/95] Loss_D: 1.4641 Loss_G: 1.7356 D(x): 0.6267 D(G(z)): 0.6253 / 0.1791\n",
      "[4/10][89/95] Loss_D: 1.4557 Loss_G: 0.8868 D(x): 0.3810 D(G(z)): 0.3464 / 0.4147\n",
      "[4/10][90/95] Loss_D: 1.5357 Loss_G: 1.2175 D(x): 0.6386 D(G(z)): 0.6519 / 0.3007\n",
      "[4/10][91/95] Loss_D: 1.3369 Loss_G: 1.0999 D(x): 0.4778 D(G(z)): 0.4132 / 0.3368\n",
      "[4/10][92/95] Loss_D: 1.3168 Loss_G: 0.8120 D(x): 0.4718 D(G(z)): 0.4044 / 0.4464\n",
      "[4/10][93/95] Loss_D: 1.4820 Loss_G: 1.9245 D(x): 0.6747 D(G(z)): 0.6537 / 0.1473\n",
      "[4/10][94/95] Loss_D: 1.2251 Loss_G: 0.9446 D(x): 0.4136 D(G(z)): 0.1936 / 0.3968\n",
      "[5/10][0/95] Loss_D: 1.7335 Loss_G: 0.6422 D(x): 0.3530 D(G(z)): 0.4683 / 0.5439\n",
      "[5/10][1/95] Loss_D: 1.9200 Loss_G: 1.8865 D(x): 0.7960 D(G(z)): 0.8070 / 0.1680\n",
      "[5/10][2/95] Loss_D: 1.8301 Loss_G: 0.8359 D(x): 0.2476 D(G(z)): 0.2723 / 0.4444\n",
      "[5/10][3/95] Loss_D: 1.5656 Loss_G: 0.7233 D(x): 0.5193 D(G(z)): 0.5592 / 0.4918\n",
      "[5/10][4/95] Loss_D: 1.6122 Loss_G: 1.4790 D(x): 0.5758 D(G(z)): 0.6352 / 0.2311\n",
      "[5/10][5/95] Loss_D: 1.4692 Loss_G: 0.9134 D(x): 0.3663 D(G(z)): 0.3085 / 0.4019\n",
      "[5/10][6/95] Loss_D: 1.1743 Loss_G: 0.9726 D(x): 0.5785 D(G(z)): 0.4462 / 0.3804\n",
      "[5/10][7/95] Loss_D: 1.1753 Loss_G: 1.4880 D(x): 0.5989 D(G(z)): 0.4667 / 0.2330\n",
      "[5/10][8/95] Loss_D: 1.1968 Loss_G: 1.1013 D(x): 0.5046 D(G(z)): 0.3562 / 0.3396\n",
      "[5/10][9/95] Loss_D: 1.1791 Loss_G: 1.2207 D(x): 0.6510 D(G(z)): 0.5113 / 0.3025\n",
      "[5/10][10/95] Loss_D: 1.4480 Loss_G: 0.8521 D(x): 0.4690 D(G(z)): 0.4590 / 0.4299\n",
      "[5/10][11/95] Loss_D: 1.5683 Loss_G: 0.8271 D(x): 0.4973 D(G(z)): 0.5560 / 0.4416\n",
      "[5/10][12/95] Loss_D: 1.3444 Loss_G: 1.0953 D(x): 0.6168 D(G(z)): 0.5571 / 0.3488\n",
      "[5/10][13/95] Loss_D: 1.2825 Loss_G: 0.9954 D(x): 0.5091 D(G(z)): 0.4264 / 0.3735\n",
      "[5/10][14/95] Loss_D: 1.4257 Loss_G: 1.0192 D(x): 0.5456 D(G(z)): 0.5155 / 0.3652\n",
      "[5/10][15/95] Loss_D: 1.4218 Loss_G: 0.7982 D(x): 0.4591 D(G(z)): 0.4378 / 0.4544\n",
      "[5/10][16/95] Loss_D: 1.1664 Loss_G: 1.1015 D(x): 0.6659 D(G(z)): 0.5172 / 0.3374\n",
      "[5/10][17/95] Loss_D: 1.2480 Loss_G: 1.2565 D(x): 0.5416 D(G(z)): 0.4516 / 0.2898\n",
      "[5/10][18/95] Loss_D: 1.3940 Loss_G: 1.2444 D(x): 0.4917 D(G(z)): 0.4634 / 0.2949\n",
      "[5/10][19/95] Loss_D: 1.2061 Loss_G: 1.7794 D(x): 0.5996 D(G(z)): 0.4736 / 0.1758\n",
      "[5/10][20/95] Loss_D: 1.1068 Loss_G: 1.4793 D(x): 0.5340 D(G(z)): 0.3521 / 0.2374\n",
      "[5/10][21/95] Loss_D: 1.2486 Loss_G: 1.3784 D(x): 0.5899 D(G(z)): 0.4857 / 0.2654\n",
      "[5/10][22/95] Loss_D: 1.3170 Loss_G: 1.4786 D(x): 0.5180 D(G(z)): 0.4495 / 0.2376\n",
      "[5/10][23/95] Loss_D: 1.4728 Loss_G: 1.3855 D(x): 0.5189 D(G(z)): 0.5265 / 0.2649\n",
      "[5/10][24/95] Loss_D: 2.0880 Loss_G: 0.8793 D(x): 0.3276 D(G(z)): 0.5449 / 0.4339\n",
      "[5/10][25/95] Loss_D: 1.7210 Loss_G: 1.8116 D(x): 0.5330 D(G(z)): 0.6237 / 0.1845\n",
      "[5/10][26/95] Loss_D: 1.9637 Loss_G: 0.8783 D(x): 0.2902 D(G(z)): 0.4394 / 0.4383\n",
      "[5/10][27/95] Loss_D: 1.4230 Loss_G: 1.6888 D(x): 0.5917 D(G(z)): 0.5384 / 0.1933\n",
      "[5/10][28/95] Loss_D: 1.3103 Loss_G: 1.6967 D(x): 0.4929 D(G(z)): 0.4115 / 0.1918\n",
      "[5/10][29/95] Loss_D: 1.2234 Loss_G: 1.1003 D(x): 0.4988 D(G(z)): 0.3646 / 0.3373\n",
      "[5/10][30/95] Loss_D: 1.5112 Loss_G: 3.7974 D(x): 0.7143 D(G(z)): 0.6725 / 0.0240\n",
      "[5/10][31/95] Loss_D: 2.4365 Loss_G: 0.1426 D(x): 0.1235 D(G(z)): 0.0971 / 0.8679\n",
      "[5/10][32/95] Loss_D: 2.1104 Loss_G: 2.0210 D(x): 0.8952 D(G(z)): 0.8610 / 0.1419\n",
      "[5/10][33/95] Loss_D: 1.0366 Loss_G: 2.4703 D(x): 0.5472 D(G(z)): 0.3238 / 0.0902\n",
      "[5/10][34/95] Loss_D: 1.0859 Loss_G: 1.1515 D(x): 0.4890 D(G(z)): 0.2709 / 0.3308\n",
      "[5/10][35/95] Loss_D: 1.0415 Loss_G: 1.3086 D(x): 0.6951 D(G(z)): 0.4515 / 0.2796\n",
      "[5/10][36/95] Loss_D: 1.6471 Loss_G: 1.4313 D(x): 0.6020 D(G(z)): 0.6549 / 0.2409\n",
      "[5/10][37/95] Loss_D: 1.4331 Loss_G: 0.9868 D(x): 0.3993 D(G(z)): 0.3320 / 0.3771\n",
      "[5/10][38/95] Loss_D: 1.6627 Loss_G: 0.4454 D(x): 0.3369 D(G(z)): 0.3684 / 0.6432\n",
      "[5/10][39/95] Loss_D: 1.7010 Loss_G: 1.5986 D(x): 0.8082 D(G(z)): 0.7657 / 0.2522\n",
      "[5/10][40/95] Loss_D: 1.6223 Loss_G: 0.9368 D(x): 0.3287 D(G(z)): 0.3165 / 0.4105\n",
      "[5/10][41/95] Loss_D: 1.1616 Loss_G: 0.8879 D(x): 0.5896 D(G(z)): 0.4446 / 0.4244\n",
      "[5/10][42/95] Loss_D: 1.1610 Loss_G: 1.2042 D(x): 0.6628 D(G(z)): 0.5198 / 0.3048\n",
      "[5/10][43/95] Loss_D: 1.2742 Loss_G: 0.8932 D(x): 0.4874 D(G(z)): 0.4028 / 0.4119\n",
      "[5/10][44/95] Loss_D: 1.2846 Loss_G: 0.8238 D(x): 0.5425 D(G(z)): 0.4538 / 0.4446\n",
      "[5/10][45/95] Loss_D: 1.1669 Loss_G: 1.1925 D(x): 0.7027 D(G(z)): 0.5434 / 0.3104\n",
      "[5/10][46/95] Loss_D: 1.3620 Loss_G: 1.0735 D(x): 0.5487 D(G(z)): 0.5127 / 0.3496\n",
      "[5/10][47/95] Loss_D: 2.0317 Loss_G: 0.8323 D(x): 0.2427 D(G(z)): 0.4184 / 0.4396\n",
      "[5/10][48/95] Loss_D: 1.2733 Loss_G: 0.8572 D(x): 0.5664 D(G(z)): 0.4851 / 0.4325\n",
      "[5/10][49/95] Loss_D: 1.3244 Loss_G: 1.2214 D(x): 0.6181 D(G(z)): 0.5592 / 0.3058\n",
      "[5/10][50/95] Loss_D: 1.3268 Loss_G: 0.9227 D(x): 0.4242 D(G(z)): 0.3487 / 0.4020\n",
      "[5/10][51/95] Loss_D: 1.2527 Loss_G: 0.9829 D(x): 0.5718 D(G(z)): 0.4832 / 0.3821\n",
      "[5/10][52/95] Loss_D: 1.1358 Loss_G: 1.3370 D(x): 0.6213 D(G(z)): 0.4646 / 0.2759\n",
      "[5/10][53/95] Loss_D: 1.2611 Loss_G: 1.0849 D(x): 0.5054 D(G(z)): 0.4005 / 0.3597\n",
      "[5/10][54/95] Loss_D: 1.3323 Loss_G: 1.1247 D(x): 0.5577 D(G(z)): 0.4968 / 0.3504\n",
      "[5/10][55/95] Loss_D: 1.3262 Loss_G: 0.8541 D(x): 0.4636 D(G(z)): 0.3913 / 0.4436\n",
      "[5/10][56/95] Loss_D: 1.2936 Loss_G: 1.2245 D(x): 0.5947 D(G(z)): 0.5056 / 0.3062\n",
      "[5/10][57/95] Loss_D: 1.1737 Loss_G: 1.4720 D(x): 0.5635 D(G(z)): 0.4315 / 0.2384\n",
      "[5/10][58/95] Loss_D: 1.2021 Loss_G: 0.8488 D(x): 0.4422 D(G(z)): 0.2816 / 0.4320\n",
      "[5/10][59/95] Loss_D: 0.9730 Loss_G: 0.7662 D(x): 0.5650 D(G(z)): 0.3153 / 0.4712\n",
      "[5/10][60/95] Loss_D: 1.8976 Loss_G: 2.1777 D(x): 0.8557 D(G(z)): 0.8183 / 0.1211\n",
      "[5/10][61/95] Loss_D: 1.7068 Loss_G: 0.8750 D(x): 0.2629 D(G(z)): 0.2313 / 0.4221\n",
      "[5/10][62/95] Loss_D: 1.6211 Loss_G: 0.4565 D(x): 0.4860 D(G(z)): 0.5724 / 0.6367\n",
      "[5/10][63/95] Loss_D: 1.6105 Loss_G: 1.0227 D(x): 0.6709 D(G(z)): 0.6933 / 0.3633\n",
      "[5/10][64/95] Loss_D: 1.4214 Loss_G: 0.7935 D(x): 0.4128 D(G(z)): 0.3905 / 0.4554\n",
      "[5/10][65/95] Loss_D: 1.3042 Loss_G: 0.7920 D(x): 0.5641 D(G(z)): 0.4986 / 0.4555\n",
      "[5/10][66/95] Loss_D: 1.3734 Loss_G: 0.9952 D(x): 0.5171 D(G(z)): 0.4923 / 0.3869\n",
      "[5/10][67/95] Loss_D: 1.1556 Loss_G: 1.1495 D(x): 0.5361 D(G(z)): 0.4000 / 0.3442\n",
      "[5/10][68/95] Loss_D: 1.2567 Loss_G: 1.1215 D(x): 0.5418 D(G(z)): 0.4544 / 0.3371\n",
      "[5/10][69/95] Loss_D: 1.1761 Loss_G: 0.7851 D(x): 0.5068 D(G(z)): 0.3688 / 0.4653\n",
      "[5/10][70/95] Loss_D: 1.1013 Loss_G: 0.9618 D(x): 0.6423 D(G(z)): 0.4663 / 0.3885\n",
      "[5/10][71/95] Loss_D: 1.2531 Loss_G: 1.6696 D(x): 0.6878 D(G(z)): 0.5449 / 0.1910\n",
      "[5/10][72/95] Loss_D: 1.2277 Loss_G: 0.8635 D(x): 0.4070 D(G(z)): 0.2562 / 0.4257\n",
      "[5/10][73/95] Loss_D: 1.1966 Loss_G: 1.0623 D(x): 0.6349 D(G(z)): 0.5132 / 0.3478\n",
      "[5/10][74/95] Loss_D: 1.2448 Loss_G: 1.2145 D(x): 0.5425 D(G(z)): 0.4577 / 0.2985\n",
      "[5/10][75/95] Loss_D: 1.2184 Loss_G: 1.0453 D(x): 0.4822 D(G(z)): 0.3635 / 0.3554\n",
      "[5/10][76/95] Loss_D: 1.3448 Loss_G: 1.0977 D(x): 0.5652 D(G(z)): 0.5261 / 0.3382\n",
      "[5/10][77/95] Loss_D: 1.2407 Loss_G: 1.8241 D(x): 0.5925 D(G(z)): 0.4951 / 0.1714\n",
      "[5/10][78/95] Loss_D: 1.9142 Loss_G: 0.5038 D(x): 0.2329 D(G(z)): 0.2682 / 0.6158\n",
      "[5/10][79/95] Loss_D: 1.6357 Loss_G: 1.5121 D(x): 0.6927 D(G(z)): 0.7039 / 0.2370\n",
      "[5/10][80/95] Loss_D: 1.6179 Loss_G: 0.8931 D(x): 0.3256 D(G(z)): 0.3141 / 0.4228\n",
      "[5/10][81/95] Loss_D: 1.2171 Loss_G: 1.1930 D(x): 0.6390 D(G(z)): 0.5126 / 0.3111\n",
      "[5/10][82/95] Loss_D: 0.9620 Loss_G: 1.6306 D(x): 0.6458 D(G(z)): 0.3949 / 0.2008\n",
      "[5/10][83/95] Loss_D: 1.2532 Loss_G: 1.3740 D(x): 0.6018 D(G(z)): 0.4974 / 0.2628\n",
      "[5/10][84/95] Loss_D: 1.1639 Loss_G: 0.7214 D(x): 0.4900 D(G(z)): 0.3285 / 0.4938\n",
      "[5/10][85/95] Loss_D: 1.5760 Loss_G: 0.7910 D(x): 0.5576 D(G(z)): 0.6113 / 0.4588\n",
      "[5/10][86/95] Loss_D: 1.0927 Loss_G: 1.5496 D(x): 0.6840 D(G(z)): 0.4950 / 0.2188\n",
      "[5/10][87/95] Loss_D: 1.0353 Loss_G: 1.1957 D(x): 0.5569 D(G(z)): 0.3425 / 0.3113\n",
      "[5/10][88/95] Loss_D: 1.4340 Loss_G: 2.3677 D(x): 0.7507 D(G(z)): 0.6540 / 0.1048\n",
      "[5/10][89/95] Loss_D: 1.8228 Loss_G: 0.4691 D(x): 0.2363 D(G(z)): 0.1870 / 0.6335\n",
      "[5/10][90/95] Loss_D: 2.1482 Loss_G: 1.3619 D(x): 0.8543 D(G(z)): 0.8322 / 0.2660\n",
      "[5/10][91/95] Loss_D: 1.4384 Loss_G: 1.2893 D(x): 0.4041 D(G(z)): 0.3497 / 0.2867\n",
      "[5/10][92/95] Loss_D: 1.2908 Loss_G: 0.7601 D(x): 0.5017 D(G(z)): 0.4264 / 0.4721\n",
      "[5/10][93/95] Loss_D: 1.3113 Loss_G: 0.9760 D(x): 0.6017 D(G(z)): 0.5392 / 0.3815\n",
      "[5/10][94/95] Loss_D: 1.6613 Loss_G: 2.0885 D(x): 0.5406 D(G(z)): 0.6471 / 0.1454\n",
      "[6/10][0/95] Loss_D: 2.1414 Loss_G: 0.8007 D(x): 0.1789 D(G(z)): 0.2060 / 0.4803\n",
      "[6/10][1/95] Loss_D: 1.4616 Loss_G: 1.0067 D(x): 0.6761 D(G(z)): 0.6438 / 0.3781\n",
      "[6/10][2/95] Loss_D: 1.3174 Loss_G: 1.7556 D(x): 0.5028 D(G(z)): 0.4548 / 0.1830\n",
      "[6/10][3/95] Loss_D: 1.7710 Loss_G: 0.5636 D(x): 0.2653 D(G(z)): 0.2924 / 0.5835\n",
      "[6/10][4/95] Loss_D: 1.7454 Loss_G: 1.4307 D(x): 0.6663 D(G(z)): 0.6958 / 0.2521\n",
      "[6/10][5/95] Loss_D: 1.2623 Loss_G: 1.2133 D(x): 0.4197 D(G(z)): 0.3006 / 0.3039\n",
      "[6/10][6/95] Loss_D: 0.9435 Loss_G: 1.3362 D(x): 0.6773 D(G(z)): 0.4124 / 0.2779\n",
      "[6/10][7/95] Loss_D: 0.9222 Loss_G: 1.4927 D(x): 0.6825 D(G(z)): 0.4010 / 0.2440\n",
      "[6/10][8/95] Loss_D: 0.8688 Loss_G: 1.4941 D(x): 0.6746 D(G(z)): 0.3515 / 0.2371\n",
      "[6/10][9/95] Loss_D: 1.0016 Loss_G: 1.3804 D(x): 0.6410 D(G(z)): 0.4078 / 0.2612\n",
      "[6/10][10/95] Loss_D: 1.2069 Loss_G: 1.2970 D(x): 0.5780 D(G(z)): 0.4520 / 0.2816\n",
      "[6/10][11/95] Loss_D: 1.4496 Loss_G: 1.2834 D(x): 0.5009 D(G(z)): 0.4886 / 0.2819\n",
      "[6/10][12/95] Loss_D: 1.4440 Loss_G: 1.0460 D(x): 0.4954 D(G(z)): 0.4658 / 0.3586\n",
      "[6/10][13/95] Loss_D: 1.4138 Loss_G: 1.7379 D(x): 0.6072 D(G(z)): 0.5759 / 0.1868\n",
      "[6/10][14/95] Loss_D: 1.7893 Loss_G: 0.8570 D(x): 0.3185 D(G(z)): 0.3962 / 0.4306\n",
      "[6/10][15/95] Loss_D: 1.3700 Loss_G: 1.2279 D(x): 0.5563 D(G(z)): 0.5137 / 0.3016\n",
      "[6/10][16/95] Loss_D: 1.2407 Loss_G: 1.7823 D(x): 0.6206 D(G(z)): 0.5076 / 0.1854\n",
      "[6/10][17/95] Loss_D: 1.2153 Loss_G: 1.0689 D(x): 0.4510 D(G(z)): 0.3101 / 0.3516\n",
      "[6/10][18/95] Loss_D: 1.7794 Loss_G: 2.3514 D(x): 0.7254 D(G(z)): 0.7569 / 0.1091\n",
      "[6/10][19/95] Loss_D: 2.0653 Loss_G: 0.7349 D(x): 0.1862 D(G(z)): 0.2380 / 0.4876\n",
      "[6/10][20/95] Loss_D: 1.8194 Loss_G: 1.3790 D(x): 0.5702 D(G(z)): 0.6944 / 0.2601\n",
      "[6/10][21/95] Loss_D: 1.2050 Loss_G: 1.7839 D(x): 0.5645 D(G(z)): 0.4483 / 0.1724\n",
      "[6/10][22/95] Loss_D: 1.3302 Loss_G: 1.0026 D(x): 0.4321 D(G(z)): 0.3477 / 0.3749\n",
      "[6/10][23/95] Loss_D: 1.1967 Loss_G: 1.1379 D(x): 0.5991 D(G(z)): 0.4794 / 0.3266\n",
      "[6/10][24/95] Loss_D: 1.3794 Loss_G: 2.5584 D(x): 0.7026 D(G(z)): 0.6228 / 0.0814\n",
      "[6/10][25/95] Loss_D: 1.7715 Loss_G: 0.6706 D(x): 0.2252 D(G(z)): 0.1261 / 0.5151\n",
      "[6/10][26/95] Loss_D: 2.0705 Loss_G: 2.2106 D(x): 0.8136 D(G(z)): 0.8346 / 0.1154\n",
      "[6/10][27/95] Loss_D: 1.7877 Loss_G: 1.0811 D(x): 0.2310 D(G(z)): 0.1292 / 0.3522\n",
      "[6/10][28/95] Loss_D: 1.3286 Loss_G: 0.8583 D(x): 0.5949 D(G(z)): 0.5154 / 0.4334\n",
      "[6/10][29/95] Loss_D: 1.2423 Loss_G: 1.3517 D(x): 0.6078 D(G(z)): 0.5101 / 0.2618\n",
      "[6/10][30/95] Loss_D: 1.1235 Loss_G: 1.2786 D(x): 0.5398 D(G(z)): 0.3739 / 0.2809\n",
      "[6/10][31/95] Loss_D: 1.1843 Loss_G: 1.0035 D(x): 0.5551 D(G(z)): 0.4283 / 0.3719\n",
      "[6/10][32/95] Loss_D: 1.4595 Loss_G: 1.2518 D(x): 0.6463 D(G(z)): 0.6332 / 0.2940\n",
      "[6/10][33/95] Loss_D: 1.0306 Loss_G: 1.2952 D(x): 0.5306 D(G(z)): 0.3063 / 0.2809\n",
      "[6/10][34/95] Loss_D: 0.9874 Loss_G: 1.0179 D(x): 0.6043 D(G(z)): 0.3660 / 0.3661\n",
      "[6/10][35/95] Loss_D: 0.9831 Loss_G: 1.4712 D(x): 0.7515 D(G(z)): 0.4924 / 0.2340\n",
      "[6/10][36/95] Loss_D: 0.9554 Loss_G: 1.2518 D(x): 0.5811 D(G(z)): 0.3103 / 0.2936\n",
      "[6/10][37/95] Loss_D: 1.0668 Loss_G: 1.1861 D(x): 0.6421 D(G(z)): 0.4386 / 0.3157\n",
      "[6/10][38/95] Loss_D: 1.2673 Loss_G: 2.2948 D(x): 0.7285 D(G(z)): 0.5945 / 0.1052\n",
      "[6/10][39/95] Loss_D: 1.4337 Loss_G: 0.9840 D(x): 0.3167 D(G(z)): 0.1984 / 0.3855\n",
      "[6/10][40/95] Loss_D: 1.3868 Loss_G: 0.9538 D(x): 0.6225 D(G(z)): 0.5624 / 0.3977\n",
      "[6/10][41/95] Loss_D: 1.4994 Loss_G: 1.0819 D(x): 0.5302 D(G(z)): 0.5431 / 0.3479\n",
      "[6/10][42/95] Loss_D: 1.5050 Loss_G: 0.9003 D(x): 0.4493 D(G(z)): 0.4645 / 0.4129\n",
      "[6/10][43/95] Loss_D: 1.6432 Loss_G: 0.5255 D(x): 0.3075 D(G(z)): 0.3304 / 0.5955\n",
      "[6/10][44/95] Loss_D: 2.0160 Loss_G: 1.4334 D(x): 0.7678 D(G(z)): 0.8156 / 0.2651\n",
      "[6/10][45/95] Loss_D: 1.5491 Loss_G: 1.0459 D(x): 0.3674 D(G(z)): 0.3694 / 0.3556\n",
      "[6/10][46/95] Loss_D: 1.3032 Loss_G: 0.6844 D(x): 0.4516 D(G(z)): 0.3825 / 0.5090\n",
      "[6/10][47/95] Loss_D: 1.2975 Loss_G: 0.9378 D(x): 0.5935 D(G(z)): 0.5190 / 0.3979\n",
      "[6/10][48/95] Loss_D: 1.2398 Loss_G: 1.6365 D(x): 0.6398 D(G(z)): 0.5270 / 0.2069\n",
      "[6/10][49/95] Loss_D: 1.0975 Loss_G: 1.2095 D(x): 0.4431 D(G(z)): 0.2336 / 0.3125\n",
      "[6/10][50/95] Loss_D: 1.0418 Loss_G: 0.9494 D(x): 0.6502 D(G(z)): 0.4468 / 0.3963\n",
      "[6/10][51/95] Loss_D: 1.2048 Loss_G: 1.3015 D(x): 0.6502 D(G(z)): 0.5201 / 0.2836\n",
      "[6/10][52/95] Loss_D: 1.0223 Loss_G: 1.1461 D(x): 0.5658 D(G(z)): 0.3402 / 0.3282\n",
      "[6/10][53/95] Loss_D: 1.4391 Loss_G: 0.7788 D(x): 0.5170 D(G(z)): 0.5198 / 0.4686\n",
      "[6/10][54/95] Loss_D: 1.3936 Loss_G: 1.1445 D(x): 0.5819 D(G(z)): 0.5580 / 0.3249\n",
      "[6/10][55/95] Loss_D: 1.4179 Loss_G: 1.0056 D(x): 0.4653 D(G(z)): 0.4474 / 0.3751\n",
      "[6/10][56/95] Loss_D: 1.3923 Loss_G: 0.7969 D(x): 0.4767 D(G(z)): 0.4558 / 0.4536\n",
      "[6/10][57/95] Loss_D: 1.4706 Loss_G: 1.2553 D(x): 0.5784 D(G(z)): 0.5870 / 0.2900\n",
      "[6/10][58/95] Loss_D: 1.4445 Loss_G: 0.9091 D(x): 0.4037 D(G(z)): 0.3849 / 0.4064\n",
      "[6/10][59/95] Loss_D: 1.2795 Loss_G: 1.4640 D(x): 0.6108 D(G(z)): 0.5289 / 0.2383\n",
      "[6/10][60/95] Loss_D: 1.2814 Loss_G: 1.4374 D(x): 0.5092 D(G(z)): 0.4215 / 0.2514\n",
      "[6/10][61/95] Loss_D: 1.2709 Loss_G: 1.0219 D(x): 0.4819 D(G(z)): 0.3881 / 0.3762\n",
      "[6/10][62/95] Loss_D: 1.2561 Loss_G: 1.3558 D(x): 0.5987 D(G(z)): 0.4944 / 0.2772\n",
      "[6/10][63/95] Loss_D: 1.4103 Loss_G: 1.1487 D(x): 0.5288 D(G(z)): 0.5231 / 0.3211\n",
      "[6/10][64/95] Loss_D: 1.3633 Loss_G: 0.6678 D(x): 0.3955 D(G(z)): 0.3087 / 0.5199\n",
      "[6/10][65/95] Loss_D: 1.2460 Loss_G: 1.4704 D(x): 0.7583 D(G(z)): 0.6092 / 0.2454\n",
      "[6/10][66/95] Loss_D: 1.1929 Loss_G: 1.0463 D(x): 0.4802 D(G(z)): 0.3248 / 0.3641\n",
      "[6/10][67/95] Loss_D: 1.3056 Loss_G: 1.2422 D(x): 0.5999 D(G(z)): 0.5234 / 0.3019\n",
      "[6/10][68/95] Loss_D: 1.2834 Loss_G: 1.5105 D(x): 0.5807 D(G(z)): 0.4992 / 0.2281\n",
      "[6/10][69/95] Loss_D: 1.4300 Loss_G: 0.5866 D(x): 0.3691 D(G(z)): 0.3028 / 0.5610\n",
      "[6/10][70/95] Loss_D: 1.2464 Loss_G: 1.2141 D(x): 0.7528 D(G(z)): 0.6052 / 0.3027\n",
      "[6/10][71/95] Loss_D: 1.0995 Loss_G: 1.6399 D(x): 0.6191 D(G(z)): 0.4422 / 0.2035\n",
      "[6/10][72/95] Loss_D: 1.3055 Loss_G: 0.6618 D(x): 0.3486 D(G(z)): 0.1865 / 0.5209\n",
      "[6/10][73/95] Loss_D: 1.8686 Loss_G: 2.1368 D(x): 0.8936 D(G(z)): 0.8188 / 0.1222\n",
      "[6/10][74/95] Loss_D: 1.7705 Loss_G: 1.1651 D(x): 0.2135 D(G(z)): 0.1098 / 0.3185\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake, converting image to a noise array\n",
    "        kernel = kernel.to(device)\n",
    "        img = F.conv2d(real_cpu, kernel,padding=int(((kernel.shape[3])-1)/2))\n",
    "        img = img+0.02*torch.rand_like(img)\n",
    "        downsampled = F.upsample(img,scale_factor=0.5,mode='bilinear')\n",
    "        #print(downsampled.shape)\n",
    "        #stop\n",
    "        downsampled_1d = downsampled.view([batch_size,nz,1,1])\n",
    "        \n",
    "        fake = netG(downsampled_1d)\n",
    "        label.fill_(fake_label)\n",
    "        fd = fake.detach()\n",
    "        output = netD(fd.float())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, niter, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu,\n",
    "                    '%s/real_samples.png' % outf,\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
    "                    normalize=True)\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ignore below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 1, 1])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7ae1ea8e213a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdownsampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownsampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
    "print(noise.shape)\n",
    "for i, data in enumerate(dataloader, 0):\n",
    "    \n",
    "    img =  data[0].to(device)    \n",
    "    kernel = kernel.to(device)\n",
    "    img = F.conv2d(img, kernel,padding=int(((kernel.shape[3])-1)/2))\n",
    "    img = img+0.01*torch.rand_like(img)\n",
    "    downsampled = F.upsample(img,scale_factor=0.25,mode='bilinear')\n",
    "    d = downsampled.view([64,256,1,1])\n",
    "    stop\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use multichannel Trained GAN\n",
    "\n",
    "last edited: Nov 3rd, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from photutils import create_matching_kernel\n",
    "from skimage.transform import downscale_local_mean\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as pyfits\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import astropy.wcs as wcs\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in GAN generator and trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "ngpu = int(3)\n",
    "nz = int(100)\n",
    "ngf = int(64)\n",
    "ndf = int(64)\n",
    "nc=7\n",
    "\n",
    "\n",
    "class Shoobygen(nn.Module):\n",
    "\n",
    "    def __init__(self,ngpu):\n",
    "        super(Shoobygen, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(nc, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            \n",
    "            nn.ConvTranspose2d( ngf*4, ngf * 8, 3, 3, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 7, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf*4, nc, 4, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        else:\n",
    "            \n",
    "            output = self.main(input)\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        return output1\n",
    "\n",
    "\n",
    "netS = Shoobygen(ngpu).to(device)\n",
    "netS.load_state_dict(torch.load('netG_epoch_999.pth',map_location='cpu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read GOODS-S sample data in seven bands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2941: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f46ccc724bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mimaggge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgalblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlim_hmag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mpashe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from galblend import *\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device(\"cpu\")\n",
    "nc = 7\n",
    "\n",
    "hi_psfs = ['psf_b.fits','psf_v.fits', 'psf_i.fits','psf_i.fits', 'psf_z.fits', 'psf_j.fits', 'psf_h.fits']\n",
    "lo_psfs = ['PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits',\n",
    "           'PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits']\n",
    "\n",
    "kernel = np.zeros((41,41,1,7))\n",
    "for i in range(len(hi_psfs)):\n",
    "    psf = pyfits.getdata('../psfs/'+hi_psfs[i])\n",
    "    psf = downscale_local_mean(psf,(3,3))\n",
    "    psf = psf[7:-8,7:-8]\n",
    "\n",
    "    psf_hsc = pyfits.getdata('../psfs/'+lo_psfs[i])\n",
    "    psf_hsc = psf_hsc[1:42,1:42]    \n",
    "    kern = create_matching_kernel(psf,psf_hsc)\n",
    "    psfh = np.repeat(kern[:,:, np.newaxis], 1, axis=2)\n",
    "    kernel[:,:,:,i] = psfh\n",
    "\n",
    "kernel = torch.Tensor(kernel)\n",
    "kernel = kernel.permute(2,3,0,1)\n",
    "kernel =  kernel.float()\n",
    "kernel = kernel.to(device)\n",
    "\n",
    "tfms = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "imaggge, data = galblend(gals=2, lim_hmag=25, plot_it=False)\n",
    "pashe = np.zeros((1,7,64,64))\n",
    "for chi in range(7):\n",
    "    s = ndimage.rotate(imaggge[chi,:,:],0,mode='nearest',reshape=False)\n",
    "    da = np.arcsinh(s)\n",
    "    pash = (255.0 / (da.max()+0.1) * (da - da.min())).astype(np.uint8)\n",
    "    pashe[0,chi,:,:] = tfms(pash)\n",
    "mm = np.zeros((1,7,64,64))\n",
    "mm[0,...]  = pashe\n",
    "real_cpu = torch.Tensor(mm).float()\n",
    "#im = real_cpu+0.1*torch.rand_like(real_cpu)\n",
    "\n",
    "\n",
    "img2 = torch.tensor(np.zeros((1,7,22,22)))\n",
    "for ch in range(real_cpu.shape[1]):\n",
    "    imagetoconvolv = real_cpu[:,ch,:,:].reshape(-1,1,64,64)\n",
    "    kerneltoconvolv = kernel[:,ch,:,:].reshape(-1,1,41,41)\n",
    "    a = F.conv2d(imagetoconvolv, kerneltoconvolv,padding = 21) ## convolve with kernel\n",
    "    img2[:,ch,:,:] = (F.upsample(a,scale_factor=1/3,mode='bilinear')).reshape(-1,22,22) ### fix pixel scale\n",
    "    img2[:,ch,:,:] = img2[:,ch,:,:]+0.25*torch.rand_like(img2[:,ch,:,:])\n",
    "            \n",
    " \n",
    "    \n",
    "img = img2.view(-1,7,22,22)\n",
    "img = img[:,:,:,:].float()\n",
    "\n",
    "fake = netS(img)\n",
    "print(fake.shape)\n",
    "fd = fake.detach()\n",
    "fd = fd.cpu()\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "filts = ['450nm','606nm','750nm','814nm','850nm','1250nm','1600nm']\n",
    "for i in range(7):\n",
    "        \n",
    "    plt.subplot(4,7,i+1)\n",
    "    plt.imshow(mm[0,i,:,:],origin='lower')\n",
    "    plt.text(10,10,filts[i],color='y',size=16)\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i ==0:\n",
    "        plt.ylabel('High Res',size=20)\n",
    "    \n",
    "    plt.subplot(4,7,7+i+1)\n",
    "    plt.imshow(img[0,i,:,:],origin='lower')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i ==0:\n",
    "        plt.ylabel('Low Res',size=20)   \n",
    "        \n",
    "    plt.subplot(4,7,14+i+1)\n",
    "    plt.imshow((fd[0,i,:,:]),origin='lower')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i ==0:\n",
    "        plt.ylabel('GAN Res',size=20)  \n",
    "        \n",
    "    plt.subplot(4,7,21+i+1)\n",
    "    plt.imshow(real_cpu[0,i,:,:]-fd[0,i,:,:],origin='lower',cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i ==0:\n",
    "        plt.ylabel('Residual',size=20)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "#plt.savefig('../plots/multi.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galblend(gals=2,lim_hmag=24,plot_it=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

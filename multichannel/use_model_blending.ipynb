{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use multichannel Trained GAN\n",
    "\n",
    "last edited: Nov 3rd, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from photutils import create_matching_kernel\n",
    "from skimage.transform import downscale_local_mean\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as pyfits\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import astropy.wcs as wcs\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in GAN generator and trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "ngpu = int(3)\n",
    "nz = int(100)\n",
    "ngf = int(64)\n",
    "ndf = int(64)\n",
    "nc=7\n",
    "\n",
    "\n",
    "class Shoobygen(nn.Module):\n",
    "\n",
    "    def __init__(self,ngpu):\n",
    "        super(Shoobygen, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(nc, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            \n",
    "            nn.ConvTranspose2d( ngf*4, ngf * 8, 3, 3, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 7, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf*4, nc, 4, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        else:\n",
    "            \n",
    "            output = self.main(input)\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        return output1\n",
    "\n",
    "\n",
    "netS = Shoobygen(ngpu).to(device)\n",
    "netS.load_state_dict(torch.load('netG_epoch_800.pth',map_location='cpu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read GOODS-S sample data in seven bands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from galblend import *\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device(\"cpu\")\n",
    "nc = 7\n",
    "\n",
    "hi_psfs = ['psf_b.fits','psf_v.fits', 'psf_i.fits','psf_i.fits', 'psf_z.fits', 'psf_j.fits', 'psf_h.fits']\n",
    "lo_psfs = ['PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits',\n",
    "           'PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits']\n",
    "\n",
    "kernel = np.zeros((41,41,1,7))\n",
    "for i in range(len(hi_psfs)):\n",
    "    psf = pyfits.getdata('../psfs/'+hi_psfs[i])\n",
    "    psf = downscale_local_mean(psf,(3,3))\n",
    "    psf = psf[7:-8,7:-8]\n",
    "\n",
    "    psf_hsc = pyfits.getdata('../psfs/'+lo_psfs[i])\n",
    "    psf_hsc = psf_hsc[1:42,1:42]    \n",
    "    kern = create_matching_kernel(psf,psf_hsc)\n",
    "    psfh = np.repeat(kern[:,:, np.newaxis], 1, axis=2)\n",
    "    kernel[:,:,:,i] = psfh\n",
    "\n",
    "kernel = torch.Tensor(kernel)\n",
    "kernel = kernel.permute(2,3,0,1)\n",
    "kernel =  kernel.float()\n",
    "kernel = kernel.to(device)\n",
    "\n",
    "tfms = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "imaggge, data = galblend(gals=2, lim_hmag=25, plot_it=False)\n",
    "pashe = np.zeros((1,7,64,64))\n",
    "for chi in range(7):\n",
    "    s = ndimage.rotate(imaggge[chi,:,:],0,mode='nearest',reshape=False)\n",
    "    da = np.arcsinh(s)\n",
    "    pash = (255.0 / (da.max()+0.1) * (da - da.min())).astype(np.uint8)\n",
    "    pashe[0,chi,:,:] = tfms(pash)\n",
    "mm = np.zeros((1,7,64,64))\n",
    "mm[0,...]  = pashe\n",
    "real_cpu = torch.Tensor(mm).float()\n",
    "#im = real_cpu+0.1*torch.rand_like(real_cpu)\n",
    "\n",
    "\n",
    "img2 = torch.tensor(np.zeros((1,7,22,22)))\n",
    "for ch in range(real_cpu.shape[1]):\n",
    "    imagetoconvolv = real_cpu[:,ch,:,:].reshape(-1,1,64,64)\n",
    "    kerneltoconvolv = kernel[:,ch,:,:].reshape(-1,1,41,41)\n",
    "    a = F.conv2d(imagetoconvolv, kerneltoconvolv,padding = 21) ## convolve with kernel\n",
    "    img2[:,ch,:,:] = (F.upsample(a,scale_factor=1/3,mode='bilinear')).reshape(-1,22,22) ### fix pixel scale\n",
    "    img2[:,ch,:,:] = img2[:,ch,:,:]+0.25*torch.rand_like(img2[:,ch,:,:])\n",
    "            \n",
    " \n",
    "    \n",
    "img = img2.view(-1,7,22,22)\n",
    "img = img[:,:,:,:].float()\n",
    "\n",
    "fake = netS(img)\n",
    "print(fake.shape)\n",
    "fd = fake.detach()\n",
    "fd = fd.cpu()\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "filts = ['450nm','606nm','750nm','814nm','850nm','1250nm','1600nm']\n",
    "for i in range(7):\n",
    "        \n",
    "    plt.subplot(4,7,i+1)\n",
    "    plt.imshow(mm[0,i,:,:],origin='lower')\n",
    "    plt.text(10,10,filts[i],color='y',size=16)\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i ==0:\n",
    "        plt.ylabel('High Res',size=20)\n",
    "    \n",
    "    plt.subplot(4,7,7+i+1)\n",
    "    plt.imshow(img[0,i,:,:],origin='lower')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i ==0:\n",
    "        plt.ylabel('Low Res',size=20)   \n",
    "        \n",
    "    plt.subplot(4,7,14+i+1)\n",
    "    plt.imshow((fd[0,i,:,:]),origin='lower')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i ==0:\n",
    "        plt.ylabel('GAN Res',size=20)  \n",
    "        \n",
    "    plt.subplot(4,7,21+i+1)\n",
    "    plt.imshow(real_cpu[0,i,:,:]-fd[0,i,:,:],origin='lower',cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i ==0:\n",
    "        plt.ylabel('Residual',size=20)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "#plt.savefig('../plots/multi.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galblend(gals=2,lim_hmag=24,plot_it=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiwavelength GAN architecture\n",
    "Added by Shooby Oct 24th<br>\n",
    "Last edited: Oct 9th<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from photutils import create_matching_kernel\n",
    "\n",
    "from astropy.convolution import convolve_fft as convolve\n",
    "import astropy.io.fits as pyfits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") # If GPU then use \"cuda:0\"\n",
    "ngpu = 3 #number of GPUs to use \n",
    "ngf = 64\n",
    "ndf = 64\n",
    "workers = 8 #number of data loading workers\n",
    "batchSize = 64 #input batch size\n",
    "imageSize = 64 #the height / width of the input image to network\n",
    "\n",
    "nz = 16 #size of the latent z vector\n",
    "niter = 500 #number of epochs to train for\n",
    "lr = 0.001 #learning rate, default=0.0002\n",
    "beta1 = 0.7 #beta1 for adam. default=0.5\n",
    "outf='outputs/' #folder to output images and model checkpoints\n",
    "ngc = 7\n",
    "\n",
    "manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import downscale_local_mean\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "hi_psfs = ['psf_b.fits','psf_v.fits', 'psf_i.fits', 'psf_i.fits', 'psf_z.fits', 'psf_j.fits', 'psf_h.fits']\n",
    "lo_psfs = ['PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits','PSF_subaru_i.fits']\n",
    "\n",
    "kernel = np.zeros((1,7,20,20))\n",
    "for i in range(len(hi_psfs)):\n",
    "    psf = pyfits.getdata('../psfs/'+hi_psfs[i])\n",
    "    psf = downscale_local_mean(psf,(3,3))\n",
    "    psf = psf[8:-8,8:-8]#[22:-22,22:-22]\n",
    "\n",
    "    psf_hsc = pyfits.getdata('../psfs/'+lo_psfs[i])\n",
    "    psf_hsc = psf_hsc[2:42,2:42]\n",
    "\n",
    "    a = create_matching_kernel(psf,psf_hsc)\n",
    "    kernel[0,i,:,:] = a[10:-10,10:-10]\n",
    "kernel = torch.Tensor(kernel)\n",
    "#kernel = kernel.permute(2,3,0,1)\n",
    "kernel =  kernel.float()\n",
    "print(kernel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from galaxy_hdf5loader import galaxydata\n",
    "\n",
    "dataset = galaxydata('Sample.hdf5')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,shuffle=True, num_workers=int(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,shuffle=True, num_workers=int(0))\n",
    "\n",
    "for i in dataloader:\n",
    "    a = (i[0].data.numpy())\n",
    "    stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = plt.hist(a.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(ngc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "#if netD != '':\n",
    "#    netD.load_state_dict(torch.load(netD))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf = 2\n",
    "class Shoobygen(nn.Module):\n",
    "\n",
    "    def __init__(self,ngpu):\n",
    "        super(Shoobygen, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(ngc, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            \n",
    "            nn.ConvTranspose2d( ngf*4, ngf * 8, 3, 3, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 7, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf*4, ngc, 4, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        return output1\n",
    "\n",
    "netS = Shoobygen(ngpu).to(device)\n",
    "netS.apply(weights_init)\n",
    "print(netS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from galaxy_hdf5loader import galaxydata\n",
    "dataset = galaxydata('Sample.hdf5')\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2,shuffle=True, num_workers=int(4))\n",
    "inputs, classes = next(iter(dataloader))  \n",
    "real_cpu = inputs.to('cpu')\n",
    "ajab = real_cpu.detach()\n",
    "ajab2 = ajab.cpu()\n",
    "\n",
    "        \n",
    "kernel = kernel.to(device)\n",
    "img2 = torch.tensor(np.zeros((2,ngc,22,22)))\n",
    "for ch in range(real_cpu.shape[1]):\n",
    "    imagetoconvolv = real_cpu[:,ch,:,:].reshape(-1,1,64,64)\n",
    "    kerneltoconvolv = kernel[:,ch,:,:].reshape(-1,1,20,20)\n",
    "    a = F.conv2d(imagetoconvolv, kerneltoconvolv).data.squeeze()\n",
    "    a = a.reshape(-1,1,45,45)\n",
    "    downsampled = F.upsample(a,scale_factor=1/2,mode='bilinear')\n",
    "    img2[:,ch,...] = downsampled[:,0,:,:]\n",
    "    \n",
    "img = img2.view(-1,ngc,22,22)\n",
    "img = img+0.25*torch.rand_like(img)\n",
    "img = img[:,:,:,:].float()\n",
    "print(img.shape)\n",
    "f = nn.Conv2d(ngc, 1, 4, 1, 0, bias=False)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[0,0,:,:])\n",
    "plt.subplot(1,2,2)\n",
    "b1=f(img)\n",
    "print(b1.shape)\n",
    "c = b1.detach().numpy()\n",
    "plt.imshow(c[0,0,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = nn.ConvTranspose2d( 1,1, 3, 3, 0, bias=False)\n",
    "b2 = f2(b1)\n",
    "print(b2.shape)\n",
    "c = b2.detach().numpy()\n",
    "plt.imshow(c[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = nn.ConvTranspose2d( 1,1, 7, 1, 1, bias=False)\n",
    "b3 = f3(b2)\n",
    "print(b3.shape)\n",
    "c = b3.detach().numpy()\n",
    "plt.imshow(c[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4 = nn.ConvTranspose2d( 1,1, 4, 1, 0, bias=False)\n",
    "b4 = f4(b3)\n",
    "print(b4.shape)\n",
    "c = b4.detach().numpy()\n",
    "plt.imshow(c[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerS = optim.Adam(netS.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "        \n",
    "        real_cpu = real_cpu.float()\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        # train with resampled, lower res, noise added images\n",
    "        kernel = kernel.to(device)\n",
    "        #im = real_cpu+0.25*torch.rand_like(real_cpu)\n",
    "        #downsampled = F.upsample(im,scale_factor=1/3,mode='bilinear')\n",
    "        #downsampled_resh = real_cpu.view(-1,1,64,64)\n",
    "        \n",
    "        img2 = torch.tensor(np.zeros((batch_size,ngc,21,21)))\n",
    "        for ch in range(real_cpu.shape[1]):\n",
    "            imagetoconvolv = real_cpu[:,ch,:,:].reshape(-1,1,64,64)\n",
    "            kerneltoconvolv = kernel[:,ch,:,:].reshape(-1,1,40,40)\n",
    "            img2[:,ch,...] = F.conv2d(imagetoconvolv, kerneltoconvolv,padding=8,stride=2)\n",
    "        img = img2.view(-1,7,21,21)\n",
    "        img = img+0.25*torch.rand_like(img)\n",
    "        img = img[:,:,:,:].float()\n",
    "\n",
    "        fake = netS(img)\n",
    "        label.fill_(fake_label)\n",
    "        fd = fake.detach()\n",
    "        output = netD(fd.float())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netS.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerS.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, niter, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            real_cp = real_cpu[:,3,:,:].reshape(batch_size,1,64,64)        \n",
    "            vutils.save_image(real_cp,'%s/real_samples.png' % outf, normalize=True)\n",
    "            fake = netS(img)\n",
    "            fak = fake[:,3,:,:].reshape(batch_size,1,64,64)\n",
    "            vutils.save_image(fak.detach(),'%s/fake_samples_epoch_%03d.png' % (outf, epoch),normalize=True)\n",
    "            grid = torchvision.utils.make_grid(fak.detach())\n",
    "            \n",
    "    # do checkpointing\n",
    "    torch.save(netS.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))\n",
    "    stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plt.imshow(img[0,4,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

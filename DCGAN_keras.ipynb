{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN with keras \n",
    "\n",
    "What I think would be the optimal choice for my problem! Except that this example is a three color and for now I will only need gray scale?! This example is a modified version of goldesel github bird generation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape\n",
    "from keras.layers import Flatten, BatchNormalization, Dense, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is interesting, how much warning info to be shown. ranging from 0 show all to 3 show almost none\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where we will load the dataset stored in dataset_path. In this script\n",
    "# we will use the Caltech-UCSD Birds-200-2011 dataset which includes 11788\n",
    "# images from 200 different birds. We will feed the images without applying\n",
    "# the provided bounding boxes from the dataset. The data will only be resized\n",
    "# and normalized. Keras ImageDataGenerator will be used for loading the dataset\n",
    "def load_dataset(dataset_path, batch_size, image_shape):\n",
    "    dataset_generator = ImageDataGenerator()\n",
    "    dataset_generator = dataset_generator.flow_from_directory(\n",
    "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "\n",
    "    return dataset_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the discriminator model. This model tries to classify images as real\n",
    "# or fake.\n",
    "def construct_discriminator(image_shape):\n",
    "\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Conv2D(filters=64, kernel_size=(5, 5),\n",
    "                             strides=(2, 2), padding='same',\n",
    "                             data_format='channels_last',\n",
    "                             kernel_initializer='glorot_uniform',\n",
    "                             input_shape=(image_shape)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    discriminator.add(Conv2D(filters=128, kernel_size=(5, 5),\n",
    "                             strides=(2, 2), padding='same',\n",
    "                             data_format='channels_last',\n",
    "                             kernel_initializer='glorot_uniform'))\n",
    "    discriminator.add(BatchNormalization(momentum=0.5))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    discriminator.add(Conv2D(filters=256, kernel_size=(5, 5),\n",
    "                             strides=(2, 2), padding='same',\n",
    "                             data_format='channels_last',\n",
    "                             kernel_initializer='glorot_uniform'))\n",
    "    discriminator.add(BatchNormalization(momentum=0.5))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    discriminator.add(Conv2D(filters=512, kernel_size=(5, 5),\n",
    "                             strides=(2, 2), padding='same',\n",
    "                             data_format='channels_last',\n",
    "                             kernel_initializer='glorot_uniform'))\n",
    "    discriminator.add(BatchNormalization(momentum=0.5))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1))\n",
    "    discriminator.add(Activation('sigmoid'))\n",
    "\n",
    "    optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "    discriminator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=None)\n",
    "\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates the generator model. This model has an input of random noise and\n",
    "# generates an image that will try mislead the discriminator.\n",
    "def construct_generator():\n",
    "\n",
    "    generator = Sequential()\n",
    "\n",
    "    generator.add(Dense(units=4 * 4 * 512,\n",
    "                        kernel_initializer='glorot_uniform',\n",
    "                        input_shape=(1, 1, 100)))\n",
    "    generator.add(Reshape(target_shape=(4, 4, 512)))\n",
    "    generator.add(BatchNormalization(momentum=0.5))\n",
    "    generator.add(Activation('relu'))\n",
    "\n",
    "    generator.add(Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
    "                                  strides=(2, 2), padding='same',\n",
    "                                  data_format='channels_last',\n",
    "                                  kernel_initializer='glorot_uniform'))\n",
    "    generator.add(BatchNormalization(momentum=0.5))\n",
    "    generator.add(Activation('relu'))\n",
    "\n",
    "    generator.add(Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
    "                                  strides=(2, 2), padding='same',\n",
    "                                  data_format='channels_last',\n",
    "                                  kernel_initializer='glorot_uniform'))\n",
    "    generator.add(BatchNormalization(momentum=0.5))\n",
    "    generator.add(Activation('relu'))\n",
    "\n",
    "    generator.add(Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
    "                                  strides=(2, 2), padding='same',\n",
    "                                  data_format='channels_last',\n",
    "                                  kernel_initializer='glorot_uniform'))\n",
    "    generator.add(BatchNormalization(momentum=0.5))\n",
    "    generator.add(Activation('relu'))\n",
    "\n",
    "    generator.add(Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
    "                                  strides=(2, 2), padding='same',\n",
    "                                  data_format='channels_last',\n",
    "                                  kernel_initializer='glorot_uniform'))\n",
    "    generator.add(Activation('tanh'))\n",
    "\n",
    "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
    "    generator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=None)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays a figure of the generated images and saves them in as .png image\n",
    "def save_generated_images(generated_images, epoch, batch_number):\n",
    "\n",
    "    plt.figure(figsize=(8, 8), num=2)\n",
    "    gs1 = gridspec.GridSpec(8, 8)\n",
    "    gs1.update(wspace=0, hspace=0)\n",
    "\n",
    "    for i in range(64):\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        ax1.set_aspect('equal')\n",
    "        image = generated_images[i, :, :, :]\n",
    "        image += 1\n",
    "        image *= 127.5\n",
    "        fig = plt.imshow(image.astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_name = 'generated_images/generatedSamples_epoch' + str(\n",
    "        epoch + 1) + '_batch' + str(batch_number + 1) + '.png'\n",
    "\n",
    "    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
    "    plt.pause(0.0000000001)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main train function\n",
    "def train_dcgan(batch_size, epochs, image_shape, dataset_path):\n",
    "    # Build the adversarial model that consists in the generator output\n",
    "    # connected to the discriminator\n",
    "    generator = construct_generator()\n",
    "    discriminator = construct_discriminator(image_shape)\n",
    "\n",
    "    gan = Sequential()\n",
    "    # Only false for the adversarial model\n",
    "    discriminator.trainable = False\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "\n",
    "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                metrics=None)\n",
    "\n",
    "    # Create a dataset Generator with help of keras\n",
    "    dataset_generator = load_dataset(dataset_path, batch_size, image_shape)\n",
    "\n",
    "    # 11788 is the total number of images on the bird dataset\n",
    "    number_of_batches = int(11788 / batch_size)\n",
    "\n",
    "    # Variables that will be used to plot the losses from the discriminator and\n",
    "    # the adversarial models\n",
    "    adversarial_loss = np.empty(shape=1)\n",
    "    discriminator_loss = np.empty(shape=1)\n",
    "    batches = np.empty(shape=1)\n",
    "\n",
    "    # Allo plot updates inside for loop\n",
    "    plt.ion()\n",
    "\n",
    "    current_batch = 0\n",
    "\n",
    "    # Let's train the DCGAN for n epochs\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(\"Epoch \" + str(epoch+1) + \"/\" + str(epochs) + \" :\")\n",
    "\n",
    "        for batch_number in range(number_of_batches):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Get the current batch and normalize the images between -1 and 1\n",
    "            real_images = dataset_generator.next()\n",
    "            real_images /= 127.5\n",
    "            real_images -= 1\n",
    "\n",
    "            # The last batch is smaller than the other ones, so we need to\n",
    "            # take that into account\n",
    "            current_batch_size = real_images.shape[0]\n",
    "\n",
    "            # Generate noise\n",
    "            noise = np.random.normal(0, 1,\n",
    "                                     size=(current_batch_size,) + (1, 1, 100))\n",
    "\n",
    "            # Generate images\n",
    "            generated_images = generator.predict(noise)\n",
    "\n",
    "            # Add some noise to the labels that will be\n",
    "            # fed to the discriminator\n",
    "            real_y = (np.ones(current_batch_size) -\n",
    "                      np.random.random_sample(current_batch_size) * 0.2)\n",
    "            fake_y = np.random.random_sample(current_batch_size) * 0.2\n",
    "\n",
    "            # Let's train the discriminator\n",
    "            discriminator.trainable = True\n",
    "\n",
    "            d_loss = discriminator.train_on_batch(real_images, real_y)\n",
    "            d_loss += discriminator.train_on_batch(generated_images, fake_y)\n",
    "\n",
    "            discriminator_loss = np.append(discriminator_loss, d_loss)\n",
    "\n",
    "            # Now it's time to train the generator\n",
    "            discriminator.trainable = False\n",
    "\n",
    "            noise = np.random.normal(0, 1,\n",
    "                                     size=(current_batch_size * 2,) +\n",
    "                                     (1, 1, 100))\n",
    "\n",
    "            # We try to mislead the discriminator by giving the opposite labels\n",
    "            fake_y = (np.ones(current_batch_size * 2) -\n",
    "                      np.random.random_sample(current_batch_size * 2) * 0.2)\n",
    "\n",
    "            g_loss = gan.train_on_batch(noise, fake_y)\n",
    "            adversarial_loss = np.append(adversarial_loss, g_loss)\n",
    "            batches = np.append(batches, current_batch)\n",
    "\n",
    "            # Each 50 batches show and save images\n",
    "            if((batch_number + 1) % 50 == 0 and\n",
    "               current_batch_size == batch_size):\n",
    "                save_generated_images(generated_images, epoch, batch_number)\n",
    "\n",
    "            time_elapsed = time.time() - start_time\n",
    "\n",
    "            # Display and plot the results\n",
    "            print(\"     Batch \" + str(batch_number + 1) + \"/\" +\n",
    "                  str(number_of_batches) +\n",
    "                  \" generator loss | discriminator loss : \" +\n",
    "                  str(g_loss) + \" | \" + str(d_loss) + ' - batch took ' +\n",
    "                  str(time_elapsed) + ' s.')\n",
    "\n",
    "            current_batch += 1\n",
    "\n",
    "        # Save the model weights each 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            discriminator.trainable = True\n",
    "            generator.save('models/generator_epoch' + str(epoch) + '.hdf5')\n",
    "            discriminator.save('models/discriminator_epoch' +\n",
    "                               str(epoch) + '.hdf5')\n",
    "\n",
    "        # Each epoch update the loss graphs\n",
    "        plt.figure(1)\n",
    "        plt.plot(batches, adversarial_loss, color='green',\n",
    "                 label='Generator Loss')\n",
    "        plt.plot(batches, discriminator_loss, color='blue',\n",
    "                 label='Discriminator Loss')\n",
    "        plt.title(\"DCGAN Train\")\n",
    "        plt.xlabel(\"Batch Iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        if epoch == 0:\n",
    "            plt.legend()\n",
    "        plt.pause(0.0000000001)\n",
    "        plt.show()\n",
    "        plt.savefig('trainingLossPlot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 images belonging to 1 classes.\n",
      "Epoch 1/100 :\n",
      "WARNING:tensorflow:From /Users/shemmati/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_5_input to have shape (50, 50, 3) but got array with shape (64, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ad4a167f5fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_dcgan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-21ba8bb4d116>\u001b[0m in \u001b[0;36mtrain_dcgan\u001b[0;34m(batch_size, epochs, image_shape, dataset_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0md_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mdiscriminator_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_5_input to have shape (50, 50, 3) but got array with shape (64, 64, 3)"
     ]
    }
   ],
   "source": [
    "dataset_path = 'images/'\n",
    "batch_size = 60\n",
    "image_shape = (50, 50, 3)\n",
    "epochs = 100\n",
    "train_dcgan(batch_size, epochs, image_shape, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

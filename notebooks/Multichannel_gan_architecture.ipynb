{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiwavelength GAN architecture\n",
    "Added by Shooby Oct 24th<br>\n",
    "Last edited: Oct 30th<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from photutils import create_matching_kernel\n",
    "\n",
    "from astropy.convolution import convolve_fft as convolve\n",
    "import astropy.io.fits as pyfits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11422dcd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") # If GPU then use \"cuda:0\"\n",
    "ngpu = 3 #number of GPUs to use \n",
    "ngf = 64\n",
    "ndf = 64\n",
    "workers = 8 #number of data loading workers\n",
    "batchSize = 64 #input batch size\n",
    "imageSize = 64 #the height / width of the input image to network\n",
    "\n",
    "nz = 16 #size of the latent z vector\n",
    "niter = 5 #number of epochs to train for\n",
    "lr = 0.001 #learning rate, default=0.0002\n",
    "beta1 = 0.7 #beta1 for adam. default=0.5\n",
    "outf='../outputs' #folder to output images and model checkpoints\n",
    "ngc = 7\n",
    "\n",
    "manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 43)\n",
      "(40, 40)\n",
      "(40, 40)\n",
      "torch.Size([1, 1, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import downscale_local_mean\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "psf = pyfits.getdata('../psfs/psf_i.fits')\n",
    "psf = downscale_local_mean(psf,(3,3))\n",
    "psf = psf[8:-8,8:-8]#[22:-22,22:-22]\n",
    "\n",
    "\n",
    "psf_hsc = pyfits.getdata('../psfs/PSF_subaru_i.fits')\n",
    "psf_hsc = psf_hsc[2:42,2:42]\n",
    "print(psf_hsc.shape)\n",
    "\n",
    "kern = create_matching_kernel(psf,psf_hsc)\n",
    "print(kern.shape)\n",
    "\n",
    "psfh = np.repeat(kern[:,:, np.newaxis], 1, axis=2)\n",
    "psfh = np.repeat(psfh[:,:,:,np.newaxis],1,axis = 3)\n",
    "kernel = torch.Tensor(psfh)\n",
    "kernel = kernel.permute(2,3,0,1)\n",
    "kernel =  kernel.float()\n",
    "print(kernel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2de26860>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(kern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from galaxy_hdf5loader import galaxydata\n",
    "\n",
    "dataset = galaxydata('../Sample.hdf5')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,shuffle=True, num_workers=int(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-842447854a52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,shuffle=True, num_workers=int(0))\n",
    "\n",
    "for i in dataloader:\n",
    "    a = (i[0].data.numpy())\n",
    "    stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAQ+ElEQVR4nO3df6zddX3H8edLKs5NHUUKIuCqW11kJENtgM04URQKJoKJbJg5qiHrophs2Y+sm0tYYCbookaiY7LZUJYpoFNpBFYrg7AZqpTBQGDaigyuNLSuyCRkKvO9P87n6rF82nt6f5xzkOcjOTnf8z6f7/f7Pueentf5/jinqSokSdrbMybdgCRpOhkQkqQuA0KS1GVASJK6DAhJUteySTcwX4cddlitXLly0m1I0lPKbbfd9u2qWjHK2KdsQKxcuZJt27ZNug1JekpJ8l+jjnUXkySpy4CQJHUZEJKkLgNCktRlQEiSugwISVKXASFJ6jIgJEldBoQkqesp+03qhVi5/tqJrPf+i984kfVK0ny4BSFJ6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVKXASFJ6jIgJEldBoQkqcuAkCR1GRCSpK45AyLJMUluTHJvkruT/H6rH5pkS5Lt7Xp5qyfJJUl2JLkzySuGlrW2jd+eZO1Q/ZVJ7mrzXJIkS/FgJUmjG2UL4gngj6rqZcBJwPlJjgXWAzdU1SrghnYb4HRgVbusAy6FQaAAFwAnAicAF8yGShuzbmi+NQt/aJKkhZgzIKpqZ1X9e5v+LnAvcBRwJrCxDdsInNWmzwSuqIGtwCFJjgROA7ZU1Z6qegTYAqxp9z2vqm6pqgKuGFqWJGlCDugYRJKVwMuBLwNHVNVOGIQIcHgbdhTw4NBsM622v/pMp95b/7ok25Js271794G0Lkk6QCMHRJLnAP8E/EFV/c/+hnZqNY/6k4tVl1XV6qpavWLFirlaliQtwEgBkeSZDMLhH6vqM638cNs9RLve1eozwDFDsx8NPDRH/ehOXZI0QaOcxRTg48C9VfXBobs2AbNnIq0Frhmqn9vOZjoJeLTtgtoMnJpkeTs4fSqwud333SQntXWdO7QsSdKELBthzKuA3wHuSnJHq/05cDFwdZLzgAeAs9t91wFnADuAx4F3AFTVniQXAbe2cRdW1Z42/U7gcuDZwPXtIkmaoDkDoqr+jf5xAoBTOuMLOH8fy9oAbOjUtwHHzdWLJGl8/Ca1JKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVKXASFJ6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHXNGRBJNiTZleSrQ7W/TPKtJHe0yxlD9/1Zkh1JvpbktKH6mlbbkWT9UP3FSb6cZHuSq5IcvJgPUJI0P6NsQVwOrOnUP1RVx7fLdQBJjgXOAX6lzfM3SQ5KchDwUeB04FjgrW0swPvaslYBjwDnLeQBSZIWx5wBUVU3A3tGXN6ZwJVV9b2q+iawAzihXXZU1X1V9X3gSuDMJAFeB3y6zb8ROOsAH4MkaQks5BjEu5Pc2XZBLW+1o4AHh8bMtNq+6s8HvlNVT+xV70qyLsm2JNt27969gNYlSXOZb0BcCvwicDywE/hAq6cztuZR76qqy6pqdVWtXrFixYF1LEk6IMvmM1NVPTw7neTvgM+3mzPAMUNDjwYeatO9+reBQ5Isa1sRw+MlSRM0ry2IJEcO3XwzMHuG0ybgnCTPSvJiYBXwFeBWYFU7Y+lgBgeyN1VVATcCb2nzrwWumU9PkqTFNecWRJJPAicDhyWZAS4ATk5yPIPdQfcDvwdQVXcnuRq4B3gCOL+q/q8t593AZuAgYENV3d1W8afAlUn+Crgd+PiiPTpJ0rzNGRBV9dZOeZ9v4lX1XuC9nfp1wHWd+n0MznKSJE0Rv0ktSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVKXASFJ6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpa86ASLIhya4kXx2qHZpkS5Lt7Xp5qyfJJUl2JLkzySuG5lnbxm9Psnao/sokd7V5LkmSxX6QkqQDN8oWxOXAmr1q64EbqmoVcEO7DXA6sKpd1gGXwiBQgAuAE4ETgAtmQ6WNWTc0397rkiRNwJwBUVU3A3v2Kp8JbGzTG4GzhupX1MBW4JAkRwKnAVuqak9VPQJsAda0+55XVbdUVQFXDC1LkjRB8z0GcURV7QRo14e3+lHAg0PjZlptf/WZTr0rybok25Js27179zxblySNYrEPUveOH9Q86l1VdVlVra6q1StWrJhni5KkUcw3IB5uu4do17tafQY4Zmjc0cBDc9SP7tQlSRM234DYBMyeibQWuGaofm47m+kk4NG2C2ozcGqS5e3g9KnA5nbfd5Oc1M5eOndoWZKkCVo214AknwROBg5LMsPgbKSLgauTnAc8AJzdhl8HnAHsAB4H3gFQVXuSXATc2sZdWFWzB77fyeBMqWcD17eLJGnC5gyIqnrrPu46pTO2gPP3sZwNwIZOfRtw3Fx9SJLGy29SS5K6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVKXASFJ6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVLXggIiyf1J7kpyR5JtrXZoki1Jtrfr5a2eJJck2ZHkziSvGFrO2jZ+e5K1C3tIkqTFsBhbEK+tquOranW7vR64oapWATe02wCnA6vaZR1wKQwCBbgAOBE4AbhgNlQkSZOzFLuYzgQ2tumNwFlD9StqYCtwSJIjgdOALVW1p6oeAbYAa5agL0nSAVhoQBTwhSS3JVnXakdU1U6Adn14qx8FPDg070yr7av+JEnWJdmWZNvu3bsX2LokaX+WLXD+V1XVQ0kOB7Yk+c/9jE2nVvupP7lYdRlwGcDq1au7YyRJi2NBWxBV9VC73gV8lsExhIfbriPa9a42fAY4Zmj2o4GH9lOXJE3QvAMiyc8lee7sNHAq8FVgEzB7JtJa4Jo2vQk4t53NdBLwaNsFtRk4NcnydnD61FaTJE3QQnYxHQF8Nsnscj5RVf+c5Fbg6iTnAQ8AZ7fx1wFnADuAx4F3AFTVniQXAbe2cRdW1Z4F9CVJWgTzDoiqug/41U79v4FTOvUCzt/HsjYAG+bbiyRp8flNaklSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1LXQ32LSAVi5/tqJrfv+i984sXVLempyC0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVKXASFJ6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1LVs0g1oPFauv3Yi673/4jdOZL2SFs4tCElS19RsQSRZA3wYOAj4+6q6eMItaRFMassF3HqRFmoqAiLJQcBHgTcAM8CtSTZV1T2T7UxPZe5WkxZmKgICOAHYUVX3ASS5EjgTMCD0lDPJrSaNz9Phg8C0BMRRwINDt2eAE/celGQdsK7dfCzJ1+a5vsOAb89z3nGY5v6muTeY7v6muTewvwOS9/3EzanqrWO4v18YdaZpCYh0avWkQtVlwGULXlmyrapWL3Q5S2Wa+5vm3mC6+5vm3sD+FmKae4P59zctZzHNAMcM3T4aeGhCvUiSmJ6AuBVYleTFSQ4GzgE2TbgnSXpam4pdTFX1RJJ3A5sZnOa6oaruXsJVLng31RKb5v6muTeY7v6muTewv4WY5t5gnv2l6km7+iVJmppdTJKkKWNASJK6nhYBkeTsJHcn+WGSfZ7qlWRNkq8l2ZFk/Rj7OzTJliTb2/XyfYx7f3sc9ya5JEnv9OBJ9faiJF9ovd2TZOVS93Yg/bWxz0vyrSQfmZbekhyf5Jb2d70zyW+Noa/9vs6TPCvJVe3+L4/rbzlib3/YXl93Jrkhycjn9I+jv6Fxb0lS+3u/mURvSX6zPX93J/nEnAutqp/6C/Ay4JeBm4DV+xhzEPAN4CXAwcB/AMeOqb/3A+vb9HrgfZ0xvw58qfV5EHALcPI09Nbuuwl4Q5t+DvCz0/LcDY39MPAJ4CPT0hvwUmBVm34hsBM4ZAl7mvN1DrwL+Ns2fQ5w1Zier1F6e+3sawt457h6G7W/Nu65wM3A1n2930zouVsF3A4sb7cPn2u5T4stiKq6t6rm+tb1j37uo6q+D8z+3Mc4nAlsbNMbgbM6Ywr4GQZ//GcBzwQenobekhwLLKuqLQBV9VhVPT6G3kbqDyDJK4EjgC+MqS8Yobeq+npVbW/TDwG7gBVL2NMor/Phvj8NnDKOrdVRequqG4deW1sZfGdqXEZ9j7iIwYeD/52y3n4X+GhVPQJQVbvmWujTIiBG1Pu5j6PGtO4jqmonQLs+fO8BVXULcCODT5g7gc1Vde809MbgU/B3knwmye1J/rr9AOM4zNlfkmcAHwD+ZEw9jdzbsCQnMPgA8I0l7GmU1/mPxlTVE8CjwPOXsKcD6W3YecD1S9rRT5qzvyQvB46pqs+PsS8Y7bl7KfDSJF9KsrX9gvZ+TcX3IBZDki8CL+jc9Z6qumaURXRqi3YO8P76G3H+X2Kwq2z2E9OWJL9RVTdPujcGr6NXAy8HHgCuAt4OfHyhvS1Sf+8CrquqBxf7g/Ai9Da7nCOBfwDWVtUPF6O3fa2qU9v7db6k/xb2Y+T1JnkbsBp4zZJ2tNdqO7Uf9dc+iHyIwWt/3EZ57pYx2M10MoP3kX9NclxVfWdfC/2pCYiqev0CF7GkP/exv/6SPJzkyKra2d4oept+bwa2VtVjbZ7rgZMY7OucdG8zwO3141/j/VzrbVECYhH6+zXg1UnexeD4yMFJHquqBZ+IsAi9keR5wLXAX1TV1oX2NIdRXuezY2aSLAN+HtizxH2N2htJXs8ggF9TVd8bQ1+z5urvucBxwE3tg8gLgE1J3lRV2ybc2+yYrVX1A+CbGfzY6SoGv2TR5S6mH5vkz31sAta26bVAb4vnAeA1SZYleSaDT07j2MU0Sm+3AsuTzO47fx3j+6n2Ofurqt+uqhdV1Urgj4ErFiMcFqO39lr7bOvpU2PoaZTX+XDfbwH+pdpRzUn31nbhfAx40yj70MfZX1U9WlWHVdXK9lrb2vpc6nCYs7fmcwwO8pPkMAa7nO7b71LHcYR90hcGn75ngO8xOLC7udVfyGDXw+y4M4CvM9gH/J4x9vd84AZge7s+tNVXM/jf9WBwlsLHGITCPcAHp6W3dvsNwJ3AXcDlwMHT1N/Q+LczvrOYRvm7vg34AXDH0OX4Je7rSa9z4EIGb2YwOBniU8AO4CvAS8bxfI3Y2xfbv+HZ52rTuHobpb+9xt7EmM5iGvG5C/DB9v5xF3DOXMv0pzYkSV3uYpIkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV3/D2stGGx5xaXSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = plt.hist(a.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(7, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(ngc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "#if netD != '':\n",
    "#    netD.load_state_dict(torch.load(netD))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoobygen(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(7, 256, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): ConvTranspose2d(256, 512, kernel_size=(6, 6), stride=(3, 3), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(256, 7, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (10): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Shoobygen(nn.Module):\n",
    "\n",
    "    def __init__(self,ngpu):\n",
    "        super(Shoobygen, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(ngc, ngf * 4, 7, 2, 2, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            \n",
    "            nn.ConvTranspose2d( ngf*4, ngf * 8, 6, 3, 2,dilation=2, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 3, 2, 2, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "  \n",
    "            nn.ConvTranspose2d(ngf*4, ngc, 4, 1, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        return output1\n",
    "\n",
    "netS = Shoobygen(ngpu).to(device)\n",
    "netS.apply(weights_init)\n",
    "print(netS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/5][0/3156] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "0\n",
      "[0/5][1/3156] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[0/5][2/3156] Loss_D: 14.1506 Loss_G: 45.9639 D(x): 1.0000 D(G(z)): 1.0000 / 0.0000\n",
      "[0/5][3/3156] Loss_D: 0.0000 Loss_G: 44.8239 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/5][4/3156] Loss_D: 0.0000 Loss_G: 50.4888 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/5][5/3156] Loss_D: 0.0000 Loss_G: 55.5693 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/5][6/3156] Loss_D: 0.0005 Loss_G: 57.6712 D(x): 0.9995 D(G(z)): 0.0000 / 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4abadd5947db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0merrD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0merrD_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mD_G_z1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0merrD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrD_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0merrD_fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerS = optim.Adam(netS.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "        \n",
    "        real_cpu = real_cpu.float()\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        # train with resampled, lower res, noise added images\n",
    "        kernel = kernel.to(device)\n",
    "        #im = real_cpu+0.25*torch.rand_like(real_cpu)\n",
    "        #downsampled = F.upsample(im,scale_factor=1/3,mode='bilinear')\n",
    "        downsampled_resh = real_cpu.view(-1,1,64,64)\n",
    "        img2 = F.conv2d(downsampled_resh, kernel,padding=8,stride=2)\n",
    "        img = img2.view(-1,7,21,21)\n",
    "        img = img+0.25*torch.rand_like(img)\n",
    "        img = img[:,:,:,:]\n",
    "\n",
    "        fake = netS(img)\n",
    "        label.fill_(fake_label)\n",
    "        fd = fake.detach()\n",
    "        output = netD(fd.float())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netS.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerS.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, niter, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            real_cp = real_cpu[:,3,:,:].reshape(batch_size,1,64,64)        \n",
    "            vutils.save_image(real_cp,'%s/real_samples.png' % outf, normalize=True)\n",
    "            fake = netS(img)\n",
    "            fak = fake[:,3,:,:].reshape(batch_size,1,66,66)\n",
    "            vutils.save_image(fak.detach(),'%s/fake_samples_epoch_%03d.png' % (outf, epoch),normalize=True)\n",
    "            grid = torchvision.utils.make_grid(fak.detach())\n",
    "            \n",
    "    # do checkpointing\n",
    "    torch.save(netS.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))\n",
    "    stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a trained GAN on galsim test objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import galsim\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from photutils import create_matching_kernel\n",
    "\n",
    "import astropy.io.fits as pyfits\n",
    "import numpy as np\n",
    "\n",
    "from skimage.transform import downscale_local_mean\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galsim_clumpy_disk(maxclumps,plot_it = 'yes'):\n",
    "    '''Returns a 64*64 image array of a disk galaxy similar to HST ACS'''\n",
    "    random_seed = np.random.randint(1,10000)\n",
    "    sky_level = 1.e6*np.abs(np.random.normal(1,0.02))     # ADU / arcsec^2\n",
    "    pixel_scale = 0.06                                   # arcsec / pixel  (size units in input catalog are pixels)\n",
    "    gal_flux = 1.e6*np.abs(np.random.normal(1,10))       # arbitrary choice, makes nice (not too) noisy images\n",
    "    gal_g1 = np.random.normal(0.01,0.02)                \n",
    "    gal_g2 = np.random.normal(0.01,0.02)                   \n",
    "\n",
    "\n",
    "    bulge_frac       = np.abs(np.random.normal(0.1,0.05))\n",
    "    disk_frac        = 1.0 - bulge_frac\n",
    "    knot_frac        = np.abs(np.random.normal(0.3,0.05))\n",
    "    smooth_disk_frac = disk_frac-knot_frac\n",
    "    n_knots = np.abs(np.random.randint(1,maxclumps))\n",
    "    hlr = np.abs(np.random.normal(0.3,0.1))\n",
    "    hlr_knots = np.abs(hlr - np.abs(np.random.normal(0.08,0.02)))\n",
    "    hlr_bulge = np.abs(np.random.normal(0.05,0.03))\n",
    "\n",
    "    rng = galsim.BaseDeviate(random_seed+1)\n",
    "    psf = galsim.Moffat(beta=3.5, fwhm=0.2, trunc=5.70)\n",
    "\n",
    "\n",
    "    smooth_disk = galsim.Exponential(flux=smooth_disk_frac, half_light_radius=hlr)\n",
    "    knots = galsim.RandomWalk(n_knots, half_light_radius=hlr_knots, flux=knot_frac, rng=rng)\n",
    "    disk = galsim.Add([smooth_disk, knots])\n",
    "    disk = disk.shear(e1=np.random.uniform(-0.5,0.5), e2=np.random.uniform(-0.5,0.5))\n",
    "    bulge = galsim.DeVaucouleurs(flux=bulge_frac, half_light_radius=hlr_bulge)\n",
    "    bulge = bulge.shear(e1=np.random.normal(0.0,0.1), e2=np.random.normal(0,0.1))\n",
    "    gal = galsim.Add([disk, bulge])\n",
    "    gal = gal.withFlux(gal_flux)\n",
    "    gal = gal.shear(g1=gal_g1, g2=gal_g2)\n",
    "\n",
    "    final = galsim.Convolve([psf, gal])\n",
    "\n",
    "    # Draw the profile\n",
    "    image = galsim.ImageF(64, 64)\n",
    "    final.drawImage(image, scale=pixel_scale)\n",
    "    image.addNoise(galsim.PoissonNoise(rng, sky_level * pixel_scale**2))\n",
    "    arr = np.log10(image.array)\n",
    "    arr[np.isnan(arr)]=0\n",
    "    if plot_it == 'yes':\n",
    "        plt.imshow(arr,origin='lower')\n",
    "        plt.colorbar()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shemmati/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in log10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.transforms' has no attribute 'normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-720b7f36f76b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'normalize'"
     ]
    }
   ],
   "source": [
    "## making the CUDA Kernel transfering HST to Subaru HSC###\n",
    "\n",
    "im = galsim_clumpy_disk(10,plot_it='no')\n",
    "im = (255.0 / (im.max()+0.5) * (im)).astype(np.uint8)\n",
    "#converting to pytorch tensor with the right size\n",
    "gals = np.repeat(im[:,:, np.newaxis], 1, axis=2)\n",
    "gals = np.repeat(gals[:,:,:,np.newaxis],1,axis = 3)\n",
    "gals =torch.tensor(gals, device=\"cpu\").float()\n",
    "gals = gals.permute(2,3,0,1)\n",
    "\n",
    "#### images need to be normalized before seeing GAN#########\n",
    "# from torchvision import transforms\n",
    "# transforms.normalize(0.5,0.5)(gals)\n",
    "#\n",
    "############################################################\n",
    "\n",
    "\n",
    "\n",
    "nc = 1\n",
    "device = \"cpu\"\n",
    "ngf = 64\n",
    "ngpu = 3\n",
    "\n",
    "class Shoobygen(nn.Module):\n",
    "\n",
    "    def __init__(self,ngpu):\n",
    "        super(Shoobygen, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d( 1, ngf * 8, 4, 1, 2, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 2, 2, 2, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "  \n",
    "            nn.ConvTranspose2d(ngf*4, nc, 2, 2, 4, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "            output1 = output[:,:,:,:]\n",
    "\n",
    "        return output1\n",
    "\n",
    "netS = Shoobygen(ngpu).to(device)\n",
    "netS.load_state_dict(torch.load('netG_epoch_490.pth',map_location='cpu'))\n",
    "\n",
    "### read in an image with HST resoluion and downgrade (resample, PSF convolve, add noise) to HSC \n",
    "inputs = gals\n",
    "real_cpu = inputs.to(device)\n",
    "ajab = real_cpu.detach()\n",
    "\n",
    "\n",
    "## Make Kernel\n",
    "psf = pyfits.getdata('psf_i.fits')\n",
    "psf = downscale_local_mean(psf,(3,3))\n",
    "psf = psf[7:-8,7:-8]#[22:-22,22:-22]\n",
    "\n",
    "psf_hsc = pyfits.getdata('psf-calexp-s16a_wide-HSC-I-15827-7,2-236.00000-42.00000.fits')\n",
    "psf_hsc = psf_hsc[0:41,1:42]\n",
    "\n",
    "kern = create_matching_kernel(psf,psf_hsc)\n",
    "psfh = np.repeat(kern[:,:, np.newaxis], 1, axis=2)\n",
    "psfh = np.repeat(psfh[:,:,:,np.newaxis],1,axis = 3)\n",
    "kernel = torch.Tensor(psfh)\n",
    "kernel = kernel.permute(2,3,0,1)\n",
    "kernel =  kernel.float()\n",
    "kernel = kernel.to(device)\n",
    "\n",
    "## add noise, downsample, convolve with kernel ---> give to GAN\n",
    "im = real_cpu+0.25*torch.rand_like(real_cpu)\n",
    "downsampled = F.upsample(im,scale_factor=1/3,mode='bilinear')\n",
    "img = F.conv2d(downsampled, kernel,padding=int(((kernel.shape[3])-1)/2))\n",
    "img = img[:,:,:,:]\n",
    "\n",
    "fake = netS(img)\n",
    "fd = fake.detach()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(ajab[0,0,:,:],origin='lower')\n",
    "plt.text(1,1,'Original (Galsim)',color='y')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img[0,0,:,:],origin='lower')\n",
    "plt.text(1,1,'downgrade',color='y')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(fd[0,0,:,:],origin='lower')\n",
    "plt.text(1,1,'recovered',color='y')\n",
    "\n",
    "vutils.save_image(fake.detach(),'fake_samples_test.png',normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

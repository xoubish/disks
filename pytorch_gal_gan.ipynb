{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  7709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7faa3c05cbb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing parameters:\n",
    "\n",
    "dataroot='gals/'\n",
    "device = torch.device(\"cuda:0\") # If GPU then use \"cuda:0\"\n",
    "ngpu = 3 #number of GPUs to use \n",
    "nz = 15 #size of the latent z vector\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "workers = 8 #number of data loading workers\n",
    "batchSize = 65 #input batch size\n",
    "imageSize = 64 #the height / width of the input image to network\n",
    "niter = 25 #number of epochs to train for\n",
    "lr = 0.0002 #learning rate, default=0.0002\n",
    "beta1 = 0.5 #beta1 for adam. default=0.5\n",
    "outf='outputs' #folder to output images and model checkpoints\n",
    "\n",
    "\n",
    "manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.MNIST(root=dataroot, download=True,\n",
    "                     transform=transforms.Compose([transforms.Resize(imageSize),transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),]))\n",
    "nc=1\n",
    "\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=int(workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(15, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "netG = Generator(ngpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "#if netG != '':\n",
    "#    netG.load_state_dict(torch.load(netG))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "#if netD != '':\n",
    "#    netD.load_state_dict(torch.load(netD))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 167, 5)\n"
     ]
    }
   ],
   "source": [
    "from astropy.convolution import convolve\n",
    "import astropy.io.fits as pyfits\n",
    "\n",
    "a = torch.randn(64,64,batchSize)\n",
    "c = a.data.numpy()\n",
    "\n",
    "psf_h = pyfits.getdata('psf_h.fits')\n",
    "#psfh_1 = np.repeat(psf_h[:, :, np.newaxis], 1, axis=2)\n",
    "psfh_2 = np.repeat(psf_h[:, :, np.newaxis], batchSize, axis=2)\n",
    "print (np.shape(psfh_2))\n",
    "\n",
    "boz=convolve(c,psfh_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][0/93] Loss_D: 1.9400 Loss_G: 2.3300 D(x): 0.2681 D(G(z)): 0.3709 / 0.1223\n",
      "[0/25][1/93] Loss_D: 2.9866 Loss_G: 3.4683 D(x): 0.9999 D(G(z)): 0.9118 / 0.0638\n",
      "[0/25][2/93] Loss_D: 1.5320 Loss_G: 5.8003 D(x): 1.0000 D(G(z)): 0.7252 / 0.0083\n",
      "[0/25][3/93] Loss_D: 0.4563 Loss_G: 6.2351 D(x): 0.9999 D(G(z)): 0.3342 / 0.0046\n",
      "[0/25][4/93] Loss_D: 0.4660 Loss_G: 6.2992 D(x): 1.0000 D(G(z)): 0.3192 / 0.0038\n",
      "[0/25][5/93] Loss_D: 0.3045 Loss_G: 6.4504 D(x): 1.0000 D(G(z)): 0.2292 / 0.0039\n",
      "[0/25][6/93] Loss_D: 0.2419 Loss_G: 6.8380 D(x): 0.9989 D(G(z)): 0.1964 / 0.0019\n",
      "[0/25][7/93] Loss_D: 0.1630 Loss_G: 6.4835 D(x): 0.9927 D(G(z)): 0.1361 / 0.0026\n",
      "[0/25][8/93] Loss_D: 0.2432 Loss_G: 6.4691 D(x): 0.9801 D(G(z)): 0.1464 / 0.0028\n",
      "[0/25][9/93] Loss_D: 0.1463 Loss_G: 6.6877 D(x): 0.9960 D(G(z)): 0.1249 / 0.0022\n",
      "[0/25][10/93] Loss_D: 0.1511 Loss_G: 6.6518 D(x): 0.9752 D(G(z)): 0.0776 / 0.0021\n",
      "[0/25][11/93] Loss_D: 0.1798 Loss_G: 6.6462 D(x): 0.9642 D(G(z)): 0.0984 / 0.0023\n",
      "[0/25][12/93] Loss_D: 0.1201 Loss_G: 7.1560 D(x): 0.9876 D(G(z)): 0.0949 / 0.0013\n",
      "[0/25][13/93] Loss_D: 0.0644 Loss_G: 7.0593 D(x): 0.9951 D(G(z)): 0.0552 / 0.0016\n",
      "[0/25][14/93] Loss_D: 0.5424 Loss_G: 6.3976 D(x): 0.9098 D(G(z)): 0.0768 / 0.0027\n",
      "[0/25][15/93] Loss_D: 0.1587 Loss_G: 8.1932 D(x): 0.9906 D(G(z)): 0.1271 / 0.0005\n",
      "[0/25][16/93] Loss_D: 0.0568 Loss_G: 7.7756 D(x): 0.9918 D(G(z)): 0.0438 / 0.0008\n",
      "[0/25][17/93] Loss_D: 0.1538 Loss_G: 7.2243 D(x): 0.9802 D(G(z)): 0.0577 / 0.0012\n",
      "[0/25][18/93] Loss_D: 0.0880 Loss_G: 8.0565 D(x): 0.9968 D(G(z)): 0.0771 / 0.0006\n",
      "[0/25][19/93] Loss_D: 0.4549 Loss_G: 6.9067 D(x): 0.9236 D(G(z)): 0.0306 / 0.0014\n",
      "[0/25][20/93] Loss_D: 0.0869 Loss_G: 7.5507 D(x): 0.9876 D(G(z)): 0.0593 / 0.0007\n",
      "[0/25][21/93] Loss_D: 0.0473 Loss_G: 7.6943 D(x): 0.9917 D(G(z)): 0.0364 / 0.0006\n",
      "[0/25][22/93] Loss_D: 0.0433 Loss_G: 7.3847 D(x): 0.9918 D(G(z)): 0.0331 / 0.0008\n",
      "[0/25][23/93] Loss_D: 0.0528 Loss_G: 7.9516 D(x): 0.9981 D(G(z)): 0.0489 / 0.0005\n",
      "[0/25][24/93] Loss_D: 0.6922 Loss_G: 6.6894 D(x): 0.9001 D(G(z)): 0.0249 / 0.0017\n",
      "[0/25][25/93] Loss_D: 0.1010 Loss_G: 9.7178 D(x): 0.9976 D(G(z)): 0.0906 / 0.0001\n",
      "[0/25][26/93] Loss_D: 0.0108 Loss_G: 9.3639 D(x): 0.9936 D(G(z)): 0.0040 / 0.0001\n",
      "[0/25][27/93] Loss_D: 0.0151 Loss_G: 7.3126 D(x): 0.9933 D(G(z)): 0.0079 / 0.0010\n",
      "[0/25][28/93] Loss_D: 0.0527 Loss_G: 7.2496 D(x): 0.9926 D(G(z)): 0.0421 / 0.0009\n",
      "[0/25][29/93] Loss_D: 0.0530 Loss_G: 8.6436 D(x): 0.9978 D(G(z)): 0.0480 / 0.0003\n",
      "[0/25][30/93] Loss_D: 0.0893 Loss_G: 7.5574 D(x): 0.9697 D(G(z)): 0.0110 / 0.0007\n",
      "[0/25][31/93] Loss_D: 0.0784 Loss_G: 7.1816 D(x): 0.9816 D(G(z)): 0.0360 / 0.0009\n",
      "[0/25][32/93] Loss_D: 0.0539 Loss_G: 8.7210 D(x): 0.9976 D(G(z)): 0.0492 / 0.0002\n",
      "[0/25][33/93] Loss_D: 0.0150 Loss_G: 8.1867 D(x): 0.9967 D(G(z)): 0.0115 / 0.0004\n",
      "[0/25][34/93] Loss_D: 0.0270 Loss_G: 7.5057 D(x): 0.9961 D(G(z)): 0.0224 / 0.0008\n",
      "[0/25][35/93] Loss_D: 0.0413 Loss_G: 8.3583 D(x): 0.9984 D(G(z)): 0.0382 / 0.0004\n",
      "[0/25][36/93] Loss_D: 0.0150 Loss_G: 8.1675 D(x): 0.9992 D(G(z)): 0.0141 / 0.0004\n",
      "[0/25][37/93] Loss_D: 0.0945 Loss_G: 6.9509 D(x): 0.9647 D(G(z)): 0.0150 / 0.0014\n",
      "[0/25][38/93] Loss_D: 0.0500 Loss_G: 8.7323 D(x): 0.9963 D(G(z)): 0.0443 / 0.0002\n",
      "[0/25][39/93] Loss_D: 0.0201 Loss_G: 8.1357 D(x): 0.9879 D(G(z)): 0.0070 / 0.0004\n",
      "[0/25][40/93] Loss_D: 0.0218 Loss_G: 7.1147 D(x): 0.9930 D(G(z)): 0.0144 / 0.0010\n",
      "[0/25][41/93] Loss_D: 0.0548 Loss_G: 9.2138 D(x): 0.9926 D(G(z)): 0.0442 / 0.0001\n",
      "[0/25][42/93] Loss_D: 0.0064 Loss_G: 8.9143 D(x): 0.9989 D(G(z)): 0.0053 / 0.0002\n",
      "[0/25][43/93] Loss_D: 0.0211 Loss_G: 7.0801 D(x): 0.9887 D(G(z)): 0.0075 / 0.0011\n",
      "[0/25][44/93] Loss_D: 0.0624 Loss_G: 10.6066 D(x): 0.9974 D(G(z)): 0.0568 / 0.0000\n",
      "[0/25][45/93] Loss_D: 0.0464 Loss_G: 8.7893 D(x): 0.9660 D(G(z)): 0.0015 / 0.0003\n",
      "[0/25][46/93] Loss_D: 0.0101 Loss_G: 6.9992 D(x): 0.9992 D(G(z)): 0.0092 / 0.0017\n",
      "[0/25][47/93] Loss_D: 0.1013 Loss_G: 14.5548 D(x): 0.9990 D(G(z)): 0.0896 / 0.0000\n",
      "[0/25][48/93] Loss_D: 0.0387 Loss_G: 14.6685 D(x): 0.9735 D(G(z)): 0.0000 / 0.0000\n",
      "[0/25][49/93] Loss_D: 0.0459 Loss_G: 11.1084 D(x): 0.9703 D(G(z)): 0.0000 / 0.0000\n",
      "[0/25][50/93] Loss_D: 0.0017 Loss_G: 7.1599 D(x): 0.9999 D(G(z)): 0.0015 / 0.0015\n",
      "[0/25][51/93] Loss_D: 0.0911 Loss_G: 13.7569 D(x): 0.9997 D(G(z)): 0.0839 / 0.0000\n",
      "[0/25][52/93] Loss_D: 0.0610 Loss_G: 13.6103 D(x): 0.9790 D(G(z)): 0.0001 / 0.0000\n",
      "[0/25][53/93] Loss_D: 0.0414 Loss_G: 10.5791 D(x): 0.9771 D(G(z)): 0.0001 / 0.0000\n",
      "[0/25][54/93] Loss_D: 0.0027 Loss_G: 7.0923 D(x): 0.9991 D(G(z)): 0.0018 / 0.0013\n",
      "[0/25][55/93] Loss_D: 0.0712 Loss_G: 13.7132 D(x): 0.9992 D(G(z)): 0.0671 / 0.0000\n",
      "[0/25][56/93] Loss_D: 0.1663 Loss_G: 1.0555 D(x): 0.8819 D(G(z)): 0.0000 / 0.3759\n",
      "[0/25][57/93] Loss_D: 5.6929 Loss_G: 36.5155 D(x): 0.9995 D(G(z)): 0.9958 / 0.0000\n",
      "[0/25][58/93] Loss_D: 18.9212 Loss_G: 32.7549 D(x): 0.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/25][59/93] Loss_D: 0.5584 Loss_G: 29.0803 D(x): 0.8610 D(G(z)): 0.0000 / 0.0000\n",
      "[0/25][60/93] Loss_D: 0.8367 Loss_G: 23.9620 D(x): 0.9146 D(G(z)): 0.0000 / 0.0000\n",
      "[0/25][61/93] Loss_D: 0.0604 Loss_G: 9.7920 D(x): 0.9732 D(G(z)): 0.0002 / 0.0016\n",
      "[0/25][62/93] Loss_D: 6.6212 Loss_G: 24.1055 D(x): 0.9738 D(G(z)): 0.9412 / 0.0000\n",
      "[0/25][63/93] Loss_D: 3.5814 Loss_G: 14.6505 D(x): 0.2471 D(G(z)): 0.0000 / 0.0000\n",
      "[0/25][64/93] Loss_D: 0.3769 Loss_G: 5.8227 D(x): 0.9464 D(G(z)): 0.1006 / 0.0273\n",
      "[0/25][65/93] Loss_D: 4.9361 Loss_G: 21.0617 D(x): 0.9527 D(G(z)): 0.9148 / 0.0000\n",
      "[0/25][66/93] Loss_D: 4.4789 Loss_G: 10.0739 D(x): 0.1150 D(G(z)): 0.0000 / 0.0001\n",
      "[0/25][67/93] Loss_D: 0.7178 Loss_G: 7.5972 D(x): 0.9344 D(G(z)): 0.3618 / 0.0010\n",
      "[0/25][68/93] Loss_D: 1.4798 Loss_G: 18.0482 D(x): 0.9293 D(G(z)): 0.6327 / 0.0000\n",
      "[0/25][69/93] Loss_D: 6.7331 Loss_G: 3.4232 D(x): 0.0147 D(G(z)): 0.0000 / 0.0572\n",
      "[0/25][70/93] Loss_D: 3.7211 Loss_G: 12.6236 D(x): 0.8596 D(G(z)): 0.9161 / 0.0000\n",
      "[0/25][71/93] Loss_D: 2.8063 Loss_G: 4.1722 D(x): 0.2151 D(G(z)): 0.0008 / 0.0200\n",
      "[0/25][72/93] Loss_D: 1.9334 Loss_G: 11.5273 D(x): 0.8872 D(G(z)): 0.7870 / 0.0000\n",
      "[0/25][73/93] Loss_D: 2.1543 Loss_G: 2.8901 D(x): 0.2067 D(G(z)): 0.0016 / 0.0720\n",
      "[0/25][74/93] Loss_D: 2.2396 Loss_G: 10.8445 D(x): 0.9065 D(G(z)): 0.8589 / 0.0000\n",
      "[0/25][75/93] Loss_D: 3.2154 Loss_G: 1.2326 D(x): 0.0606 D(G(z)): 0.0016 / 0.3277\n",
      "[0/25][76/93] Loss_D: 2.8055 Loss_G: 8.9224 D(x): 0.9624 D(G(z)): 0.9289 / 0.0003\n",
      "[0/25][77/93] Loss_D: 1.7768 Loss_G: 3.6447 D(x): 0.2931 D(G(z)): 0.0053 / 0.0419\n",
      "[0/25][78/93] Loss_D: 0.8948 Loss_G: 5.4505 D(x): 0.8720 D(G(z)): 0.4953 / 0.0058\n",
      "[0/25][79/93] Loss_D: 0.6444 Loss_G: 2.8925 D(x): 0.6463 D(G(z)): 0.0943 / 0.0656\n",
      "[0/25][80/93] Loss_D: 1.2781 Loss_G: 8.5400 D(x): 0.8266 D(G(z)): 0.6061 / 0.0003\n",
      "[0/25][81/93] Loss_D: 3.6297 Loss_G: 0.0760 D(x): 0.0997 D(G(z)): 0.0065 / 0.9275\n",
      "[0/25][82/93] Loss_D: 3.6638 Loss_G: 6.6763 D(x): 0.9649 D(G(z)): 0.9705 / 0.0024\n",
      "[0/25][83/93] Loss_D: 1.7799 Loss_G: 2.1835 D(x): 0.2435 D(G(z)): 0.0168 / 0.1461\n",
      "[0/25][84/93] Loss_D: 0.7949 Loss_G: 3.5945 D(x): 0.9131 D(G(z)): 0.4785 / 0.0412\n",
      "[0/25][85/93] Loss_D: 0.5860 Loss_G: 2.7966 D(x): 0.7030 D(G(z)): 0.1558 / 0.0714\n",
      "[0/25][86/93] Loss_D: 0.6307 Loss_G: 2.8767 D(x): 0.7689 D(G(z)): 0.2932 / 0.0623\n",
      "[0/25][87/93] Loss_D: 0.8356 Loss_G: 2.1185 D(x): 0.6308 D(G(z)): 0.2837 / 0.1335\n",
      "[0/25][88/93] Loss_D: 0.9027 Loss_G: 3.5415 D(x): 0.7129 D(G(z)): 0.3958 / 0.0377\n",
      "[0/25][89/93] Loss_D: 0.9969 Loss_G: 0.2406 D(x): 0.4591 D(G(z)): 0.1283 / 0.7883\n",
      "[0/25][90/93] Loss_D: 2.4445 Loss_G: 8.0385 D(x): 0.9631 D(G(z)): 0.9022 / 0.0009\n",
      "[0/25][91/93] Loss_D: 3.9135 Loss_G: 0.6435 D(x): 0.0311 D(G(z)): 0.0047 / 0.5583\n",
      "[0/25][92/93] Loss_D: 1.4694 Loss_G: 3.5298 D(x): 0.9433 D(G(z)): 0.7426 / 0.0488\n",
      "[1/25][0/93] Loss_D: 0.8468 Loss_G: 1.6703 D(x): 0.5331 D(G(z)): 0.1290 / 0.2058\n",
      "[1/25][1/93] Loss_D: 0.7698 Loss_G: 3.2739 D(x): 0.8584 D(G(z)): 0.4385 / 0.0483\n",
      "[1/25][2/93] Loss_D: 1.2874 Loss_G: 0.4976 D(x): 0.3740 D(G(z)): 0.1575 / 0.6302\n",
      "[1/25][3/93] Loss_D: 1.7895 Loss_G: 5.6723 D(x): 0.9021 D(G(z)): 0.7784 / 0.0079\n",
      "[1/25][4/93] Loss_D: 2.4914 Loss_G: 0.8085 D(x): 0.1522 D(G(z)): 0.0286 / 0.5208\n",
      "[1/25][5/93] Loss_D: 1.4931 Loss_G: 2.2756 D(x): 0.8327 D(G(z)): 0.6797 / 0.1491\n",
      "[1/25][6/93] Loss_D: 1.0479 Loss_G: 1.8547 D(x): 0.5782 D(G(z)): 0.2937 / 0.1874\n",
      "[1/25][7/93] Loss_D: 0.7733 Loss_G: 1.8463 D(x): 0.6990 D(G(z)): 0.2886 / 0.1835\n",
      "[1/25][8/93] Loss_D: 0.9301 Loss_G: 1.5752 D(x): 0.6324 D(G(z)): 0.3385 / 0.2252\n",
      "[1/25][9/93] Loss_D: 0.9641 Loss_G: 2.4658 D(x): 0.6846 D(G(z)): 0.3794 / 0.1005\n",
      "[1/25][10/93] Loss_D: 0.7608 Loss_G: 1.2971 D(x): 0.6185 D(G(z)): 0.2121 / 0.3013\n",
      "[1/25][11/93] Loss_D: 1.1532 Loss_G: 4.9544 D(x): 0.8366 D(G(z)): 0.5980 / 0.0097\n",
      "[1/25][12/93] Loss_D: 2.8746 Loss_G: 0.0632 D(x): 0.0909 D(G(z)): 0.0181 / 0.9416\n",
      "[1/25][13/93] Loss_D: 3.4689 Loss_G: 2.7167 D(x): 0.9898 D(G(z)): 0.9491 / 0.0910\n",
      "[1/25][14/93] Loss_D: 0.7134 Loss_G: 2.7157 D(x): 0.6052 D(G(z)): 0.1554 / 0.0816\n",
      "[1/25][15/93] Loss_D: 0.9575 Loss_G: 0.6406 D(x): 0.5042 D(G(z)): 0.1563 / 0.5563\n",
      "[1/25][16/93] Loss_D: 1.2959 Loss_G: 3.5577 D(x): 0.9377 D(G(z)): 0.6776 / 0.0369\n",
      "[1/25][17/93] Loss_D: 1.1048 Loss_G: 1.1954 D(x): 0.4050 D(G(z)): 0.0825 / 0.3220\n",
      "[1/25][18/93] Loss_D: 0.7370 Loss_G: 1.9304 D(x): 0.8214 D(G(z)): 0.3895 / 0.1751\n",
      "[1/25][19/93] Loss_D: 0.8236 Loss_G: 2.5182 D(x): 0.7240 D(G(z)): 0.3390 / 0.0979\n",
      "[1/25][20/93] Loss_D: 1.2135 Loss_G: 0.6621 D(x): 0.4471 D(G(z)): 0.1693 / 0.5418\n",
      "[1/25][21/93] Loss_D: 1.6849 Loss_G: 3.9881 D(x): 0.8607 D(G(z)): 0.7362 / 0.0296\n",
      "[1/25][22/93] Loss_D: 1.5882 Loss_G: 0.9086 D(x): 0.2796 D(G(z)): 0.0524 / 0.4350\n",
      "[1/25][23/93] Loss_D: 1.1897 Loss_G: 2.4102 D(x): 0.8029 D(G(z)): 0.5801 / 0.1086\n",
      "[1/25][24/93] Loss_D: 0.9260 Loss_G: 1.5396 D(x): 0.5521 D(G(z)): 0.2252 / 0.2482\n",
      "[1/25][25/93] Loss_D: 0.9339 Loss_G: 1.6140 D(x): 0.6741 D(G(z)): 0.3743 / 0.2239\n",
      "[1/25][26/93] Loss_D: 0.8997 Loss_G: 2.6501 D(x): 0.7302 D(G(z)): 0.4114 / 0.0869\n",
      "[1/25][27/93] Loss_D: 1.2414 Loss_G: 0.2703 D(x): 0.3800 D(G(z)): 0.1474 / 0.7779\n",
      "[1/25][28/93] Loss_D: 2.0594 Loss_G: 4.3964 D(x): 0.9282 D(G(z)): 0.8331 / 0.0190\n",
      "[1/25][29/93] Loss_D: 1.8456 Loss_G: 0.5997 D(x): 0.2143 D(G(z)): 0.0527 / 0.5934\n",
      "[1/25][30/93] Loss_D: 1.4157 Loss_G: 2.5427 D(x): 0.8774 D(G(z)): 0.6774 / 0.1107\n",
      "[1/25][31/93] Loss_D: 1.0742 Loss_G: 1.2739 D(x): 0.5067 D(G(z)): 0.2131 / 0.3182\n",
      "[1/25][32/93] Loss_D: 0.9634 Loss_G: 2.0124 D(x): 0.7532 D(G(z)): 0.4398 / 0.1571\n",
      "[1/25][33/93] Loss_D: 0.8868 Loss_G: 1.0118 D(x): 0.5685 D(G(z)): 0.2272 / 0.3912\n",
      "[1/25][34/93] Loss_D: 1.4457 Loss_G: 3.6105 D(x): 0.8161 D(G(z)): 0.6640 / 0.0454\n",
      "[1/25][35/93] Loss_D: 2.4226 Loss_G: 0.3773 D(x): 0.1228 D(G(z)): 0.0661 / 0.6983\n",
      "[1/25][36/93] Loss_D: 1.7123 Loss_G: 2.8693 D(x): 0.8642 D(G(z)): 0.7644 / 0.0871\n",
      "[1/25][37/93] Loss_D: 1.5414 Loss_G: 0.6720 D(x): 0.2937 D(G(z)): 0.1635 / 0.5285\n",
      "[1/25][38/93] Loss_D: 1.4916 Loss_G: 2.5097 D(x): 0.7360 D(G(z)): 0.6638 / 0.0926\n",
      "[1/25][39/93] Loss_D: 1.4922 Loss_G: 0.3571 D(x): 0.3055 D(G(z)): 0.1650 / 0.7096\n",
      "[1/25][40/93] Loss_D: 1.7391 Loss_G: 3.4483 D(x): 0.9005 D(G(z)): 0.7775 / 0.0384\n",
      "[1/25][41/93] Loss_D: 1.3842 Loss_G: 0.8049 D(x): 0.2935 D(G(z)): 0.0619 / 0.4577\n",
      "[1/25][42/93] Loss_D: 1.0604 Loss_G: 2.4259 D(x): 0.8868 D(G(z)): 0.5914 / 0.1019\n",
      "[1/25][43/93] Loss_D: 1.1104 Loss_G: 0.8403 D(x): 0.4307 D(G(z)): 0.1800 / 0.4582\n",
      "[1/25][44/93] Loss_D: 1.2348 Loss_G: 2.0497 D(x): 0.7251 D(G(z)): 0.5687 / 0.1515\n",
      "[1/25][45/93] Loss_D: 0.9523 Loss_G: 1.6358 D(x): 0.6018 D(G(z)): 0.2742 / 0.2256\n",
      "[1/25][46/93] Loss_D: 0.9968 Loss_G: 0.8432 D(x): 0.5706 D(G(z)): 0.3166 / 0.4656\n",
      "[1/25][47/93] Loss_D: 1.2155 Loss_G: 3.1732 D(x): 0.7895 D(G(z)): 0.5902 / 0.0599\n",
      "[1/25][48/93] Loss_D: 1.6262 Loss_G: 0.2410 D(x): 0.2702 D(G(z)): 0.0961 / 0.7979\n",
      "[1/25][49/93] Loss_D: 2.2255 Loss_G: 3.1465 D(x): 0.9508 D(G(z)): 0.8614 / 0.0638\n",
      "[1/25][50/93] Loss_D: 1.5981 Loss_G: 0.9922 D(x): 0.2908 D(G(z)): 0.0889 / 0.4034\n",
      "[1/25][51/93] Loss_D: 0.9582 Loss_G: 1.1800 D(x): 0.7671 D(G(z)): 0.4719 / 0.3222\n",
      "[1/25][52/93] Loss_D: 0.8104 Loss_G: 2.2024 D(x): 0.7604 D(G(z)): 0.3994 / 0.1217\n",
      "[1/25][53/93] Loss_D: 0.8863 Loss_G: 1.1289 D(x): 0.5623 D(G(z)): 0.2101 / 0.3698\n",
      "[1/25][54/93] Loss_D: 1.5683 Loss_G: 2.1835 D(x): 0.6405 D(G(z)): 0.5298 / 0.1273\n",
      "[1/25][55/93] Loss_D: 1.0404 Loss_G: 0.9442 D(x): 0.5085 D(G(z)): 0.2505 / 0.4051\n",
      "[1/25][56/93] Loss_D: 1.1706 Loss_G: 2.6037 D(x): 0.7215 D(G(z)): 0.5353 / 0.0818\n",
      "[1/25][57/93] Loss_D: 1.3025 Loss_G: 0.3362 D(x): 0.3521 D(G(z)): 0.1505 / 0.7232\n",
      "[1/25][58/93] Loss_D: 1.7957 Loss_G: 4.2916 D(x): 0.9060 D(G(z)): 0.7956 / 0.0166\n",
      "[1/25][59/93] Loss_D: 1.6811 Loss_G: 1.1199 D(x): 0.2381 D(G(z)): 0.0395 / 0.3358\n",
      "[1/25][60/93] Loss_D: 0.9405 Loss_G: 1.3783 D(x): 0.7409 D(G(z)): 0.4355 / 0.2648\n",
      "[1/25][61/93] Loss_D: 0.9348 Loss_G: 2.6758 D(x): 0.7475 D(G(z)): 0.4447 / 0.0859\n",
      "[1/25][62/93] Loss_D: 0.9348 Loss_G: 1.1462 D(x): 0.5246 D(G(z)): 0.1824 / 0.3366\n",
      "[1/25][63/93] Loss_D: 1.0282 Loss_G: 1.7572 D(x): 0.7081 D(G(z)): 0.4684 / 0.1894\n",
      "[1/25][64/93] Loss_D: 1.3454 Loss_G: 0.6597 D(x): 0.4442 D(G(z)): 0.3580 / 0.5315\n",
      "[1/25][65/93] Loss_D: 1.4671 Loss_G: 2.6385 D(x): 0.7106 D(G(z)): 0.6545 / 0.0965\n",
      "[1/25][66/93] Loss_D: 1.7765 Loss_G: 0.2234 D(x): 0.2306 D(G(z)): 0.1380 / 0.8122\n",
      "[1/25][67/93] Loss_D: 2.0205 Loss_G: 3.0794 D(x): 0.9195 D(G(z)): 0.8334 / 0.0662\n",
      "[1/25][68/93] Loss_D: 1.1556 Loss_G: 1.7100 D(x): 0.4468 D(G(z)): 0.0828 / 0.2134\n",
      "[1/25][69/93] Loss_D: 0.9830 Loss_G: 0.6802 D(x): 0.6178 D(G(z)): 0.3366 / 0.5322\n",
      "[1/25][70/93] Loss_D: 1.2511 Loss_G: 2.6923 D(x): 0.8438 D(G(z)): 0.6312 / 0.0864\n",
      "[1/25][71/93] Loss_D: 1.2646 Loss_G: 0.7500 D(x): 0.3537 D(G(z)): 0.0984 / 0.4891\n",
      "[1/25][72/93] Loss_D: 1.0705 Loss_G: 1.7938 D(x): 0.8189 D(G(z)): 0.5622 / 0.1787\n",
      "[1/25][73/93] Loss_D: 1.0833 Loss_G: 1.1111 D(x): 0.5303 D(G(z)): 0.2799 / 0.3522\n",
      "[1/25][74/93] Loss_D: 1.0831 Loss_G: 1.6102 D(x): 0.6873 D(G(z)): 0.4707 / 0.2158\n",
      "[1/25][75/93] Loss_D: 1.0047 Loss_G: 0.8649 D(x): 0.5333 D(G(z)): 0.2615 / 0.4315\n",
      "[1/25][76/93] Loss_D: 1.1076 Loss_G: 2.0537 D(x): 0.7496 D(G(z)): 0.5382 / 0.1398\n",
      "[1/25][77/93] Loss_D: 0.9606 Loss_G: 1.1764 D(x): 0.5383 D(G(z)): 0.1954 / 0.3191\n",
      "[1/25][78/93] Loss_D: 1.0323 Loss_G: 1.3494 D(x): 0.6564 D(G(z)): 0.4315 / 0.2688\n",
      "[1/25][79/93] Loss_D: 0.9697 Loss_G: 1.3739 D(x): 0.6182 D(G(z)): 0.3664 / 0.2603\n",
      "[1/25][80/93] Loss_D: 0.9677 Loss_G: 1.2449 D(x): 0.6090 D(G(z)): 0.3440 / 0.2956\n",
      "[1/25][81/93] Loss_D: 1.0458 Loss_G: 0.8377 D(x): 0.5647 D(G(z)): 0.3470 / 0.4402\n",
      "[1/25][82/93] Loss_D: 1.1863 Loss_G: 2.3943 D(x): 0.7142 D(G(z)): 0.5572 / 0.1018\n",
      "[1/25][83/93] Loss_D: 1.3532 Loss_G: 0.2675 D(x): 0.3255 D(G(z)): 0.1440 / 0.7695\n",
      "[1/25][84/93] Loss_D: 1.7187 Loss_G: 3.1946 D(x): 0.9168 D(G(z)): 0.7917 / 0.0524\n",
      "[1/25][85/93] Loss_D: 1.6018 Loss_G: 0.5429 D(x): 0.2482 D(G(z)): 0.0928 / 0.5940\n",
      "[1/25][86/93] Loss_D: 1.2370 Loss_G: 1.7970 D(x): 0.8059 D(G(z)): 0.6102 / 0.1783\n",
      "[1/25][87/93] Loss_D: 0.9644 Loss_G: 0.9725 D(x): 0.5204 D(G(z)): 0.2364 / 0.3884\n",
      "[1/25][88/93] Loss_D: 1.0389 Loss_G: 1.8382 D(x): 0.7369 D(G(z)): 0.5061 / 0.1781\n",
      "[1/25][89/93] Loss_D: 1.0451 Loss_G: 0.6565 D(x): 0.4750 D(G(z)): 0.2315 / 0.5333\n",
      "[1/25][90/93] Loss_D: 1.2212 Loss_G: 2.4164 D(x): 0.8187 D(G(z)): 0.6211 / 0.1129\n",
      "[1/25][91/93] Loss_D: 1.3637 Loss_G: 0.3544 D(x): 0.3416 D(G(z)): 0.1716 / 0.7134\n",
      "[1/25][92/93] Loss_D: 1.7953 Loss_G: 3.5469 D(x): 0.9017 D(G(z)): 0.8041 / 0.0351\n",
      "[2/25][0/93] Loss_D: 2.1240 Loss_G: 0.4481 D(x): 0.1495 D(G(z)): 0.0674 / 0.6472\n",
      "[2/25][1/93] Loss_D: 1.5492 Loss_G: 2.2677 D(x): 0.8292 D(G(z)): 0.7227 / 0.1248\n",
      "[2/25][2/93] Loss_D: 1.3422 Loss_G: 0.6797 D(x): 0.3638 D(G(z)): 0.1950 / 0.5189\n",
      "[2/25][3/93] Loss_D: 1.3145 Loss_G: 2.0394 D(x): 0.7331 D(G(z)): 0.6132 / 0.1392\n",
      "[2/25][4/93] Loss_D: 1.0305 Loss_G: 1.2910 D(x): 0.5146 D(G(z)): 0.2237 / 0.2858\n",
      "[2/25][5/93] Loss_D: 1.0635 Loss_G: 1.2972 D(x): 0.6021 D(G(z)): 0.3983 / 0.2855\n",
      "[2/25][6/93] Loss_D: 1.2490 Loss_G: 1.1338 D(x): 0.5392 D(G(z)): 0.4469 / 0.3415\n",
      "[2/25][7/93] Loss_D: 0.8161 Loss_G: 2.0172 D(x): 0.7122 D(G(z)): 0.3514 / 0.1459\n",
      "[2/25][8/93] Loss_D: 1.0319 Loss_G: 0.5630 D(x): 0.4860 D(G(z)): 0.2100 / 0.5775\n",
      "[2/25][9/93] Loss_D: 1.3431 Loss_G: 3.3161 D(x): 0.8380 D(G(z)): 0.6733 / 0.0478\n",
      "[2/25][10/93] Loss_D: 1.8012 Loss_G: 0.3730 D(x): 0.2252 D(G(z)): 0.0656 / 0.6984\n",
      "[2/25][11/93] Loss_D: 1.7533 Loss_G: 2.3751 D(x): 0.9008 D(G(z)): 0.7828 / 0.1247\n",
      "[2/25][12/93] Loss_D: 1.4180 Loss_G: 0.6505 D(x): 0.3371 D(G(z)): 0.1574 / 0.5408\n",
      "[2/25][13/93] Loss_D: 1.1518 Loss_G: 1.7829 D(x): 0.8255 D(G(z)): 0.5905 / 0.1959\n",
      "[2/25][14/93] Loss_D: 0.8965 Loss_G: 1.3783 D(x): 0.6047 D(G(z)): 0.2898 / 0.2742\n",
      "[2/25][15/93] Loss_D: 1.1122 Loss_G: 1.1448 D(x): 0.6244 D(G(z)): 0.4118 / 0.3360\n",
      "[2/25][16/93] Loss_D: 1.2581 Loss_G: 1.7985 D(x): 0.6352 D(G(z)): 0.5307 / 0.1798\n",
      "[2/25][17/93] Loss_D: 1.6691 Loss_G: 0.4149 D(x): 0.3285 D(G(z)): 0.3445 / 0.6669\n",
      "[2/25][18/93] Loss_D: 1.6032 Loss_G: 3.7154 D(x): 0.7903 D(G(z)): 0.7181 / 0.0314\n",
      "[2/25][19/93] Loss_D: 2.1944 Loss_G: 0.2859 D(x): 0.1255 D(G(z)): 0.0581 / 0.7564\n",
      "[2/25][20/93] Loss_D: 1.7748 Loss_G: 2.4447 D(x): 0.9009 D(G(z)): 0.7842 / 0.0957\n",
      "[2/25][21/93] Loss_D: 1.2255 Loss_G: 1.1081 D(x): 0.4069 D(G(z)): 0.2041 / 0.3457\n",
      "[2/25][22/93] Loss_D: 1.1068 Loss_G: 1.8271 D(x): 0.6895 D(G(z)): 0.4965 / 0.1675\n",
      "[2/25][23/93] Loss_D: 0.9211 Loss_G: 1.7028 D(x): 0.5974 D(G(z)): 0.2941 / 0.1918\n",
      "[2/25][24/93] Loss_D: 1.3866 Loss_G: 0.5483 D(x): 0.4184 D(G(z)): 0.3384 / 0.5881\n",
      "[2/25][25/93] Loss_D: 1.5892 Loss_G: 2.5873 D(x): 0.7320 D(G(z)): 0.7050 / 0.0904\n",
      "[2/25][26/93] Loss_D: 1.8685 Loss_G: 0.3028 D(x): 0.2022 D(G(z)): 0.1243 / 0.7488\n",
      "[2/25][27/93] Loss_D: 1.7372 Loss_G: 2.2020 D(x): 0.8799 D(G(z)): 0.7813 / 0.1385\n",
      "[2/25][28/93] Loss_D: 1.1467 Loss_G: 1.0836 D(x): 0.4216 D(G(z)): 0.1759 / 0.3564\n",
      "[2/25][29/93] Loss_D: 1.0493 Loss_G: 1.1856 D(x): 0.7086 D(G(z)): 0.4807 / 0.3172\n",
      "[2/25][30/93] Loss_D: 0.9333 Loss_G: 1.7273 D(x): 0.6974 D(G(z)): 0.4214 / 0.1866\n",
      "[2/25][31/93] Loss_D: 1.0837 Loss_G: 0.7107 D(x): 0.4805 D(G(z)): 0.2659 / 0.4989\n",
      "[2/25][32/93] Loss_D: 1.2641 Loss_G: 2.5169 D(x): 0.8024 D(G(z)): 0.6307 / 0.0927\n",
      "[2/25][33/93] Loss_D: 1.6420 Loss_G: 0.5937 D(x): 0.2863 D(G(z)): 0.1976 / 0.5582\n",
      "[2/25][34/93] Loss_D: 1.3651 Loss_G: 2.0352 D(x): 0.7343 D(G(z)): 0.6371 / 0.1519\n",
      "[2/25][35/93] Loss_D: 1.1827 Loss_G: 1.3221 D(x): 0.4812 D(G(z)): 0.2489 / 0.2813\n",
      "[2/25][36/93] Loss_D: 1.1681 Loss_G: 0.7601 D(x): 0.5250 D(G(z)): 0.3767 / 0.4739\n",
      "[2/25][37/93] Loss_D: 1.1636 Loss_G: 3.2627 D(x): 0.8074 D(G(z)): 0.5980 / 0.0409\n",
      "[2/25][38/93] Loss_D: 2.1159 Loss_G: 0.2568 D(x): 0.1508 D(G(z)): 0.0597 / 0.7820\n",
      "[2/25][39/93] Loss_D: 2.3576 Loss_G: 1.8275 D(x): 0.9232 D(G(z)): 0.8614 / 0.1680\n",
      "[2/25][40/93] Loss_D: 1.3113 Loss_G: 0.9869 D(x): 0.3650 D(G(z)): 0.2197 / 0.3806\n",
      "[2/25][41/93] Loss_D: 1.0463 Loss_G: 1.3716 D(x): 0.6929 D(G(z)): 0.4781 / 0.2730\n",
      "[2/25][42/93] Loss_D: 1.1732 Loss_G: 1.2328 D(x): 0.5569 D(G(z)): 0.4166 / 0.3149\n",
      "[2/25][43/93] Loss_D: 1.2243 Loss_G: 0.7902 D(x): 0.5043 D(G(z)): 0.3880 / 0.4799\n",
      "[2/25][44/93] Loss_D: 1.1237 Loss_G: 2.0340 D(x): 0.6966 D(G(z)): 0.5167 / 0.1480\n",
      "[2/25][45/93] Loss_D: 1.2379 Loss_G: 0.4285 D(x): 0.3943 D(G(z)): 0.2289 / 0.6672\n",
      "[2/25][46/93] Loss_D: 1.6492 Loss_G: 3.3076 D(x): 0.8686 D(G(z)): 0.7630 / 0.0439\n",
      "[2/25][47/93] Loss_D: 2.0707 Loss_G: 0.3797 D(x): 0.1472 D(G(z)): 0.0666 / 0.6936\n",
      "[2/25][48/93] Loss_D: 1.7347 Loss_G: 1.8097 D(x): 0.8760 D(G(z)): 0.7763 / 0.1766\n",
      "[2/25][49/93] Loss_D: 1.1634 Loss_G: 1.2685 D(x): 0.4628 D(G(z)): 0.2756 / 0.2989\n",
      "[2/25][50/93] Loss_D: 1.0847 Loss_G: 1.1871 D(x): 0.6082 D(G(z)): 0.4174 / 0.3174\n",
      "[2/25][51/93] Loss_D: 1.3619 Loss_G: 0.8963 D(x): 0.4684 D(G(z)): 0.4106 / 0.4157\n",
      "[2/25][52/93] Loss_D: 1.1281 Loss_G: 1.5468 D(x): 0.6555 D(G(z)): 0.4862 / 0.2209\n",
      "[2/25][53/93] Loss_D: 1.3154 Loss_G: 0.5560 D(x): 0.3883 D(G(z)): 0.2876 / 0.5819\n",
      "[2/25][54/93] Loss_D: 1.5127 Loss_G: 1.8652 D(x): 0.7278 D(G(z)): 0.6723 / 0.1690\n",
      "[2/25][55/93] Loss_D: 1.1667 Loss_G: 0.7847 D(x): 0.4079 D(G(z)): 0.1866 / 0.4609\n",
      "[2/25][56/93] Loss_D: 1.2815 Loss_G: 1.3094 D(x): 0.6777 D(G(z)): 0.5802 / 0.2862\n",
      "[2/25][57/93] Loss_D: 0.9823 Loss_G: 1.4068 D(x): 0.6190 D(G(z)): 0.3498 / 0.2707\n",
      "[2/25][58/93] Loss_D: 0.7878 Loss_G: 1.6066 D(x): 0.7132 D(G(z)): 0.3212 / 0.2280\n",
      "[2/25][59/93] Loss_D: 0.8029 Loss_G: 1.5233 D(x): 0.6934 D(G(z)): 0.3144 / 0.2410\n",
      "[2/25][60/93] Loss_D: 1.1260 Loss_G: 0.9933 D(x): 0.5562 D(G(z)): 0.3944 / 0.3856\n",
      "[2/25][61/93] Loss_D: 1.2734 Loss_G: 1.7117 D(x): 0.6315 D(G(z)): 0.5345 / 0.1975\n",
      "[2/25][62/93] Loss_D: 1.4186 Loss_G: 0.3701 D(x): 0.3418 D(G(z)): 0.2467 / 0.6971\n",
      "[2/25][63/93] Loss_D: 1.6464 Loss_G: 2.7138 D(x): 0.8222 D(G(z)): 0.7522 / 0.0825\n",
      "[2/25][64/93] Loss_D: 1.9516 Loss_G: 0.3306 D(x): 0.1761 D(G(z)): 0.1131 / 0.7267\n",
      "[2/25][65/93] Loss_D: 1.6651 Loss_G: 1.7297 D(x): 0.8516 D(G(z)): 0.7569 / 0.1919\n",
      "[2/25][66/93] Loss_D: 1.1661 Loss_G: 1.1685 D(x): 0.4579 D(G(z)): 0.2758 / 0.3249\n",
      "[2/25][67/93] Loss_D: 0.9798 Loss_G: 1.1739 D(x): 0.6473 D(G(z)): 0.3981 / 0.3262\n",
      "[2/25][68/93] Loss_D: 1.1936 Loss_G: 1.4815 D(x): 0.6055 D(G(z)): 0.4651 / 0.2385\n",
      "[2/25][69/93] Loss_D: 1.2500 Loss_G: 0.5513 D(x): 0.4367 D(G(z)): 0.3194 / 0.5837\n",
      "[2/25][70/93] Loss_D: 1.5067 Loss_G: 1.8224 D(x): 0.7054 D(G(z)): 0.6633 / 0.1742\n",
      "[2/25][71/93] Loss_D: 1.5068 Loss_G: 0.5208 D(x): 0.3290 D(G(z)): 0.2726 / 0.5986\n",
      "[2/25][72/93] Loss_D: 1.1456 Loss_G: 1.6497 D(x): 0.7713 D(G(z)): 0.5775 / 0.2038\n",
      "[2/25][73/93] Loss_D: 1.1281 Loss_G: 0.9521 D(x): 0.4708 D(G(z)): 0.2796 / 0.3973\n",
      "[2/25][74/93] Loss_D: 1.2213 Loss_G: 1.0752 D(x): 0.6014 D(G(z)): 0.4975 / 0.3493\n",
      "[2/25][75/93] Loss_D: 1.1346 Loss_G: 1.3255 D(x): 0.5758 D(G(z)): 0.4242 / 0.2724\n",
      "[2/25][76/93] Loss_D: 1.0749 Loss_G: 1.0200 D(x): 0.5476 D(G(z)): 0.3524 / 0.3652\n",
      "[2/25][77/93] Loss_D: 1.3461 Loss_G: 0.9349 D(x): 0.5247 D(G(z)): 0.4888 / 0.3979\n",
      "[2/25][78/93] Loss_D: 1.0569 Loss_G: 1.9557 D(x): 0.6478 D(G(z)): 0.4427 / 0.1496\n",
      "[2/25][79/93] Loss_D: 1.3848 Loss_G: 0.2260 D(x): 0.3408 D(G(z)): 0.2090 / 0.8020\n",
      "[2/25][80/93] Loss_D: 2.0565 Loss_G: 2.7788 D(x): 0.8680 D(G(z)): 0.8401 / 0.0743\n",
      "[2/25][81/93] Loss_D: 2.1638 Loss_G: 0.4079 D(x): 0.1441 D(G(z)): 0.0886 / 0.6734\n",
      "[2/25][82/93] Loss_D: 1.4307 Loss_G: 1.5053 D(x): 0.8157 D(G(z)): 0.6882 / 0.2339\n",
      "[2/25][83/93] Loss_D: 1.0472 Loss_G: 1.3627 D(x): 0.5376 D(G(z)): 0.3216 / 0.2692\n",
      "[2/25][84/93] Loss_D: 1.2133 Loss_G: 0.5739 D(x): 0.4709 D(G(z)): 0.3397 / 0.5753\n",
      "[2/25][85/93] Loss_D: 1.3450 Loss_G: 1.8954 D(x): 0.7335 D(G(z)): 0.6285 / 0.1717\n",
      "[2/25][86/93] Loss_D: 1.5005 Loss_G: 0.5457 D(x): 0.3563 D(G(z)): 0.3040 / 0.5922\n",
      "[2/25][87/93] Loss_D: 1.1904 Loss_G: 1.2136 D(x): 0.7161 D(G(z)): 0.5561 / 0.3080\n",
      "[2/25][88/93] Loss_D: 1.0745 Loss_G: 1.5161 D(x): 0.6376 D(G(z)): 0.4414 / 0.2299\n",
      "[2/25][89/93] Loss_D: 1.3813 Loss_G: 0.5054 D(x): 0.4102 D(G(z)): 0.3349 / 0.6189\n",
      "[2/25][90/93] Loss_D: 1.6841 Loss_G: 2.3802 D(x): 0.7533 D(G(z)): 0.7352 / 0.1013\n",
      "[2/25][91/93] Loss_D: 1.9452 Loss_G: 0.3595 D(x): 0.1893 D(G(z)): 0.1699 / 0.7112\n",
      "[2/25][92/93] Loss_D: 1.7715 Loss_G: 2.4585 D(x): 0.8277 D(G(z)): 0.7626 / 0.0930\n",
      "[3/25][0/93] Loss_D: 1.6240 Loss_G: 0.6570 D(x): 0.2656 D(G(z)): 0.1746 / 0.5404\n",
      "[3/25][1/93] Loss_D: 1.4687 Loss_G: 1.4398 D(x): 0.6933 D(G(z)): 0.6355 / 0.2417\n",
      "[3/25][2/93] Loss_D: 1.5297 Loss_G: 0.5275 D(x): 0.3411 D(G(z)): 0.3216 / 0.6019\n",
      "[3/25][3/93] Loss_D: 1.4937 Loss_G: 2.0650 D(x): 0.7621 D(G(z)): 0.6893 / 0.1402\n",
      "[3/25][4/93] Loss_D: 1.6687 Loss_G: 0.3748 D(x): 0.2439 D(G(z)): 0.1822 / 0.6956\n",
      "[3/25][5/93] Loss_D: 1.5988 Loss_G: 1.6909 D(x): 0.8100 D(G(z)): 0.7351 / 0.2069\n",
      "[3/25][6/93] Loss_D: 1.2925 Loss_G: 0.8823 D(x): 0.4031 D(G(z)): 0.2772 / 0.4302\n",
      "[3/25][7/93] Loss_D: 1.0343 Loss_G: 1.2786 D(x): 0.6729 D(G(z)): 0.4567 / 0.2909\n",
      "[3/25][8/93] Loss_D: 1.1701 Loss_G: 0.9270 D(x): 0.5289 D(G(z)): 0.3853 / 0.4095\n",
      "[3/25][9/93] Loss_D: 1.1852 Loss_G: 1.2908 D(x): 0.6349 D(G(z)): 0.4942 / 0.2885\n",
      "[3/25][10/93] Loss_D: 1.2440 Loss_G: 0.7957 D(x): 0.4712 D(G(z)): 0.3475 / 0.4569\n",
      "[3/25][11/93] Loss_D: 1.3425 Loss_G: 1.4768 D(x): 0.6287 D(G(z)): 0.5677 / 0.2398\n",
      "[3/25][12/93] Loss_D: 1.3621 Loss_G: 0.5513 D(x): 0.4012 D(G(z)): 0.3265 / 0.5814\n",
      "[3/25][13/93] Loss_D: 1.4436 Loss_G: 2.3078 D(x): 0.7475 D(G(z)): 0.6692 / 0.1146\n",
      "[3/25][14/93] Loss_D: 1.5783 Loss_G: 0.5608 D(x): 0.2751 D(G(z)): 0.1197 / 0.5747\n",
      "[3/25][15/93] Loss_D: 1.4133 Loss_G: 1.2854 D(x): 0.7416 D(G(z)): 0.6597 / 0.2901\n",
      "[3/25][16/93] Loss_D: 1.0726 Loss_G: 1.4075 D(x): 0.5502 D(G(z)): 0.3412 / 0.2535\n",
      "[3/25][17/93] Loss_D: 1.3278 Loss_G: 0.5053 D(x): 0.4201 D(G(z)): 0.3427 / 0.6174\n",
      "[3/25][18/93] Loss_D: 1.4594 Loss_G: 2.0015 D(x): 0.7641 D(G(z)): 0.6684 / 0.1457\n",
      "[3/25][19/93] Loss_D: 1.6053 Loss_G: 0.4459 D(x): 0.2622 D(G(z)): 0.1879 / 0.6650\n",
      "[3/25][20/93] Loss_D: 1.8222 Loss_G: 1.7912 D(x): 0.8306 D(G(z)): 0.7830 / 0.1875\n",
      "[3/25][21/93] Loss_D: 1.1520 Loss_G: 1.3514 D(x): 0.4957 D(G(z)): 0.2547 / 0.2884\n",
      "[3/25][22/93] Loss_D: 1.3313 Loss_G: 0.5413 D(x): 0.4771 D(G(z)): 0.4155 / 0.5923\n",
      "[3/25][23/93] Loss_D: 1.2565 Loss_G: 2.2162 D(x): 0.8098 D(G(z)): 0.6271 / 0.1213\n",
      "[3/25][24/93] Loss_D: 1.6779 Loss_G: 0.3602 D(x): 0.2415 D(G(z)): 0.1609 / 0.7060\n",
      "[3/25][25/93] Loss_D: 1.6409 Loss_G: 1.7920 D(x): 0.8576 D(G(z)): 0.7487 / 0.1740\n",
      "[3/25][26/93] Loss_D: 1.5326 Loss_G: 0.7873 D(x): 0.3203 D(G(z)): 0.2844 / 0.4702\n",
      "[3/25][27/93] Loss_D: 1.1598 Loss_G: 1.7960 D(x): 0.7647 D(G(z)): 0.5624 / 0.1766\n",
      "[3/25][28/93] Loss_D: 1.5119 Loss_G: 0.4902 D(x): 0.2990 D(G(z)): 0.2263 / 0.6231\n",
      "[3/25][29/93] Loss_D: 1.4895 Loss_G: 1.2720 D(x): 0.7043 D(G(z)): 0.6610 / 0.2924\n",
      "[3/25][30/93] Loss_D: 1.2715 Loss_G: 1.1710 D(x): 0.4820 D(G(z)): 0.3984 / 0.3182\n",
      "[3/25][31/93] Loss_D: 1.3594 Loss_G: 0.5688 D(x): 0.4330 D(G(z)): 0.3831 / 0.5716\n",
      "[3/25][32/93] Loss_D: 1.4443 Loss_G: 1.6404 D(x): 0.6921 D(G(z)): 0.6512 / 0.2044\n",
      "[3/25][33/93] Loss_D: 1.3087 Loss_G: 0.6506 D(x): 0.3746 D(G(z)): 0.2475 / 0.5277\n",
      "[3/25][34/93] Loss_D: 1.4018 Loss_G: 1.1971 D(x): 0.6415 D(G(z)): 0.6038 / 0.3119\n",
      "[3/25][35/93] Loss_D: 1.1969 Loss_G: 1.0401 D(x): 0.4900 D(G(z)): 0.3633 / 0.3602\n",
      "[3/25][36/93] Loss_D: 1.2000 Loss_G: 1.2297 D(x): 0.5770 D(G(z)): 0.4600 / 0.3003\n",
      "[3/25][37/93] Loss_D: 1.0686 Loss_G: 1.2803 D(x): 0.5678 D(G(z)): 0.3717 / 0.2872\n",
      "[3/25][38/93] Loss_D: 1.1041 Loss_G: 1.0627 D(x): 0.5485 D(G(z)): 0.3825 / 0.3511\n",
      "[3/25][39/93] Loss_D: 1.0763 Loss_G: 1.4923 D(x): 0.6200 D(G(z)): 0.4348 / 0.2330\n",
      "[3/25][40/93] Loss_D: 1.1866 Loss_G: 0.7006 D(x): 0.4867 D(G(z)): 0.3469 / 0.5023\n",
      "[3/25][41/93] Loss_D: 1.3055 Loss_G: 3.3426 D(x): 0.8417 D(G(z)): 0.6648 / 0.0467\n",
      "[3/25][42/93] Loss_D: 2.7098 Loss_G: 0.2440 D(x): 0.1101 D(G(z)): 0.0826 / 0.7865\n",
      "[3/25][43/93] Loss_D: 1.9196 Loss_G: 1.4157 D(x): 0.8378 D(G(z)): 0.8099 / 0.2879\n",
      "[3/25][44/93] Loss_D: 1.6892 Loss_G: 1.0220 D(x): 0.4093 D(G(z)): 0.4586 / 0.3984\n",
      "[3/25][45/93] Loss_D: 1.4712 Loss_G: 0.6564 D(x): 0.4807 D(G(z)): 0.4798 / 0.5275\n",
      "[3/25][46/93] Loss_D: 1.1627 Loss_G: 1.2193 D(x): 0.6550 D(G(z)): 0.5110 / 0.3009\n",
      "[3/25][47/93] Loss_D: 1.1814 Loss_G: 0.8710 D(x): 0.4941 D(G(z)): 0.3635 / 0.4242\n",
      "[3/25][48/93] Loss_D: 1.1969 Loss_G: 1.6005 D(x): 0.6591 D(G(z)): 0.5259 / 0.2104\n",
      "[3/25][49/93] Loss_D: 1.3615 Loss_G: 0.4896 D(x): 0.3757 D(G(z)): 0.2841 / 0.6192\n",
      "[3/25][50/93] Loss_D: 1.5768 Loss_G: 1.8541 D(x): 0.7162 D(G(z)): 0.6859 / 0.1659\n",
      "[3/25][51/93] Loss_D: 1.3536 Loss_G: 0.8358 D(x): 0.3744 D(G(z)): 0.2695 / 0.4466\n",
      "[3/25][52/93] Loss_D: 1.3917 Loss_G: 1.3803 D(x): 0.6306 D(G(z)): 0.5824 / 0.2589\n",
      "[3/25][53/93] Loss_D: 1.3849 Loss_G: 0.6541 D(x): 0.3795 D(G(z)): 0.3123 / 0.5326\n",
      "[3/25][54/93] Loss_D: 1.3659 Loss_G: 1.5046 D(x): 0.6876 D(G(z)): 0.6146 / 0.2371\n",
      "[3/25][55/93] Loss_D: 1.3014 Loss_G: 0.9201 D(x): 0.4189 D(G(z)): 0.3225 / 0.4115\n",
      "[3/25][56/93] Loss_D: 1.2944 Loss_G: 0.9952 D(x): 0.5737 D(G(z)): 0.5012 / 0.3863\n",
      "[3/25][57/93] Loss_D: 1.2548 Loss_G: 1.1155 D(x): 0.5864 D(G(z)): 0.4869 / 0.3448\n",
      "[3/25][58/93] Loss_D: 1.2508 Loss_G: 0.8186 D(x): 0.5156 D(G(z)): 0.4166 / 0.4523\n",
      "[3/25][59/93] Loss_D: 1.2825 Loss_G: 1.3550 D(x): 0.6328 D(G(z)): 0.5352 / 0.2737\n",
      "[3/25][60/93] Loss_D: 1.2802 Loss_G: 0.8139 D(x): 0.4755 D(G(z)): 0.3895 / 0.4578\n",
      "[3/25][61/93] Loss_D: 1.3321 Loss_G: 1.1921 D(x): 0.5934 D(G(z)): 0.5404 / 0.3121\n",
      "[3/25][62/93] Loss_D: 1.3221 Loss_G: 0.7563 D(x): 0.4609 D(G(z)): 0.4090 / 0.4750\n",
      "[3/25][63/93] Loss_D: 1.3643 Loss_G: 1.6493 D(x): 0.6071 D(G(z)): 0.5662 / 0.2018\n",
      "[3/25][64/93] Loss_D: 1.2709 Loss_G: 0.6511 D(x): 0.4198 D(G(z)): 0.3019 / 0.5279\n",
      "[3/25][65/93] Loss_D: 1.5048 Loss_G: 1.5977 D(x): 0.6465 D(G(z)): 0.6409 / 0.2114\n",
      "[3/25][66/93] Loss_D: 1.4845 Loss_G: 0.4125 D(x): 0.3286 D(G(z)): 0.2728 / 0.6675\n",
      "[3/25][67/93] Loss_D: 1.6105 Loss_G: 1.8472 D(x): 0.7665 D(G(z)): 0.7281 / 0.1677\n",
      "[3/25][68/93] Loss_D: 1.4845 Loss_G: 0.4523 D(x): 0.3021 D(G(z)): 0.2144 / 0.6436\n",
      "[3/25][69/93] Loss_D: 1.3417 Loss_G: 1.6954 D(x): 0.7739 D(G(z)): 0.6468 / 0.2014\n",
      "[3/25][70/93] Loss_D: 1.3228 Loss_G: 0.6652 D(x): 0.3967 D(G(z)): 0.2778 / 0.5218\n",
      "[3/25][71/93] Loss_D: 1.4438 Loss_G: 1.2821 D(x): 0.6337 D(G(z)): 0.6139 / 0.2869\n",
      "[3/25][72/93] Loss_D: 1.3176 Loss_G: 0.9290 D(x): 0.4730 D(G(z)): 0.3843 / 0.4023\n",
      "[3/25][73/93] Loss_D: 1.3637 Loss_G: 0.9373 D(x): 0.5343 D(G(z)): 0.4967 / 0.3976\n",
      "[3/25][74/93] Loss_D: 1.3266 Loss_G: 0.8457 D(x): 0.4931 D(G(z)): 0.4411 / 0.4351\n",
      "[3/25][75/93] Loss_D: 1.3647 Loss_G: 1.4104 D(x): 0.5531 D(G(z)): 0.5155 / 0.2524\n",
      "[3/25][76/93] Loss_D: 0.9556 Loss_G: 1.4858 D(x): 0.5977 D(G(z)): 0.3370 / 0.2314\n",
      "[3/25][77/93] Loss_D: 1.4429 Loss_G: 0.4974 D(x): 0.4018 D(G(z)): 0.3717 / 0.6255\n",
      "[3/25][78/93] Loss_D: 1.7516 Loss_G: 2.0524 D(x): 0.7239 D(G(z)): 0.7336 / 0.1416\n",
      "[3/25][79/93] Loss_D: 2.0109 Loss_G: 0.3492 D(x): 0.1978 D(G(z)): 0.2209 / 0.7129\n",
      "[3/25][80/93] Loss_D: 1.5583 Loss_G: 1.5893 D(x): 0.8021 D(G(z)): 0.7176 / 0.2399\n",
      "[3/25][81/93] Loss_D: 1.1650 Loss_G: 1.7603 D(x): 0.5725 D(G(z)): 0.4096 / 0.1996\n",
      "[3/25][82/93] Loss_D: 1.9357 Loss_G: 0.2877 D(x): 0.2582 D(G(z)): 0.3278 / 0.7557\n",
      "[3/25][83/93] Loss_D: 1.7556 Loss_G: 1.5293 D(x): 0.8107 D(G(z)): 0.7722 / 0.2326\n",
      "[3/25][84/93] Loss_D: 1.5319 Loss_G: 0.8384 D(x): 0.3494 D(G(z)): 0.3175 / 0.4494\n",
      "[3/25][85/93] Loss_D: 1.2588 Loss_G: 1.1072 D(x): 0.6432 D(G(z)): 0.5318 / 0.3509\n",
      "[3/25][86/93] Loss_D: 1.1381 Loss_G: 1.6149 D(x): 0.6214 D(G(z)): 0.4491 / 0.2176\n",
      "[3/25][87/93] Loss_D: 1.1928 Loss_G: 0.6193 D(x): 0.4515 D(G(z)): 0.2694 / 0.5506\n",
      "[3/25][88/93] Loss_D: 1.3843 Loss_G: 1.8574 D(x): 0.7744 D(G(z)): 0.6506 / 0.1743\n",
      "[3/25][89/93] Loss_D: 1.5367 Loss_G: 0.6080 D(x): 0.3375 D(G(z)): 0.3173 / 0.5633\n",
      "[3/25][90/93] Loss_D: 1.7740 Loss_G: 1.2965 D(x): 0.5621 D(G(z)): 0.6654 / 0.2921\n",
      "[3/25][91/93] Loss_D: 1.4809 Loss_G: 1.6699 D(x): 0.5026 D(G(z)): 0.5045 / 0.2011\n",
      "[3/25][92/93] Loss_D: 1.6418 Loss_G: 0.4406 D(x): 0.2759 D(G(z)): 0.2708 / 0.6662\n",
      "[4/25][0/93] Loss_D: 1.5990 Loss_G: 1.8603 D(x): 0.7396 D(G(z)): 0.6851 / 0.1688\n",
      "[4/25][1/93] Loss_D: 1.4505 Loss_G: 0.8935 D(x): 0.3601 D(G(z)): 0.2743 / 0.4261\n",
      "[4/25][2/93] Loss_D: 1.4550 Loss_G: 1.4325 D(x): 0.6303 D(G(z)): 0.6039 / 0.2470\n",
      "[4/25][3/93] Loss_D: 1.2674 Loss_G: 0.9210 D(x): 0.4507 D(G(z)): 0.3174 / 0.4113\n",
      "[4/25][4/93] Loss_D: 1.2582 Loss_G: 1.4582 D(x): 0.6359 D(G(z)): 0.5315 / 0.2571\n",
      "[4/25][5/93] Loss_D: 1.5438 Loss_G: 0.5177 D(x): 0.3802 D(G(z)): 0.3442 / 0.6051\n",
      "[4/25][6/93] Loss_D: 1.5127 Loss_G: 2.0252 D(x): 0.7351 D(G(z)): 0.6820 / 0.1587\n",
      "[4/25][7/93] Loss_D: 1.8358 Loss_G: 0.3388 D(x): 0.2577 D(G(z)): 0.2651 / 0.7176\n",
      "[4/25][8/93] Loss_D: 1.6447 Loss_G: 2.0170 D(x): 0.7778 D(G(z)): 0.7439 / 0.1453\n",
      "[4/25][9/93] Loss_D: 1.5655 Loss_G: 0.5997 D(x): 0.3004 D(G(z)): 0.2452 / 0.5586\n",
      "[4/25][10/93] Loss_D: 1.3640 Loss_G: 1.4613 D(x): 0.7224 D(G(z)): 0.6281 / 0.2499\n",
      "[4/25][11/93] Loss_D: 1.3649 Loss_G: 0.9019 D(x): 0.4164 D(G(z)): 0.3455 / 0.4191\n",
      "[4/25][12/93] Loss_D: 1.4160 Loss_G: 1.0103 D(x): 0.5575 D(G(z)): 0.5365 / 0.3761\n",
      "[4/25][13/93] Loss_D: 1.1339 Loss_G: 1.2247 D(x): 0.5714 D(G(z)): 0.4204 / 0.3029\n",
      "[4/25][14/93] Loss_D: 1.2518 Loss_G: 0.7486 D(x): 0.4689 D(G(z)): 0.3610 / 0.4857\n",
      "[4/25][15/93] Loss_D: 1.1595 Loss_G: 1.7578 D(x): 0.7464 D(G(z)): 0.5661 / 0.1838\n",
      "[4/25][16/93] Loss_D: 1.4861 Loss_G: 0.5269 D(x): 0.3370 D(G(z)): 0.2612 / 0.5947\n",
      "[4/25][17/93] Loss_D: 1.3560 Loss_G: 1.0189 D(x): 0.6856 D(G(z)): 0.6096 / 0.3701\n",
      "[4/25][18/93] Loss_D: 1.2540 Loss_G: 0.9621 D(x): 0.5150 D(G(z)): 0.4187 / 0.3902\n",
      "[4/25][19/93] Loss_D: 1.2892 Loss_G: 0.8712 D(x): 0.5507 D(G(z)): 0.4824 / 0.4236\n",
      "[4/25][20/93] Loss_D: 1.2041 Loss_G: 1.0503 D(x): 0.5958 D(G(z)): 0.4521 / 0.3570\n",
      "[4/25][21/93] Loss_D: 1.4359 Loss_G: 0.6314 D(x): 0.4287 D(G(z)): 0.4250 / 0.5390\n",
      "[4/25][22/93] Loss_D: 1.3856 Loss_G: 1.0684 D(x): 0.6198 D(G(z)): 0.5765 / 0.3562\n",
      "[4/25][23/93] Loss_D: 1.2883 Loss_G: 0.9335 D(x): 0.5018 D(G(z)): 0.4170 / 0.4025\n",
      "[4/25][24/93] Loss_D: 1.4129 Loss_G: 0.7164 D(x): 0.4898 D(G(z)): 0.4769 / 0.5034\n",
      "[4/25][25/93] Loss_D: 1.3541 Loss_G: 1.3019 D(x): 0.6110 D(G(z)): 0.5509 / 0.2829\n",
      "[4/25][26/93] Loss_D: 1.4497 Loss_G: 0.5288 D(x): 0.3718 D(G(z)): 0.3195 / 0.5967\n",
      "[4/25][27/93] Loss_D: 1.4278 Loss_G: 1.3174 D(x): 0.6914 D(G(z)): 0.6352 / 0.2815\n",
      "[4/25][28/93] Loss_D: 1.4620 Loss_G: 0.6019 D(x): 0.3742 D(G(z)): 0.3298 / 0.5559\n",
      "[4/25][29/93] Loss_D: 1.3779 Loss_G: 1.3183 D(x): 0.6725 D(G(z)): 0.6084 / 0.2767\n",
      "[4/25][30/93] Loss_D: 1.4550 Loss_G: 0.4881 D(x): 0.3515 D(G(z)): 0.3028 / 0.6192\n",
      "[4/25][31/93] Loss_D: 1.4148 Loss_G: 1.5994 D(x): 0.7272 D(G(z)): 0.6506 / 0.2100\n",
      "[4/25][32/93] Loss_D: 1.4388 Loss_G: 0.7785 D(x): 0.3499 D(G(z)): 0.2854 / 0.4651\n",
      "[4/25][33/93] Loss_D: 1.1525 Loss_G: 1.1493 D(x): 0.6451 D(G(z)): 0.4955 / 0.3234\n",
      "[4/25][34/93] Loss_D: 1.4409 Loss_G: 0.6497 D(x): 0.3978 D(G(z)): 0.3850 / 0.5268\n",
      "[4/25][35/93] Loss_D: 1.3302 Loss_G: 1.1344 D(x): 0.6130 D(G(z)): 0.5601 / 0.3272\n",
      "[4/25][36/93] Loss_D: 1.2469 Loss_G: 0.8370 D(x): 0.4705 D(G(z)): 0.3681 / 0.4372\n",
      "[4/25][37/93] Loss_D: 1.1423 Loss_G: 1.3537 D(x): 0.6757 D(G(z)): 0.5048 / 0.2654\n",
      "[4/25][38/93] Loss_D: 1.4161 Loss_G: 0.4525 D(x): 0.3728 D(G(z)): 0.3071 / 0.6405\n",
      "[4/25][39/93] Loss_D: 1.4833 Loss_G: 1.3191 D(x): 0.7251 D(G(z)): 0.6770 / 0.2789\n",
      "[4/25][40/93] Loss_D: 1.2999 Loss_G: 0.7243 D(x): 0.3944 D(G(z)): 0.2782 / 0.4877\n",
      "[4/25][41/93] Loss_D: 1.2587 Loss_G: 1.4202 D(x): 0.7490 D(G(z)): 0.6012 / 0.2606\n",
      "[4/25][42/93] Loss_D: 1.4016 Loss_G: 0.9144 D(x): 0.4531 D(G(z)): 0.3624 / 0.4185\n",
      "[4/25][43/93] Loss_D: 1.4812 Loss_G: 0.4662 D(x): 0.4214 D(G(z)): 0.4347 / 0.6337\n",
      "[4/25][44/93] Loss_D: 1.4966 Loss_G: 1.2820 D(x): 0.6805 D(G(z)): 0.6591 / 0.2941\n",
      "[4/25][45/93] Loss_D: 1.5806 Loss_G: 0.6824 D(x): 0.3610 D(G(z)): 0.3986 / 0.5220\n",
      "[4/25][46/93] Loss_D: 1.4483 Loss_G: 1.0194 D(x): 0.6284 D(G(z)): 0.5957 / 0.3832\n",
      "[4/25][47/93] Loss_D: 1.1688 Loss_G: 1.1912 D(x): 0.5694 D(G(z)): 0.4278 / 0.3182\n",
      "[4/25][48/93] Loss_D: 1.2444 Loss_G: 0.9922 D(x): 0.5300 D(G(z)): 0.4153 / 0.3835\n",
      "[4/25][49/93] Loss_D: 1.2049 Loss_G: 0.8636 D(x): 0.5532 D(G(z)): 0.4381 / 0.4343\n",
      "[4/25][50/93] Loss_D: 1.4107 Loss_G: 0.9089 D(x): 0.5285 D(G(z)): 0.5194 / 0.4100\n",
      "[4/25][51/93] Loss_D: 1.3948 Loss_G: 0.9343 D(x): 0.5016 D(G(z)): 0.4690 / 0.4053\n",
      "[4/25][52/93] Loss_D: 1.3836 Loss_G: 0.6353 D(x): 0.4677 D(G(z)): 0.4441 / 0.5371\n",
      "[4/25][53/93] Loss_D: 1.2811 Loss_G: 1.5502 D(x): 0.6880 D(G(z)): 0.5782 / 0.2237\n",
      "[4/25][54/93] Loss_D: 1.4992 Loss_G: 0.4249 D(x): 0.3316 D(G(z)): 0.2854 / 0.6669\n",
      "[4/25][55/93] Loss_D: 1.5394 Loss_G: 1.5793 D(x): 0.7428 D(G(z)): 0.6982 / 0.2148\n",
      "[4/25][56/93] Loss_D: 1.4171 Loss_G: 0.6882 D(x): 0.3404 D(G(z)): 0.2623 / 0.5139\n",
      "[4/25][57/93] Loss_D: 1.2528 Loss_G: 1.2883 D(x): 0.6864 D(G(z)): 0.5586 / 0.2887\n",
      "[4/25][58/93] Loss_D: 1.1464 Loss_G: 1.4451 D(x): 0.5255 D(G(z)): 0.3369 / 0.2471\n",
      "[4/25][59/93] Loss_D: 1.4052 Loss_G: 0.4925 D(x): 0.3935 D(G(z)): 0.3436 / 0.6200\n",
      "[4/25][60/93] Loss_D: 1.4549 Loss_G: 1.4533 D(x): 0.7344 D(G(z)): 0.6658 / 0.2421\n",
      "[4/25][61/93] Loss_D: 1.3950 Loss_G: 0.7027 D(x): 0.3576 D(G(z)): 0.2794 / 0.5002\n",
      "[4/25][62/93] Loss_D: 1.2610 Loss_G: 0.9820 D(x): 0.6518 D(G(z)): 0.5491 / 0.3852\n",
      "[4/25][63/93] Loss_D: 1.4365 Loss_G: 0.7114 D(x): 0.4574 D(G(z)): 0.4571 / 0.4973\n",
      "[4/25][64/93] Loss_D: 1.4208 Loss_G: 0.8564 D(x): 0.5486 D(G(z)): 0.5437 / 0.4346\n",
      "[4/25][65/93] Loss_D: 1.4905 Loss_G: 0.7598 D(x): 0.4593 D(G(z)): 0.4925 / 0.4751\n",
      "[4/25][66/93] Loss_D: 1.4062 Loss_G: 0.6790 D(x): 0.4943 D(G(z)): 0.4890 / 0.5125\n",
      "[4/25][67/93] Loss_D: 1.4229 Loss_G: 1.1691 D(x): 0.5989 D(G(z)): 0.5826 / 0.3205\n",
      "[4/25][68/93] Loss_D: 1.3846 Loss_G: 0.5456 D(x): 0.3814 D(G(z)): 0.3243 / 0.5837\n",
      "[4/25][69/93] Loss_D: 1.4599 Loss_G: 1.1102 D(x): 0.6155 D(G(z)): 0.6091 / 0.3343\n",
      "[4/25][70/93] Loss_D: 1.1320 Loss_G: 1.3089 D(x): 0.5937 D(G(z)): 0.4123 / 0.2776\n",
      "[4/25][71/93] Loss_D: 1.4046 Loss_G: 0.4487 D(x): 0.3739 D(G(z)): 0.3218 / 0.6439\n",
      "[4/25][72/93] Loss_D: 1.4675 Loss_G: 1.1091 D(x): 0.6781 D(G(z)): 0.6503 / 0.3360\n",
      "[4/25][73/93] Loss_D: 1.2272 Loss_G: 0.8971 D(x): 0.4591 D(G(z)): 0.3487 / 0.4134\n",
      "[4/25][74/93] Loss_D: 1.2923 Loss_G: 0.8362 D(x): 0.5340 D(G(z)): 0.4724 / 0.4383\n",
      "[4/25][75/93] Loss_D: 1.2339 Loss_G: 0.9825 D(x): 0.5501 D(G(z)): 0.4539 / 0.3790\n",
      "[4/25][76/93] Loss_D: 1.2222 Loss_G: 0.8135 D(x): 0.5159 D(G(z)): 0.4119 / 0.4519\n",
      "[4/25][77/93] Loss_D: 1.2589 Loss_G: 1.1800 D(x): 0.6157 D(G(z)): 0.5150 / 0.3225\n",
      "[4/25][78/93] Loss_D: 1.3326 Loss_G: 1.0277 D(x): 0.5161 D(G(z)): 0.4443 / 0.3837\n",
      "[4/25][79/93] Loss_D: 1.3502 Loss_G: 0.4196 D(x): 0.3947 D(G(z)): 0.3196 / 0.6713\n",
      "[4/25][80/93] Loss_D: 1.5361 Loss_G: 1.3746 D(x): 0.7452 D(G(z)): 0.6921 / 0.2628\n",
      "[4/25][81/93] Loss_D: 1.3350 Loss_G: 0.7959 D(x): 0.4100 D(G(z)): 0.3220 / 0.4713\n",
      "[4/25][82/93] Loss_D: 1.1519 Loss_G: 1.3808 D(x): 0.7053 D(G(z)): 0.5288 / 0.2683\n",
      "[4/25][83/93] Loss_D: 1.4181 Loss_G: 0.5061 D(x): 0.3710 D(G(z)): 0.3133 / 0.6167\n",
      "[4/25][84/93] Loss_D: 1.4665 Loss_G: 1.2476 D(x): 0.7262 D(G(z)): 0.6569 / 0.3081\n",
      "[4/25][85/93] Loss_D: 1.2015 Loss_G: 0.9209 D(x): 0.4648 D(G(z)): 0.3258 / 0.4076\n",
      "[4/25][86/93] Loss_D: 1.2835 Loss_G: 0.7174 D(x): 0.5453 D(G(z)): 0.4750 / 0.4945\n",
      "[4/25][87/93] Loss_D: 1.3518 Loss_G: 1.1383 D(x): 0.6053 D(G(z)): 0.5553 / 0.3364\n",
      "[4/25][88/93] Loss_D: 1.3854 Loss_G: 0.7406 D(x): 0.4305 D(G(z)): 0.3849 / 0.4977\n",
      "[4/25][89/93] Loss_D: 1.3787 Loss_G: 1.0770 D(x): 0.5992 D(G(z)): 0.5619 / 0.3544\n",
      "[4/25][90/93] Loss_D: 1.3353 Loss_G: 0.6220 D(x): 0.4439 D(G(z)): 0.3853 / 0.5476\n",
      "[4/25][91/93] Loss_D: 1.3937 Loss_G: 1.5933 D(x): 0.6807 D(G(z)): 0.6243 / 0.2108\n",
      "[4/25][92/93] Loss_D: 1.3529 Loss_G: 0.9438 D(x): 0.4398 D(G(z)): 0.3198 / 0.3980\n",
      "[5/25][0/93] Loss_D: 1.4061 Loss_G: 0.4566 D(x): 0.4270 D(G(z)): 0.4075 / 0.6404\n",
      "[5/25][1/93] Loss_D: 1.5651 Loss_G: 1.5114 D(x): 0.6734 D(G(z)): 0.6710 / 0.2265\n",
      "[5/25][2/93] Loss_D: 1.6108 Loss_G: 0.4506 D(x): 0.2738 D(G(z)): 0.2510 / 0.6497\n",
      "[5/25][3/93] Loss_D: 1.4638 Loss_G: 1.4043 D(x): 0.7361 D(G(z)): 0.6720 / 0.2524\n",
      "[5/25][4/93] Loss_D: 1.0627 Loss_G: 1.4799 D(x): 0.5514 D(G(z)): 0.3204 / 0.2343\n",
      "[5/25][5/93] Loss_D: 1.4400 Loss_G: 0.3010 D(x): 0.3348 D(G(z)): 0.2526 / 0.7511\n",
      "[5/25][6/93] Loss_D: 1.8510 Loss_G: 1.6412 D(x): 0.8372 D(G(z)): 0.8005 / 0.2061\n",
      "[5/25][7/93] Loss_D: 1.1786 Loss_G: 1.2463 D(x): 0.4280 D(G(z)): 0.2164 / 0.3010\n",
      "[5/25][8/93] Loss_D: 1.2287 Loss_G: 0.5423 D(x): 0.4840 D(G(z)): 0.3723 / 0.5873\n",
      "[5/25][9/93] Loss_D: 1.3628 Loss_G: 1.6398 D(x): 0.7511 D(G(z)): 0.6435 / 0.2136\n",
      "[5/25][10/93] Loss_D: 1.2729 Loss_G: 0.9228 D(x): 0.4291 D(G(z)): 0.2816 / 0.4056\n",
      "[5/25][11/93] Loss_D: 1.5145 Loss_G: 0.7393 D(x): 0.5228 D(G(z)): 0.5501 / 0.4897\n",
      "[5/25][12/93] Loss_D: 1.0806 Loss_G: 1.5967 D(x): 0.7019 D(G(z)): 0.4826 / 0.2233\n",
      "[5/25][13/93] Loss_D: 1.2515 Loss_G: 0.7697 D(x): 0.4366 D(G(z)): 0.2425 / 0.4768\n",
      "[5/25][14/93] Loss_D: 1.2983 Loss_G: 0.9410 D(x): 0.6339 D(G(z)): 0.5473 / 0.4027\n",
      "[5/25][15/93] Loss_D: 1.6114 Loss_G: 0.8717 D(x): 0.4756 D(G(z)): 0.5577 / 0.4310\n",
      "[5/25][16/93] Loss_D: 1.2448 Loss_G: 0.7244 D(x): 0.5132 D(G(z)): 0.4113 / 0.4891\n",
      "[5/25][17/93] Loss_D: 1.3554 Loss_G: 1.0926 D(x): 0.6135 D(G(z)): 0.5652 / 0.3437\n",
      "[5/25][18/93] Loss_D: 1.2319 Loss_G: 0.7697 D(x): 0.4855 D(G(z)): 0.3763 / 0.4785\n",
      "[5/25][19/93] Loss_D: 1.3057 Loss_G: 1.1408 D(x): 0.6397 D(G(z)): 0.5636 / 0.3301\n",
      "[5/25][20/93] Loss_D: 1.3969 Loss_G: 0.8301 D(x): 0.4433 D(G(z)): 0.4185 / 0.4530\n",
      "[5/25][21/93] Loss_D: 1.2845 Loss_G: 1.0961 D(x): 0.5938 D(G(z)): 0.5085 / 0.3490\n",
      "[5/25][22/93] Loss_D: 1.3785 Loss_G: 0.6545 D(x): 0.4230 D(G(z)): 0.3780 / 0.5315\n",
      "[5/25][23/93] Loss_D: 1.5128 Loss_G: 1.4787 D(x): 0.6102 D(G(z)): 0.6116 / 0.2447\n",
      "[5/25][24/93] Loss_D: 1.3287 Loss_G: 0.6785 D(x): 0.3911 D(G(z)): 0.2850 / 0.5310\n",
      "[5/25][25/93] Loss_D: 1.4925 Loss_G: 1.5504 D(x): 0.6661 D(G(z)): 0.6335 / 0.2231\n",
      "[5/25][26/93] Loss_D: 1.5377 Loss_G: 0.4775 D(x): 0.3199 D(G(z)): 0.2815 / 0.6310\n",
      "[5/25][27/93] Loss_D: 1.5512 Loss_G: 1.3672 D(x): 0.6865 D(G(z)): 0.6689 / 0.2699\n",
      "[5/25][28/93] Loss_D: 1.2282 Loss_G: 1.0754 D(x): 0.4551 D(G(z)): 0.3129 / 0.3539\n",
      "[5/25][29/93] Loss_D: 1.1108 Loss_G: 1.0756 D(x): 0.6089 D(G(z)): 0.4187 / 0.3535\n",
      "[5/25][30/93] Loss_D: 1.3193 Loss_G: 0.6331 D(x): 0.4660 D(G(z)): 0.3982 / 0.5371\n",
      "[5/25][31/93] Loss_D: 1.7530 Loss_G: 0.9859 D(x): 0.5800 D(G(z)): 0.6768 / 0.3946\n",
      "[5/25][32/93] Loss_D: 1.3345 Loss_G: 0.6675 D(x): 0.4240 D(G(z)): 0.3453 / 0.5174\n",
      "[5/25][33/93] Loss_D: 1.3708 Loss_G: 0.9458 D(x): 0.5849 D(G(z)): 0.5579 / 0.3945\n",
      "[5/25][34/93] Loss_D: 1.2575 Loss_G: 0.8806 D(x): 0.5051 D(G(z)): 0.4250 / 0.4205\n",
      "[5/25][35/93] Loss_D: 1.1892 Loss_G: 1.0882 D(x): 0.6134 D(G(z)): 0.4905 / 0.3469\n",
      "[5/25][36/93] Loss_D: 1.1738 Loss_G: 0.9853 D(x): 0.5390 D(G(z)): 0.4002 / 0.3794\n",
      "[5/25][37/93] Loss_D: 1.3615 Loss_G: 0.6942 D(x): 0.5055 D(G(z)): 0.4768 / 0.5041\n",
      "[5/25][38/93] Loss_D: 1.4600 Loss_G: 0.8647 D(x): 0.5112 D(G(z)): 0.5288 / 0.4280\n",
      "[5/25][39/93] Loss_D: 1.1955 Loss_G: 1.4972 D(x): 0.6276 D(G(z)): 0.4893 / 0.2317\n",
      "[5/25][40/93] Loss_D: 1.4696 Loss_G: 0.4621 D(x): 0.3409 D(G(z)): 0.2801 / 0.6360\n",
      "[5/25][41/93] Loss_D: 1.4307 Loss_G: 1.8505 D(x): 0.7522 D(G(z)): 0.6609 / 0.1646\n",
      "[5/25][42/93] Loss_D: 1.7641 Loss_G: 0.5534 D(x): 0.2643 D(G(z)): 0.3037 / 0.5851\n",
      "[5/25][43/93] Loss_D: 1.5746 Loss_G: 0.9543 D(x): 0.6420 D(G(z)): 0.6484 / 0.3987\n",
      "[5/25][44/93] Loss_D: 1.1263 Loss_G: 1.3798 D(x): 0.6250 D(G(z)): 0.4364 / 0.2736\n",
      "[5/25][45/93] Loss_D: 1.2568 Loss_G: 0.6141 D(x): 0.4372 D(G(z)): 0.3047 / 0.5526\n",
      "[5/25][46/93] Loss_D: 1.3489 Loss_G: 0.9596 D(x): 0.6712 D(G(z)): 0.5950 / 0.3948\n",
      "[5/25][47/93] Loss_D: 1.2130 Loss_G: 1.2623 D(x): 0.6125 D(G(z)): 0.4940 / 0.2964\n",
      "[5/25][48/93] Loss_D: 1.1692 Loss_G: 0.7895 D(x): 0.5013 D(G(z)): 0.3488 / 0.4694\n",
      "[5/25][49/93] Loss_D: 1.3003 Loss_G: 1.6317 D(x): 0.6640 D(G(z)): 0.5700 / 0.2069\n",
      "[5/25][50/93] Loss_D: 1.3648 Loss_G: 0.4968 D(x): 0.3569 D(G(z)): 0.2504 / 0.6135\n",
      "[5/25][51/93] Loss_D: 1.7416 Loss_G: 2.1736 D(x): 0.7668 D(G(z)): 0.7528 / 0.1278\n",
      "[5/25][52/93] Loss_D: 2.0517 Loss_G: 0.4639 D(x): 0.1701 D(G(z)): 0.1601 / 0.6356\n",
      "[5/25][53/93] Loss_D: 1.5757 Loss_G: 0.9849 D(x): 0.6994 D(G(z)): 0.6834 / 0.3834\n",
      "[5/25][54/93] Loss_D: 1.2742 Loss_G: 1.1764 D(x): 0.5264 D(G(z)): 0.4503 / 0.3180\n",
      "[5/25][55/93] Loss_D: 1.3484 Loss_G: 0.8116 D(x): 0.4514 D(G(z)): 0.4025 / 0.4505\n",
      "[5/25][56/93] Loss_D: 1.1733 Loss_G: 0.8865 D(x): 0.5595 D(G(z)): 0.4317 / 0.4201\n",
      "[5/25][57/93] Loss_D: 1.3172 Loss_G: 0.9180 D(x): 0.5313 D(G(z)): 0.4811 / 0.4054\n",
      "[5/25][58/93] Loss_D: 1.2224 Loss_G: 1.0713 D(x): 0.5689 D(G(z)): 0.4692 / 0.3526\n",
      "[5/25][59/93] Loss_D: 1.0385 Loss_G: 1.2937 D(x): 0.6141 D(G(z)): 0.3984 / 0.2901\n",
      "[5/25][60/93] Loss_D: 1.3385 Loss_G: 0.6443 D(x): 0.4487 D(G(z)): 0.3829 / 0.5343\n",
      "[5/25][61/93] Loss_D: 1.4728 Loss_G: 1.0502 D(x): 0.6164 D(G(z)): 0.6091 / 0.3604\n",
      "[5/25][62/93] Loss_D: 1.3252 Loss_G: 1.2516 D(x): 0.5375 D(G(z)): 0.4627 / 0.3036\n",
      "[5/25][63/93] Loss_D: 1.0460 Loss_G: 1.3935 D(x): 0.6308 D(G(z)): 0.4013 / 0.2713\n",
      "[5/25][64/93] Loss_D: 1.8281 Loss_G: 0.3394 D(x): 0.2422 D(G(z)): 0.2705 / 0.7220\n",
      "[5/25][65/93] Loss_D: 1.7080 Loss_G: 1.3252 D(x): 0.7684 D(G(z)): 0.7382 / 0.2937\n",
      "[5/25][66/93] Loss_D: 1.1829 Loss_G: 1.4536 D(x): 0.5396 D(G(z)): 0.3842 / 0.2656\n",
      "[5/25][67/93] Loss_D: 1.5005 Loss_G: 0.4697 D(x): 0.3624 D(G(z)): 0.3530 / 0.6350\n",
      "[5/25][68/93] Loss_D: 1.3839 Loss_G: 1.4526 D(x): 0.8173 D(G(z)): 0.6679 / 0.2642\n",
      "[5/25][69/93] Loss_D: 1.3077 Loss_G: 1.0173 D(x): 0.4461 D(G(z)): 0.3617 / 0.3781\n",
      "[5/25][70/93] Loss_D: 1.2929 Loss_G: 1.1874 D(x): 0.6476 D(G(z)): 0.5536 / 0.3177\n",
      "[5/25][71/93] Loss_D: 1.4059 Loss_G: 0.9651 D(x): 0.4634 D(G(z)): 0.4364 / 0.4060\n",
      "[5/25][72/93] Loss_D: 1.3217 Loss_G: 1.0758 D(x): 0.5454 D(G(z)): 0.4736 / 0.3738\n",
      "[5/25][73/93] Loss_D: 1.2703 Loss_G: 1.3910 D(x): 0.5714 D(G(z)): 0.4681 / 0.2731\n",
      "[5/25][74/93] Loss_D: 1.3783 Loss_G: 0.7274 D(x): 0.4397 D(G(z)): 0.3856 / 0.5089\n",
      "[5/25][75/93] Loss_D: 1.4256 Loss_G: 1.6172 D(x): 0.6739 D(G(z)): 0.6056 / 0.2209\n",
      "[5/25][76/93] Loss_D: 1.7550 Loss_G: 0.5222 D(x): 0.3007 D(G(z)): 0.3173 / 0.6001\n",
      "[5/25][77/93] Loss_D: 1.4639 Loss_G: 1.4937 D(x): 0.6923 D(G(z)): 0.6442 / 0.2323\n",
      "[5/25][78/93] Loss_D: 1.4616 Loss_G: 0.5939 D(x): 0.3318 D(G(z)): 0.2608 / 0.5607\n",
      "[5/25][79/93] Loss_D: 1.4299 Loss_G: 1.6909 D(x): 0.7490 D(G(z)): 0.6649 / 0.1901\n",
      "[5/25][80/93] Loss_D: 1.5065 Loss_G: 0.6122 D(x): 0.3108 D(G(z)): 0.2660 / 0.5494\n",
      "[5/25][81/93] Loss_D: 1.5150 Loss_G: 1.1347 D(x): 0.6444 D(G(z)): 0.6456 / 0.3284\n",
      "[5/25][82/93] Loss_D: 1.4095 Loss_G: 0.8243 D(x): 0.4173 D(G(z)): 0.3890 / 0.4438\n",
      "[5/25][83/93] Loss_D: 1.3959 Loss_G: 0.6501 D(x): 0.4644 D(G(z)): 0.4458 / 0.5256\n",
      "[5/25][84/93] Loss_D: 1.3678 Loss_G: 1.2243 D(x): 0.6078 D(G(z)): 0.5701 / 0.3018\n",
      "[5/25][85/93] Loss_D: 1.4359 Loss_G: 0.6896 D(x): 0.3998 D(G(z)): 0.3724 / 0.5047\n",
      "[5/25][86/93] Loss_D: 1.2820 Loss_G: 1.0259 D(x): 0.6099 D(G(z)): 0.5374 / 0.3646\n",
      "[5/25][87/93] Loss_D: 1.2177 Loss_G: 1.0126 D(x): 0.5418 D(G(z)): 0.4373 / 0.3669\n",
      "[5/25][88/93] Loss_D: 1.3122 Loss_G: 0.7418 D(x): 0.4578 D(G(z)): 0.3967 / 0.4808\n",
      "[5/25][89/93] Loss_D: 1.3021 Loss_G: 1.0195 D(x): 0.5942 D(G(z)): 0.5331 / 0.3655\n",
      "[5/25][90/93] Loss_D: 1.1205 Loss_G: 1.2553 D(x): 0.5797 D(G(z)): 0.3978 / 0.2967\n",
      "[5/25][91/93] Loss_D: 1.3844 Loss_G: 0.5595 D(x): 0.4078 D(G(z)): 0.3542 / 0.5777\n",
      "[5/25][92/93] Loss_D: 1.3368 Loss_G: 1.3683 D(x): 0.7247 D(G(z)): 0.6193 / 0.2646\n",
      "[6/25][0/93] Loss_D: 1.4308 Loss_G: 0.6845 D(x): 0.3768 D(G(z)): 0.3157 / 0.5124\n",
      "[6/25][1/93] Loss_D: 1.2506 Loss_G: 0.8655 D(x): 0.6350 D(G(z)): 0.5340 / 0.4289\n",
      "[6/25][2/93] Loss_D: 1.4252 Loss_G: 0.8644 D(x): 0.5323 D(G(z)): 0.5227 / 0.4349\n",
      "[6/25][3/93] Loss_D: 1.3330 Loss_G: 0.9368 D(x): 0.5393 D(G(z)): 0.4806 / 0.4047\n",
      "[6/25][4/93] Loss_D: 1.3404 Loss_G: 0.8220 D(x): 0.5074 D(G(z)): 0.4539 / 0.4485\n",
      "[6/25][5/93] Loss_D: 1.3638 Loss_G: 0.9042 D(x): 0.5494 D(G(z)): 0.5075 / 0.4109\n",
      "[6/25][6/93] Loss_D: 1.1131 Loss_G: 1.1072 D(x): 0.5853 D(G(z)): 0.4182 / 0.3381\n",
      "[6/25][7/93] Loss_D: 1.3454 Loss_G: 0.6099 D(x): 0.4273 D(G(z)): 0.3728 / 0.5517\n",
      "[6/25][8/93] Loss_D: 1.2890 Loss_G: 1.3818 D(x): 0.7310 D(G(z)): 0.5971 / 0.2617\n",
      "[6/25][9/93] Loss_D: 1.3189 Loss_G: 0.8257 D(x): 0.4175 D(G(z)): 0.3412 / 0.4473\n",
      "[6/25][10/93] Loss_D: 1.2407 Loss_G: 1.2574 D(x): 0.6906 D(G(z)): 0.5544 / 0.3000\n",
      "[6/25][11/93] Loss_D: 1.2893 Loss_G: 0.7724 D(x): 0.4355 D(G(z)): 0.3276 / 0.4752\n",
      "[6/25][12/93] Loss_D: 1.3454 Loss_G: 1.0914 D(x): 0.6291 D(G(z)): 0.5604 / 0.3528\n",
      "[6/25][13/93] Loss_D: 1.2757 Loss_G: 0.8924 D(x): 0.5049 D(G(z)): 0.4215 / 0.4234\n",
      "[6/25][14/93] Loss_D: 1.2562 Loss_G: 1.1583 D(x): 0.6149 D(G(z)): 0.5205 / 0.3256\n",
      "[6/25][15/93] Loss_D: 1.1237 Loss_G: 1.0618 D(x): 0.5533 D(G(z)): 0.3745 / 0.3563\n",
      "[6/25][16/93] Loss_D: 1.2846 Loss_G: 0.7183 D(x): 0.4870 D(G(z)): 0.4119 / 0.5010\n",
      "[6/25][17/93] Loss_D: 1.3637 Loss_G: 1.3787 D(x): 0.6568 D(G(z)): 0.5938 / 0.2609\n",
      "[6/25][18/93] Loss_D: 1.4620 Loss_G: 0.5211 D(x): 0.3549 D(G(z)): 0.3130 / 0.6004\n",
      "[6/25][19/93] Loss_D: 1.3387 Loss_G: 1.5972 D(x): 0.7699 D(G(z)): 0.6440 / 0.2104\n",
      "[6/25][20/93] Loss_D: 1.2380 Loss_G: 1.0913 D(x): 0.4214 D(G(z)): 0.2370 / 0.3552\n",
      "[6/25][21/93] Loss_D: 1.3899 Loss_G: 0.5529 D(x): 0.4600 D(G(z)): 0.4375 / 0.5923\n",
      "[6/25][22/93] Loss_D: 1.5499 Loss_G: 1.4985 D(x): 0.6692 D(G(z)): 0.6684 / 0.2342\n",
      "[6/25][23/93] Loss_D: 1.4437 Loss_G: 0.6630 D(x): 0.3408 D(G(z)): 0.2585 / 0.5199\n",
      "[6/25][24/93] Loss_D: 1.4108 Loss_G: 0.8960 D(x): 0.6009 D(G(z)): 0.5823 / 0.4163\n",
      "[6/25][25/93] Loss_D: 1.1178 Loss_G: 1.3828 D(x): 0.5896 D(G(z)): 0.4315 / 0.2575\n",
      "[6/25][26/93] Loss_D: 1.2900 Loss_G: 0.6324 D(x): 0.4159 D(G(z)): 0.2933 / 0.5359\n",
      "[6/25][27/93] Loss_D: 1.3167 Loss_G: 1.1119 D(x): 0.6681 D(G(z)): 0.5842 / 0.3384\n",
      "[6/25][28/93] Loss_D: 1.4125 Loss_G: 1.0756 D(x): 0.4941 D(G(z)): 0.4746 / 0.3644\n",
      "[6/25][29/93] Loss_D: 0.9848 Loss_G: 1.1485 D(x): 0.6123 D(G(z)): 0.3415 / 0.3238\n",
      "[6/25][30/93] Loss_D: 1.2390 Loss_G: 0.7127 D(x): 0.5037 D(G(z)): 0.3998 / 0.4966\n",
      "[6/25][31/93] Loss_D: 1.3837 Loss_G: 1.4114 D(x): 0.6830 D(G(z)): 0.6126 / 0.2626\n",
      "[6/25][32/93] Loss_D: 1.5892 Loss_G: 0.4431 D(x): 0.2989 D(G(z)): 0.2685 / 0.6504\n",
      "[6/25][33/93] Loss_D: 1.5752 Loss_G: 1.1847 D(x): 0.7313 D(G(z)): 0.7060 / 0.3194\n",
      "[6/25][34/93] Loss_D: 1.0888 Loss_G: 1.3585 D(x): 0.5593 D(G(z)): 0.3300 / 0.2654\n",
      "[6/25][35/93] Loss_D: 0.9857 Loss_G: 1.0689 D(x): 0.6154 D(G(z)): 0.3390 / 0.3548\n",
      "[6/25][36/93] Loss_D: 1.4091 Loss_G: 0.4918 D(x): 0.4318 D(G(z)): 0.4144 / 0.6220\n",
      "[6/25][37/93] Loss_D: 1.4989 Loss_G: 1.1142 D(x): 0.6660 D(G(z)): 0.6498 / 0.3369\n",
      "[6/25][38/93] Loss_D: 1.3264 Loss_G: 0.8318 D(x): 0.4410 D(G(z)): 0.3725 / 0.4454\n",
      "[6/25][39/93] Loss_D: 1.2820 Loss_G: 0.9115 D(x): 0.5782 D(G(z)): 0.4958 / 0.4158\n",
      "[6/25][40/93] Loss_D: 1.2579 Loss_G: 0.8919 D(x): 0.5248 D(G(z)): 0.4424 / 0.4163\n",
      "[6/25][41/93] Loss_D: 1.2615 Loss_G: 1.0375 D(x): 0.5644 D(G(z)): 0.4797 / 0.3595\n",
      "[6/25][42/93] Loss_D: 1.3049 Loss_G: 0.7787 D(x): 0.4854 D(G(z)): 0.4118 / 0.4655\n",
      "[6/25][43/93] Loss_D: 1.3199 Loss_G: 1.1465 D(x): 0.5717 D(G(z)): 0.5200 / 0.3236\n",
      "[6/25][44/93] Loss_D: 1.3470 Loss_G: 0.6727 D(x): 0.4432 D(G(z)): 0.3901 / 0.5136\n",
      "[6/25][45/93] Loss_D: 1.3216 Loss_G: 1.2910 D(x): 0.5953 D(G(z)): 0.5414 / 0.2823\n",
      "[6/25][46/93] Loss_D: 1.2938 Loss_G: 0.6555 D(x): 0.4270 D(G(z)): 0.3301 / 0.5237\n",
      "[6/25][47/93] Loss_D: 1.2631 Loss_G: 1.5136 D(x): 0.6651 D(G(z)): 0.5671 / 0.2282\n",
      "[6/25][48/93] Loss_D: 1.4104 Loss_G: 0.5062 D(x): 0.3615 D(G(z)): 0.2866 / 0.6089\n",
      "[6/25][49/93] Loss_D: 1.2087 Loss_G: 1.7973 D(x): 0.8202 D(G(z)): 0.6244 / 0.1794\n",
      "[6/25][50/93] Loss_D: 1.6038 Loss_G: 0.4860 D(x): 0.2702 D(G(z)): 0.2141 / 0.6205\n",
      "[6/25][51/93] Loss_D: 1.4819 Loss_G: 1.0732 D(x): 0.7292 D(G(z)): 0.6770 / 0.3499\n",
      "[6/25][52/93] Loss_D: 1.3045 Loss_G: 0.8501 D(x): 0.4624 D(G(z)): 0.3721 / 0.4340\n",
      "[6/25][53/93] Loss_D: 1.0621 Loss_G: 1.2383 D(x): 0.6920 D(G(z)): 0.4743 / 0.2965\n",
      "[6/25][54/93] Loss_D: 1.3664 Loss_G: 0.6085 D(x): 0.4221 D(G(z)): 0.3634 / 0.5473\n",
      "[6/25][55/93] Loss_D: 1.1911 Loss_G: 1.1614 D(x): 0.6817 D(G(z)): 0.5459 / 0.3208\n",
      "[6/25][56/93] Loss_D: 1.2566 Loss_G: 0.9298 D(x): 0.5043 D(G(z)): 0.4204 / 0.3986\n",
      "[6/25][57/93] Loss_D: 1.2912 Loss_G: 0.6620 D(x): 0.4766 D(G(z)): 0.3994 / 0.5230\n",
      "[6/25][58/93] Loss_D: 1.3291 Loss_G: 1.1414 D(x): 0.6395 D(G(z)): 0.5732 / 0.3262\n",
      "[6/25][59/93] Loss_D: 1.2305 Loss_G: 0.9586 D(x): 0.5050 D(G(z)): 0.3986 / 0.3920\n",
      "[6/25][60/93] Loss_D: 1.2125 Loss_G: 0.7325 D(x): 0.5344 D(G(z)): 0.4197 / 0.4881\n",
      "[6/25][61/93] Loss_D: 1.1452 Loss_G: 1.5643 D(x): 0.7424 D(G(z)): 0.5570 / 0.2197\n",
      "[6/25][62/93] Loss_D: 1.4422 Loss_G: 0.5972 D(x): 0.3521 D(G(z)): 0.2931 / 0.5588\n",
      "[6/25][63/93] Loss_D: 1.3887 Loss_G: 1.0795 D(x): 0.6749 D(G(z)): 0.6094 / 0.3466\n",
      "[6/25][64/93] Loss_D: 1.3885 Loss_G: 0.7972 D(x): 0.4236 D(G(z)): 0.3877 / 0.4578\n",
      "[6/25][65/93] Loss_D: 1.1542 Loss_G: 1.1628 D(x): 0.6333 D(G(z)): 0.4839 / 0.3215\n",
      "[6/25][66/93] Loss_D: 1.1984 Loss_G: 0.8935 D(x): 0.5019 D(G(z)): 0.3763 / 0.4197\n",
      "[6/25][67/93] Loss_D: 1.1814 Loss_G: 1.3040 D(x): 0.6312 D(G(z)): 0.4943 / 0.2844\n",
      "[6/25][68/93] Loss_D: 1.3895 Loss_G: 0.4750 D(x): 0.4114 D(G(z)): 0.3676 / 0.6282\n",
      "[6/25][69/93] Loss_D: 1.5478 Loss_G: 1.6712 D(x): 0.7021 D(G(z)): 0.6782 / 0.2013\n",
      "[6/25][70/93] Loss_D: 1.5391 Loss_G: 0.5197 D(x): 0.2979 D(G(z)): 0.2493 / 0.6024\n",
      "[6/25][71/93] Loss_D: 1.5041 Loss_G: 1.1296 D(x): 0.6438 D(G(z)): 0.6467 / 0.3408\n",
      "[6/25][72/93] Loss_D: 1.3371 Loss_G: 0.9638 D(x): 0.4792 D(G(z)): 0.4300 / 0.3949\n",
      "[6/25][73/93] Loss_D: 1.1475 Loss_G: 0.9874 D(x): 0.5844 D(G(z)): 0.4413 / 0.3868\n",
      "[6/25][74/93] Loss_D: 1.3633 Loss_G: 1.1235 D(x): 0.5629 D(G(z)): 0.5213 / 0.3400\n",
      "[6/25][75/93] Loss_D: 1.4154 Loss_G: 0.6996 D(x): 0.4472 D(G(z)): 0.4248 / 0.5046\n",
      "[6/25][76/93] Loss_D: 1.5220 Loss_G: 1.5464 D(x): 0.6407 D(G(z)): 0.6432 / 0.2268\n",
      "[6/25][77/93] Loss_D: 1.6384 Loss_G: 0.4656 D(x): 0.3065 D(G(z)): 0.3142 / 0.6327\n",
      "[6/25][78/93] Loss_D: 1.5746 Loss_G: 1.2574 D(x): 0.6827 D(G(z)): 0.6832 / 0.2905\n",
      "[6/25][79/93] Loss_D: 1.2572 Loss_G: 1.0485 D(x): 0.4349 D(G(z)): 0.3185 / 0.3536\n",
      "[6/25][80/93] Loss_D: 1.3684 Loss_G: 0.7286 D(x): 0.4493 D(G(z)): 0.4193 / 0.4913\n",
      "[6/25][81/93] Loss_D: 1.2928 Loss_G: 1.2128 D(x): 0.6084 D(G(z)): 0.5324 / 0.3061\n",
      "[6/25][82/93] Loss_D: 1.1891 Loss_G: 1.0820 D(x): 0.5106 D(G(z)): 0.3753 / 0.3493\n",
      "[6/25][83/93] Loss_D: 1.3307 Loss_G: 0.7801 D(x): 0.4937 D(G(z)): 0.4493 / 0.4631\n",
      "[6/25][84/93] Loss_D: 1.0536 Loss_G: 1.8471 D(x): 0.7488 D(G(z)): 0.5175 / 0.1656\n",
      "[6/25][85/93] Loss_D: 1.4048 Loss_G: 0.5917 D(x): 0.3161 D(G(z)): 0.1802 / 0.5595\n",
      "[6/25][86/93] Loss_D: 1.3727 Loss_G: 0.9960 D(x): 0.6737 D(G(z)): 0.6063 / 0.3741\n",
      "[6/25][87/93] Loss_D: 1.2629 Loss_G: 1.5447 D(x): 0.5951 D(G(z)): 0.5052 / 0.2301\n",
      "[6/25][88/93] Loss_D: 1.7856 Loss_G: 0.4424 D(x): 0.2932 D(G(z)): 0.3598 / 0.6494\n",
      "[6/25][89/93] Loss_D: 1.5685 Loss_G: 1.2301 D(x): 0.7150 D(G(z)): 0.6929 / 0.3226\n",
      "[6/25][90/93] Loss_D: 1.5816 Loss_G: 0.6886 D(x): 0.3828 D(G(z)): 0.4019 / 0.5160\n",
      "[6/25][91/93] Loss_D: 1.1489 Loss_G: 1.1581 D(x): 0.6534 D(G(z)): 0.5024 / 0.3259\n",
      "[6/25][92/93] Loss_D: 1.1843 Loss_G: 1.0089 D(x): 0.5518 D(G(z)): 0.4106 / 0.3804\n",
      "[7/25][0/93] Loss_D: 1.1582 Loss_G: 1.1978 D(x): 0.6137 D(G(z)): 0.4686 / 0.3157\n",
      "[7/25][1/93] Loss_D: 1.3645 Loss_G: 0.5218 D(x): 0.4245 D(G(z)): 0.3595 / 0.6003\n",
      "[7/25][2/93] Loss_D: 1.5116 Loss_G: 1.4792 D(x): 0.7110 D(G(z)): 0.6777 / 0.2394\n",
      "[7/25][3/93] Loss_D: 1.4354 Loss_G: 0.7657 D(x): 0.3633 D(G(z)): 0.3122 / 0.4738\n",
      "[7/25][4/93] Loss_D: 1.3489 Loss_G: 1.2216 D(x): 0.6274 D(G(z)): 0.5656 / 0.2986\n",
      "[7/25][5/93] Loss_D: 1.2921 Loss_G: 0.8991 D(x): 0.4609 D(G(z)): 0.3762 / 0.4132\n",
      "[7/25][6/93] Loss_D: 1.2967 Loss_G: 0.6439 D(x): 0.4894 D(G(z)): 0.4309 / 0.5302\n",
      "[7/25][7/93] Loss_D: 1.3900 Loss_G: 1.3562 D(x): 0.6421 D(G(z)): 0.6014 / 0.2662\n",
      "[7/25][8/93] Loss_D: 1.3235 Loss_G: 0.6785 D(x): 0.4032 D(G(z)): 0.3143 / 0.5161\n",
      "[7/25][9/93] Loss_D: 1.1860 Loss_G: 1.6763 D(x): 0.7609 D(G(z)): 0.5888 / 0.2002\n",
      "[7/25][10/93] Loss_D: 1.1635 Loss_G: 1.0745 D(x): 0.4696 D(G(z)): 0.2585 / 0.3569\n",
      "[7/25][11/93] Loss_D: 1.4650 Loss_G: 0.6963 D(x): 0.5163 D(G(z)): 0.5199 / 0.5104\n",
      "[7/25][12/93] Loss_D: 1.3846 Loss_G: 1.2303 D(x): 0.5530 D(G(z)): 0.5274 / 0.3039\n",
      "[7/25][13/93] Loss_D: 1.4565 Loss_G: 0.6379 D(x): 0.3875 D(G(z)): 0.3712 / 0.5373\n",
      "[7/25][14/93] Loss_D: 1.4106 Loss_G: 0.9275 D(x): 0.5953 D(G(z)): 0.5807 / 0.4051\n",
      "[7/25][15/93] Loss_D: 1.1088 Loss_G: 1.3445 D(x): 0.6219 D(G(z)): 0.4433 / 0.2750\n",
      "[7/25][16/93] Loss_D: 1.3570 Loss_G: 0.6574 D(x): 0.4200 D(G(z)): 0.3658 / 0.5325\n",
      "[7/25][17/93] Loss_D: 1.3582 Loss_G: 1.0021 D(x): 0.6402 D(G(z)): 0.5847 / 0.3752\n",
      "[7/25][18/93] Loss_D: 1.2049 Loss_G: 0.9852 D(x): 0.5181 D(G(z)): 0.3997 / 0.3831\n",
      "[7/25][19/93] Loss_D: 1.1858 Loss_G: 0.9435 D(x): 0.5721 D(G(z)): 0.4526 / 0.3966\n",
      "[7/25][20/93] Loss_D: 1.0915 Loss_G: 1.0311 D(x): 0.6243 D(G(z)): 0.4497 / 0.3690\n",
      "[7/25][21/93] Loss_D: 1.2740 Loss_G: 1.2439 D(x): 0.6009 D(G(z)): 0.5148 / 0.2978\n",
      "[7/25][22/93] Loss_D: 1.4904 Loss_G: 0.4539 D(x): 0.3600 D(G(z)): 0.3502 / 0.6413\n",
      "[7/25][23/93] Loss_D: 1.6644 Loss_G: 1.7180 D(x): 0.7428 D(G(z)): 0.7298 / 0.1862\n",
      "[7/25][24/93] Loss_D: 1.8607 Loss_G: 0.5245 D(x): 0.2223 D(G(z)): 0.2606 / 0.6015\n",
      "[7/25][25/93] Loss_D: 1.3642 Loss_G: 1.1739 D(x): 0.6490 D(G(z)): 0.5771 / 0.3219\n",
      "[7/25][26/93] Loss_D: 1.3503 Loss_G: 1.1479 D(x): 0.5037 D(G(z)): 0.4646 / 0.3221\n",
      "[7/25][27/93] Loss_D: 1.3108 Loss_G: 0.6782 D(x): 0.4405 D(G(z)): 0.3678 / 0.5195\n",
      "[7/25][28/93] Loss_D: 1.3992 Loss_G: 1.2504 D(x): 0.6397 D(G(z)): 0.5892 / 0.2996\n",
      "[7/25][29/93] Loss_D: 1.2353 Loss_G: 1.0050 D(x): 0.4705 D(G(z)): 0.3305 / 0.3800\n",
      "[7/25][30/93] Loss_D: 1.2826 Loss_G: 0.7498 D(x): 0.5265 D(G(z)): 0.4548 / 0.4849\n",
      "[7/25][31/93] Loss_D: 1.3710 Loss_G: 1.5465 D(x): 0.6515 D(G(z)): 0.5889 / 0.2412\n",
      "[7/25][32/93] Loss_D: 1.3458 Loss_G: 0.4905 D(x): 0.3963 D(G(z)): 0.2991 / 0.6179\n",
      "[7/25][33/93] Loss_D: 1.5658 Loss_G: 2.5815 D(x): 0.7789 D(G(z)): 0.7134 / 0.0881\n",
      "[7/25][34/93] Loss_D: 1.9867 Loss_G: 0.5510 D(x): 0.1824 D(G(z)): 0.1355 / 0.5842\n",
      "[7/25][35/93] Loss_D: 1.4013 Loss_G: 0.9179 D(x): 0.6859 D(G(z)): 0.6110 / 0.4090\n",
      "[7/25][36/93] Loss_D: 1.3070 Loss_G: 1.3568 D(x): 0.5633 D(G(z)): 0.4954 / 0.2757\n",
      "[7/25][37/93] Loss_D: 1.1732 Loss_G: 1.0892 D(x): 0.5246 D(G(z)): 0.3716 / 0.3563\n",
      "[7/25][38/93] Loss_D: 0.8414 Loss_G: 1.8779 D(x): 0.8183 D(G(z)): 0.4464 / 0.1675\n",
      "[7/25][39/93] Loss_D: 1.6059 Loss_G: 0.5382 D(x): 0.2946 D(G(z)): 0.2478 / 0.5903\n",
      "[7/25][40/93] Loss_D: 1.5432 Loss_G: 0.9753 D(x): 0.6782 D(G(z)): 0.6607 / 0.3903\n",
      "[7/25][41/93] Loss_D: 1.3495 Loss_G: 1.1856 D(x): 0.5262 D(G(z)): 0.4792 / 0.3176\n",
      "[7/25][42/93] Loss_D: 1.2603 Loss_G: 0.8280 D(x): 0.4987 D(G(z)): 0.3497 / 0.4440\n",
      "[7/25][43/93] Loss_D: 1.3225 Loss_G: 0.8598 D(x): 0.5996 D(G(z)): 0.5394 / 0.4296\n",
      "[7/25][44/93] Loss_D: 1.3940 Loss_G: 0.8599 D(x): 0.5261 D(G(z)): 0.5107 / 0.4291\n",
      "[7/25][45/93] Loss_D: 1.2840 Loss_G: 0.8507 D(x): 0.5205 D(G(z)): 0.4480 / 0.4390\n",
      "[7/25][46/93] Loss_D: 1.2503 Loss_G: 0.9215 D(x): 0.5571 D(G(z)): 0.4658 / 0.4126\n",
      "[7/25][47/93] Loss_D: 1.3001 Loss_G: 1.0150 D(x): 0.5571 D(G(z)): 0.4936 / 0.3775\n",
      "[7/25][48/93] Loss_D: 1.1814 Loss_G: 0.9948 D(x): 0.5461 D(G(z)): 0.4181 / 0.3797\n",
      "[7/25][49/93] Loss_D: 1.2671 Loss_G: 0.7793 D(x): 0.4983 D(G(z)): 0.4057 / 0.4782\n",
      "[7/25][50/93] Loss_D: 1.2997 Loss_G: 1.3636 D(x): 0.6655 D(G(z)): 0.5737 / 0.2635\n",
      "[7/25][51/93] Loss_D: 1.3240 Loss_G: 0.7136 D(x): 0.4028 D(G(z)): 0.3106 / 0.5023\n",
      "[7/25][52/93] Loss_D: 1.2641 Loss_G: 1.4464 D(x): 0.6665 D(G(z)): 0.5597 / 0.2460\n",
      "[7/25][53/93] Loss_D: 1.4036 Loss_G: 0.5857 D(x): 0.3803 D(G(z)): 0.3163 / 0.5642\n",
      "[7/25][54/93] Loss_D: 1.4852 Loss_G: 1.2383 D(x): 0.6568 D(G(z)): 0.6386 / 0.3080\n",
      "[7/25][55/93] Loss_D: 1.4516 Loss_G: 0.6496 D(x): 0.3959 D(G(z)): 0.3631 / 0.5325\n",
      "[7/25][56/93] Loss_D: 1.3973 Loss_G: 0.9642 D(x): 0.6219 D(G(z)): 0.5831 / 0.3940\n",
      "[7/25][57/93] Loss_D: 1.2758 Loss_G: 0.9021 D(x): 0.4914 D(G(z)): 0.4147 / 0.4174\n",
      "[7/25][58/93] Loss_D: 1.2773 Loss_G: 0.8875 D(x): 0.5451 D(G(z)): 0.4759 / 0.4198\n",
      "[7/25][59/93] Loss_D: 1.3777 Loss_G: 0.9402 D(x): 0.4993 D(G(z)): 0.4798 / 0.3974\n",
      "[7/25][60/93] Loss_D: 1.1466 Loss_G: 1.3285 D(x): 0.5948 D(G(z)): 0.4426 / 0.2722\n",
      "[7/25][61/93] Loss_D: 1.4124 Loss_G: 0.5777 D(x): 0.3843 D(G(z)): 0.3496 / 0.5721\n",
      "[7/25][62/93] Loss_D: 1.3337 Loss_G: 1.3848 D(x): 0.6821 D(G(z)): 0.5962 / 0.2563\n",
      "[7/25][63/93] Loss_D: 1.4203 Loss_G: 0.6481 D(x): 0.3773 D(G(z)): 0.3324 / 0.5298\n",
      "[7/25][64/93] Loss_D: 1.4327 Loss_G: 1.1871 D(x): 0.6372 D(G(z)): 0.6081 / 0.3134\n",
      "[7/25][65/93] Loss_D: 1.2726 Loss_G: 0.8313 D(x): 0.4368 D(G(z)): 0.3269 / 0.4425\n",
      "[7/25][66/93] Loss_D: 1.1541 Loss_G: 0.9734 D(x): 0.6013 D(G(z)): 0.4594 / 0.3882\n",
      "[7/25][67/93] Loss_D: 1.2623 Loss_G: 0.9183 D(x): 0.5448 D(G(z)): 0.4607 / 0.4077\n",
      "[7/25][68/93] Loss_D: 1.2816 Loss_G: 0.7591 D(x): 0.5211 D(G(z)): 0.4494 / 0.4752\n",
      "[7/25][69/93] Loss_D: 1.2359 Loss_G: 1.4667 D(x): 0.6679 D(G(z)): 0.5489 / 0.2391\n",
      "[7/25][70/93] Loss_D: 1.0604 Loss_G: 1.5613 D(x): 0.6263 D(G(z)): 0.4049 / 0.2221\n",
      "[7/25][71/93] Loss_D: 1.3687 Loss_G: 0.4370 D(x): 0.3605 D(G(z)): 0.2219 / 0.6521\n",
      "[7/25][72/93] Loss_D: 1.4429 Loss_G: 1.4443 D(x): 0.7764 D(G(z)): 0.6808 / 0.2458\n",
      "[7/25][73/93] Loss_D: 1.2057 Loss_G: 1.1873 D(x): 0.5164 D(G(z)): 0.3555 / 0.3202\n",
      "[7/25][74/93] Loss_D: 1.4064 Loss_G: 0.6321 D(x): 0.4574 D(G(z)): 0.4344 / 0.5377\n",
      "[7/25][75/93] Loss_D: 1.4486 Loss_G: 0.8602 D(x): 0.5638 D(G(z)): 0.5651 / 0.4330\n",
      "[7/25][76/93] Loss_D: 1.3390 Loss_G: 0.9936 D(x): 0.5083 D(G(z)): 0.4681 / 0.3789\n",
      "[7/25][77/93] Loss_D: 1.2369 Loss_G: 1.1253 D(x): 0.5828 D(G(z)): 0.4863 / 0.3336\n",
      "[7/25][78/93] Loss_D: 1.2992 Loss_G: 0.7117 D(x): 0.4576 D(G(z)): 0.3747 / 0.4980\n",
      "[7/25][79/93] Loss_D: 1.1259 Loss_G: 1.2201 D(x): 0.6785 D(G(z)): 0.5068 / 0.3068\n",
      "[7/25][80/93] Loss_D: 1.2419 Loss_G: 0.8800 D(x): 0.4926 D(G(z)): 0.4015 / 0.4238\n",
      "[7/25][81/93] Loss_D: 1.3287 Loss_G: 1.0700 D(x): 0.5580 D(G(z)): 0.5119 / 0.3479\n",
      "[7/25][82/93] Loss_D: 1.2383 Loss_G: 1.0360 D(x): 0.5038 D(G(z)): 0.4038 / 0.3596\n",
      "[7/25][83/93] Loss_D: 1.2910 Loss_G: 0.7422 D(x): 0.4916 D(G(z)): 0.4255 / 0.4893\n",
      "[7/25][84/93] Loss_D: 1.3533 Loss_G: 1.3319 D(x): 0.5951 D(G(z)): 0.5509 / 0.2700\n",
      "[7/25][85/93] Loss_D: 1.3497 Loss_G: 0.6022 D(x): 0.4200 D(G(z)): 0.3578 / 0.5524\n",
      "[7/25][86/93] Loss_D: 1.5127 Loss_G: 1.4314 D(x): 0.6405 D(G(z)): 0.6405 / 0.2455\n",
      "[7/25][87/93] Loss_D: 1.4649 Loss_G: 0.4797 D(x): 0.3447 D(G(z)): 0.2899 / 0.6315\n",
      "[7/25][88/93] Loss_D: 1.4458 Loss_G: 1.7060 D(x): 0.7114 D(G(z)): 0.6531 / 0.1955\n",
      "[7/25][89/93] Loss_D: 1.4942 Loss_G: 0.5282 D(x): 0.3377 D(G(z)): 0.2748 / 0.6020\n",
      "[7/25][90/93] Loss_D: 1.2572 Loss_G: 1.9793 D(x): 0.8082 D(G(z)): 0.6319 / 0.1503\n",
      "[7/25][91/93] Loss_D: 1.4277 Loss_G: 0.7832 D(x): 0.3344 D(G(z)): 0.2166 / 0.4683\n",
      "[7/25][92/93] Loss_D: 1.1174 Loss_G: 1.1051 D(x): 0.6828 D(G(z)): 0.5059 / 0.3443\n",
      "[8/25][0/93] Loss_D: 1.0229 Loss_G: 1.8251 D(x): 0.6971 D(G(z)): 0.4663 / 0.1754\n",
      "[8/25][1/93] Loss_D: 1.2105 Loss_G: 0.7925 D(x): 0.3870 D(G(z)): 0.1907 / 0.4655\n",
      "[8/25][2/93] Loss_D: 1.5250 Loss_G: 0.9946 D(x): 0.6666 D(G(z)): 0.6329 / 0.3985\n",
      "[8/25][3/93] Loss_D: 1.3227 Loss_G: 1.0590 D(x): 0.5131 D(G(z)): 0.4481 / 0.3634\n",
      "[8/25][4/93] Loss_D: 1.4507 Loss_G: 0.5424 D(x): 0.4101 D(G(z)): 0.4080 / 0.5898\n",
      "[8/25][5/93] Loss_D: 1.4008 Loss_G: 1.3481 D(x): 0.6887 D(G(z)): 0.6203 / 0.2776\n",
      "[8/25][6/93] Loss_D: 1.1952 Loss_G: 0.9171 D(x): 0.4811 D(G(z)): 0.3430 / 0.4160\n",
      "[8/25][7/93] Loss_D: 1.2953 Loss_G: 1.0429 D(x): 0.6013 D(G(z)): 0.5234 / 0.3598\n",
      "[8/25][8/93] Loss_D: 1.2844 Loss_G: 0.8768 D(x): 0.5053 D(G(z)): 0.4227 / 0.4300\n",
      "[8/25][9/93] Loss_D: 1.1448 Loss_G: 1.2614 D(x): 0.6470 D(G(z)): 0.4900 / 0.2982\n",
      "[8/25][10/93] Loss_D: 1.2017 Loss_G: 0.8200 D(x): 0.4915 D(G(z)): 0.3576 / 0.4519\n",
      "[8/25][11/93] Loss_D: 1.2650 Loss_G: 1.5090 D(x): 0.6554 D(G(z)): 0.5564 / 0.2265\n",
      "[8/25][12/93] Loss_D: 1.1886 Loss_G: 0.6679 D(x): 0.4287 D(G(z)): 0.2631 / 0.5270\n",
      "[8/25][13/93] Loss_D: 1.4006 Loss_G: 1.4745 D(x): 0.6682 D(G(z)): 0.6136 / 0.2375\n",
      "[8/25][14/93] Loss_D: 1.3520 Loss_G: 0.7624 D(x): 0.3992 D(G(z)): 0.3136 / 0.4739\n",
      "[8/25][15/93] Loss_D: 1.2314 Loss_G: 1.2646 D(x): 0.6713 D(G(z)): 0.5520 / 0.2892\n",
      "[8/25][16/93] Loss_D: 1.2444 Loss_G: 0.9353 D(x): 0.4772 D(G(z)): 0.3756 / 0.3973\n",
      "[8/25][17/93] Loss_D: 1.3319 Loss_G: 0.6708 D(x): 0.4990 D(G(z)): 0.4464 / 0.5157\n",
      "[8/25][18/93] Loss_D: 1.4116 Loss_G: 1.2162 D(x): 0.6359 D(G(z)): 0.6069 / 0.3097\n",
      "[8/25][19/93] Loss_D: 1.3520 Loss_G: 0.5907 D(x): 0.4217 D(G(z)): 0.3578 / 0.5595\n",
      "[8/25][20/93] Loss_D: 1.2977 Loss_G: 1.3637 D(x): 0.6741 D(G(z)): 0.5832 / 0.2637\n",
      "[8/25][21/93] Loss_D: 1.1956 Loss_G: 0.7329 D(x): 0.4545 D(G(z)): 0.3176 / 0.4917\n",
      "[8/25][22/93] Loss_D: 1.2526 Loss_G: 1.6706 D(x): 0.6897 D(G(z)): 0.5719 / 0.1967\n",
      "[8/25][23/93] Loss_D: 1.1964 Loss_G: 0.7649 D(x): 0.4384 D(G(z)): 0.2690 / 0.4721\n",
      "[8/25][24/93] Loss_D: 1.4555 Loss_G: 1.2591 D(x): 0.5930 D(G(z)): 0.5939 / 0.2883\n",
      "[8/25][25/93] Loss_D: 1.5367 Loss_G: 0.7694 D(x): 0.3667 D(G(z)): 0.3923 / 0.4702\n",
      "[8/25][26/93] Loss_D: 1.3125 Loss_G: 0.9938 D(x): 0.5630 D(G(z)): 0.5021 / 0.3814\n",
      "[8/25][27/93] Loss_D: 1.2194 Loss_G: 1.2168 D(x): 0.5630 D(G(z)): 0.4556 / 0.3055\n",
      "[8/25][28/93] Loss_D: 1.1229 Loss_G: 0.9399 D(x): 0.5402 D(G(z)): 0.3761 / 0.4005\n",
      "[8/25][29/93] Loss_D: 1.3086 Loss_G: 1.4933 D(x): 0.6080 D(G(z)): 0.5389 / 0.2398\n",
      "[8/25][30/93] Loss_D: 1.0341 Loss_G: 1.5839 D(x): 0.6032 D(G(z)): 0.3517 / 0.2140\n",
      "[8/25][31/93] Loss_D: 1.5502 Loss_G: 0.3630 D(x): 0.3398 D(G(z)): 0.2934 / 0.7023\n",
      "[8/25][32/93] Loss_D: 1.8989 Loss_G: 2.1605 D(x): 0.7566 D(G(z)): 0.7907 / 0.1338\n",
      "[8/25][33/93] Loss_D: 1.1389 Loss_G: 1.4280 D(x): 0.5062 D(G(z)): 0.2368 / 0.2724\n",
      "[8/25][34/93] Loss_D: 1.1777 Loss_G: 0.4272 D(x): 0.4926 D(G(z)): 0.3218 / 0.6650\n",
      "[8/25][35/93] Loss_D: 1.6937 Loss_G: 1.8769 D(x): 0.8143 D(G(z)): 0.7534 / 0.1695\n",
      "[8/25][36/93] Loss_D: 1.7150 Loss_G: 0.7120 D(x): 0.2673 D(G(z)): 0.2610 / 0.5052\n",
      "[8/25][37/93] Loss_D: 1.1856 Loss_G: 1.1841 D(x): 0.6931 D(G(z)): 0.5397 / 0.3220\n",
      "[8/25][38/93] Loss_D: 1.3017 Loss_G: 1.1798 D(x): 0.5251 D(G(z)): 0.4449 / 0.3167\n",
      "[8/25][39/93] Loss_D: 1.1529 Loss_G: 1.0743 D(x): 0.5480 D(G(z)): 0.3870 / 0.3496\n",
      "[8/25][40/93] Loss_D: 1.2914 Loss_G: 0.9463 D(x): 0.5359 D(G(z)): 0.4634 / 0.3935\n",
      "[8/25][41/93] Loss_D: 1.1128 Loss_G: 1.3056 D(x): 0.6159 D(G(z)): 0.4444 / 0.2793\n",
      "[8/25][42/93] Loss_D: 1.2732 Loss_G: 0.7030 D(x): 0.4544 D(G(z)): 0.3588 / 0.5080\n",
      "[8/25][43/93] Loss_D: 1.3443 Loss_G: 1.3055 D(x): 0.6674 D(G(z)): 0.5990 / 0.2898\n",
      "[8/25][44/93] Loss_D: 1.3357 Loss_G: 0.5690 D(x): 0.4315 D(G(z)): 0.3630 / 0.5729\n",
      "[8/25][45/93] Loss_D: 1.3887 Loss_G: 1.8329 D(x): 0.7233 D(G(z)): 0.6350 / 0.1767\n",
      "[8/25][46/93] Loss_D: 1.3999 Loss_G: 0.5557 D(x): 0.3416 D(G(z)): 0.2134 / 0.5808\n",
      "[8/25][47/93] Loss_D: 1.4950 Loss_G: 1.7963 D(x): 0.7600 D(G(z)): 0.6925 / 0.1732\n",
      "[8/25][48/93] Loss_D: 1.8423 Loss_G: 0.5682 D(x): 0.2154 D(G(z)): 0.2257 / 0.5736\n",
      "[8/25][49/93] Loss_D: 1.3173 Loss_G: 1.3325 D(x): 0.7151 D(G(z)): 0.6072 / 0.2738\n",
      "[8/25][50/93] Loss_D: 1.1997 Loss_G: 1.2889 D(x): 0.5356 D(G(z)): 0.4099 / 0.2911\n",
      "[8/25][51/93] Loss_D: 1.3264 Loss_G: 0.6623 D(x): 0.4286 D(G(z)): 0.3531 / 0.5313\n",
      "[8/25][52/93] Loss_D: 1.2907 Loss_G: 1.1067 D(x): 0.6861 D(G(z)): 0.5818 / 0.3447\n",
      "[8/25][53/93] Loss_D: 1.2576 Loss_G: 0.9443 D(x): 0.5112 D(G(z)): 0.4145 / 0.4044\n",
      "[8/25][54/93] Loss_D: 1.2890 Loss_G: 0.8075 D(x): 0.4994 D(G(z)): 0.4269 / 0.4513\n",
      "[8/25][55/93] Loss_D: 1.2457 Loss_G: 1.0106 D(x): 0.5993 D(G(z)): 0.5100 / 0.3706\n",
      "[8/25][56/93] Loss_D: 1.1915 Loss_G: 0.9234 D(x): 0.5527 D(G(z)): 0.4362 / 0.4027\n",
      "[8/25][57/93] Loss_D: 1.0723 Loss_G: 1.1155 D(x): 0.6255 D(G(z)): 0.4438 / 0.3338\n",
      "[8/25][58/93] Loss_D: 0.8285 Loss_G: 1.9080 D(x): 0.7546 D(G(z)): 0.3877 / 0.1589\n",
      "[8/25][59/93] Loss_D: 1.7427 Loss_G: 0.3056 D(x): 0.2453 D(G(z)): 0.2123 / 0.7467\n",
      "[8/25][60/93] Loss_D: 1.7408 Loss_G: 1.4691 D(x): 0.8398 D(G(z)): 0.7760 / 0.2398\n",
      "[8/25][61/93] Loss_D: 1.1613 Loss_G: 1.2681 D(x): 0.4617 D(G(z)): 0.2829 / 0.2871\n",
      "[8/25][62/93] Loss_D: 1.3427 Loss_G: 0.6781 D(x): 0.4608 D(G(z)): 0.4092 / 0.5212\n",
      "[8/25][63/93] Loss_D: 1.3246 Loss_G: 1.1652 D(x): 0.6441 D(G(z)): 0.5640 / 0.3211\n",
      "[8/25][64/93] Loss_D: 1.1806 Loss_G: 1.0885 D(x): 0.5471 D(G(z)): 0.4125 / 0.3487\n",
      "[8/25][65/93] Loss_D: 1.2253 Loss_G: 0.6344 D(x): 0.4749 D(G(z)): 0.3487 / 0.5397\n",
      "[8/25][66/93] Loss_D: 1.3462 Loss_G: 1.6063 D(x): 0.7432 D(G(z)): 0.6342 / 0.2130\n",
      "[8/25][67/93] Loss_D: 1.5108 Loss_G: 0.6569 D(x): 0.3235 D(G(z)): 0.2576 / 0.5363\n",
      "[8/25][68/93] Loss_D: 1.3499 Loss_G: 1.1086 D(x): 0.6574 D(G(z)): 0.5825 / 0.3473\n",
      "[8/25][69/93] Loss_D: 1.1903 Loss_G: 1.0602 D(x): 0.5293 D(G(z)): 0.4053 / 0.3591\n",
      "[8/25][70/93] Loss_D: 1.1649 Loss_G: 1.0281 D(x): 0.5544 D(G(z)): 0.4111 / 0.3767\n",
      "[8/25][71/93] Loss_D: 1.2701 Loss_G: 0.9078 D(x): 0.5521 D(G(z)): 0.4723 / 0.4169\n",
      "[8/25][72/93] Loss_D: 1.3286 Loss_G: 0.9531 D(x): 0.5199 D(G(z)): 0.4650 / 0.3972\n",
      "[8/25][73/93] Loss_D: 1.2428 Loss_G: 0.9340 D(x): 0.5551 D(G(z)): 0.4615 / 0.3997\n",
      "[8/25][74/93] Loss_D: 1.3876 Loss_G: 1.0265 D(x): 0.5227 D(G(z)): 0.5019 / 0.3660\n",
      "[8/25][75/93] Loss_D: 1.3595 Loss_G: 0.8195 D(x): 0.4611 D(G(z)): 0.4272 / 0.4466\n",
      "[8/25][76/93] Loss_D: 1.2905 Loss_G: 0.7675 D(x): 0.5215 D(G(z)): 0.4566 / 0.4699\n",
      "[8/25][77/93] Loss_D: 1.0987 Loss_G: 1.5639 D(x): 0.7212 D(G(z)): 0.5129 / 0.2202\n",
      "[8/25][78/93] Loss_D: 1.1697 Loss_G: 0.8541 D(x): 0.4628 D(G(z)): 0.2510 / 0.4359\n",
      "[8/25][79/93] Loss_D: 1.1463 Loss_G: 0.9994 D(x): 0.6506 D(G(z)): 0.5002 / 0.3753\n",
      "[8/25][80/93] Loss_D: 1.2591 Loss_G: 0.7533 D(x): 0.4981 D(G(z)): 0.4118 / 0.4774\n",
      "[8/25][81/93] Loss_D: 1.1565 Loss_G: 1.8326 D(x): 0.7176 D(G(z)): 0.5490 / 0.1681\n",
      "[8/25][82/93] Loss_D: 1.1346 Loss_G: 0.9478 D(x): 0.4686 D(G(z)): 0.1934 / 0.3918\n",
      "[8/25][83/93] Loss_D: 1.2999 Loss_G: 0.9373 D(x): 0.5842 D(G(z)): 0.5190 / 0.3971\n",
      "[8/25][84/93] Loss_D: 1.1950 Loss_G: 1.0716 D(x): 0.5614 D(G(z)): 0.4489 / 0.3539\n",
      "[8/25][85/93] Loss_D: 1.2116 Loss_G: 0.8584 D(x): 0.5214 D(G(z)): 0.4106 / 0.4302\n",
      "[8/25][86/93] Loss_D: 1.2100 Loss_G: 1.0922 D(x): 0.5884 D(G(z)): 0.4819 / 0.3439\n",
      "[8/25][87/93] Loss_D: 1.1635 Loss_G: 1.5640 D(x): 0.6231 D(G(z)): 0.4783 / 0.2180\n",
      "[8/25][88/93] Loss_D: 1.3661 Loss_G: 0.3487 D(x): 0.3684 D(G(z)): 0.2740 / 0.7103\n",
      "[8/25][89/93] Loss_D: 1.6237 Loss_G: 2.2961 D(x): 0.8114 D(G(z)): 0.7448 / 0.1055\n",
      "[8/25][90/93] Loss_D: 1.6769 Loss_G: 0.5229 D(x): 0.2408 D(G(z)): 0.1463 / 0.5997\n",
      "[8/25][91/93] Loss_D: 1.4405 Loss_G: 1.3324 D(x): 0.7280 D(G(z)): 0.6629 / 0.2740\n",
      "[8/25][92/93] Loss_D: 1.1876 Loss_G: 1.0027 D(x): 0.4846 D(G(z)): 0.3421 / 0.3778\n",
      "[9/25][0/93] Loss_D: 1.0533 Loss_G: 0.9818 D(x): 0.6124 D(G(z)): 0.4119 / 0.3905\n",
      "[9/25][1/93] Loss_D: 1.1980 Loss_G: 1.3763 D(x): 0.6335 D(G(z)): 0.5109 / 0.2628\n",
      "[9/25][2/93] Loss_D: 1.1934 Loss_G: 0.8996 D(x): 0.4811 D(G(z)): 0.3372 / 0.4192\n",
      "[9/25][3/93] Loss_D: 1.1725 Loss_G: 1.5526 D(x): 0.6714 D(G(z)): 0.5130 / 0.2194\n",
      "[9/25][4/93] Loss_D: 1.3654 Loss_G: 0.6293 D(x): 0.3703 D(G(z)): 0.2767 / 0.5439\n",
      "[9/25][5/93] Loss_D: 1.2804 Loss_G: 1.6298 D(x): 0.7282 D(G(z)): 0.6034 / 0.2037\n",
      "[9/25][6/93] Loss_D: 1.1268 Loss_G: 1.3244 D(x): 0.5613 D(G(z)): 0.3302 / 0.2767\n",
      "[9/25][7/93] Loss_D: 1.2358 Loss_G: 0.6130 D(x): 0.4593 D(G(z)): 0.3453 / 0.5562\n",
      "[9/25][8/93] Loss_D: 1.4125 Loss_G: 2.0682 D(x): 0.7809 D(G(z)): 0.6661 / 0.1434\n",
      "[9/25][9/93] Loss_D: 2.1603 Loss_G: 0.3992 D(x): 0.1597 D(G(z)): 0.2011 / 0.6790\n",
      "[9/25][10/93] Loss_D: 1.7896 Loss_G: 1.0656 D(x): 0.7326 D(G(z)): 0.7451 / 0.3669\n",
      "[9/25][11/93] Loss_D: 1.1589 Loss_G: 1.0968 D(x): 0.5356 D(G(z)): 0.3842 / 0.3589\n",
      "[9/25][12/93] Loss_D: 1.1998 Loss_G: 1.1266 D(x): 0.6023 D(G(z)): 0.4758 / 0.3467\n",
      "[9/25][13/93] Loss_D: 1.2375 Loss_G: 1.3739 D(x): 0.6190 D(G(z)): 0.5018 / 0.2721\n",
      "[9/25][14/93] Loss_D: 1.3162 Loss_G: 0.8998 D(x): 0.4822 D(G(z)): 0.4124 / 0.4256\n",
      "[9/25][15/93] Loss_D: 1.2763 Loss_G: 1.6801 D(x): 0.6247 D(G(z)): 0.5230 / 0.1962\n",
      "[9/25][16/93] Loss_D: 1.2825 Loss_G: 0.6636 D(x): 0.4157 D(G(z)): 0.2886 / 0.5219\n",
      "[9/25][17/93] Loss_D: 1.3003 Loss_G: 1.7504 D(x): 0.6970 D(G(z)): 0.5994 / 0.1873\n",
      "[9/25][18/93] Loss_D: 1.2206 Loss_G: 0.6159 D(x): 0.4104 D(G(z)): 0.2491 / 0.5468\n",
      "[9/25][19/93] Loss_D: 1.4398 Loss_G: 1.0731 D(x): 0.6135 D(G(z)): 0.5980 / 0.3509\n",
      "[9/25][20/93] Loss_D: 1.0800 Loss_G: 1.4898 D(x): 0.6304 D(G(z)): 0.4465 / 0.2320\n",
      "[9/25][21/93] Loss_D: 1.3156 Loss_G: 0.7039 D(x): 0.4262 D(G(z)): 0.3418 / 0.5019\n",
      "[9/25][22/93] Loss_D: 1.1414 Loss_G: 1.8744 D(x): 0.7630 D(G(z)): 0.5634 / 0.1616\n",
      "[9/25][23/93] Loss_D: 1.6224 Loss_G: 0.4595 D(x): 0.2656 D(G(z)): 0.2132 / 0.6380\n",
      "[9/25][24/93] Loss_D: 1.5043 Loss_G: 1.5314 D(x): 0.7809 D(G(z)): 0.7008 / 0.2234\n",
      "[9/25][25/93] Loss_D: 1.2314 Loss_G: 0.9454 D(x): 0.4268 D(G(z)): 0.2947 / 0.3977\n",
      "[9/25][26/93] Loss_D: 1.1551 Loss_G: 1.3417 D(x): 0.6642 D(G(z)): 0.5060 / 0.2754\n",
      "[9/25][27/93] Loss_D: 1.0584 Loss_G: 1.2627 D(x): 0.5625 D(G(z)): 0.3621 / 0.3018\n",
      "[9/25][28/93] Loss_D: 1.1709 Loss_G: 1.3438 D(x): 0.5885 D(G(z)): 0.4384 / 0.2853\n",
      "[9/25][29/93] Loss_D: 1.6543 Loss_G: 1.4543 D(x): 0.4580 D(G(z)): 0.5515 / 0.2452\n",
      "[9/25][30/93] Loss_D: 1.6025 Loss_G: 0.7090 D(x): 0.3528 D(G(z)): 0.3844 / 0.5171\n",
      "[9/25][31/93] Loss_D: 1.4422 Loss_G: 3.0369 D(x): 0.7888 D(G(z)): 0.6818 / 0.0578\n",
      "[9/25][32/93] Loss_D: 1.1013 Loss_G: 1.4735 D(x): 0.5139 D(G(z)): 0.2130 / 0.2559\n",
      "[9/25][33/93] Loss_D: 1.5495 Loss_G: 0.5148 D(x): 0.4085 D(G(z)): 0.4051 / 0.6189\n",
      "[9/25][34/93] Loss_D: 1.6469 Loss_G: 1.8687 D(x): 0.7017 D(G(z)): 0.6935 / 0.1895\n",
      "[9/25][35/93] Loss_D: 1.3287 Loss_G: 0.8761 D(x): 0.3907 D(G(z)): 0.2368 / 0.4332\n",
      "[9/25][36/93] Loss_D: 1.2429 Loss_G: 1.5353 D(x): 0.7320 D(G(z)): 0.5867 / 0.2380\n",
      "[9/25][37/93] Loss_D: 1.4605 Loss_G: 0.8063 D(x): 0.4426 D(G(z)): 0.4232 / 0.4595\n",
      "[9/25][38/93] Loss_D: 1.2377 Loss_G: 1.6166 D(x): 0.6765 D(G(z)): 0.5510 / 0.2090\n",
      "[9/25][39/93] Loss_D: 1.3265 Loss_G: 0.9419 D(x): 0.4337 D(G(z)): 0.3463 / 0.4025\n",
      "[9/25][40/93] Loss_D: 1.2399 Loss_G: 1.2795 D(x): 0.6011 D(G(z)): 0.4945 / 0.2972\n",
      "[9/25][41/93] Loss_D: 1.0819 Loss_G: 1.4108 D(x): 0.5560 D(G(z)): 0.3704 / 0.2567\n",
      "[9/25][42/93] Loss_D: 1.2762 Loss_G: 0.9330 D(x): 0.4978 D(G(z)): 0.4103 / 0.4061\n",
      "[9/25][43/93] Loss_D: 1.2873 Loss_G: 1.0910 D(x): 0.5533 D(G(z)): 0.4765 / 0.3495\n",
      "[9/25][44/93] Loss_D: 1.1815 Loss_G: 1.2769 D(x): 0.5570 D(G(z)): 0.4246 / 0.2924\n",
      "[9/25][45/93] Loss_D: 1.3008 Loss_G: 0.5268 D(x): 0.4623 D(G(z)): 0.3861 / 0.6058\n",
      "[9/25][46/93] Loss_D: 1.4959 Loss_G: 2.1874 D(x): 0.7536 D(G(z)): 0.6861 / 0.1300\n",
      "[9/25][47/93] Loss_D: 1.8290 Loss_G: 0.3778 D(x): 0.2109 D(G(z)): 0.1518 / 0.6879\n",
      "[9/25][48/93] Loss_D: 1.5402 Loss_G: 1.4167 D(x): 0.7855 D(G(z)): 0.7158 / 0.2536\n",
      "[9/25][49/93] Loss_D: 1.4108 Loss_G: 0.9304 D(x): 0.4118 D(G(z)): 0.3749 / 0.4050\n",
      "[9/25][50/93] Loss_D: 1.2385 Loss_G: 0.8951 D(x): 0.5599 D(G(z)): 0.4668 / 0.4200\n",
      "[9/25][51/93] Loss_D: 1.2307 Loss_G: 1.0017 D(x): 0.5585 D(G(z)): 0.4593 / 0.3795\n",
      "[9/25][52/93] Loss_D: 1.0312 Loss_G: 1.3314 D(x): 0.6560 D(G(z)): 0.4441 / 0.2705\n",
      "[9/25][53/93] Loss_D: 0.8428 Loss_G: 1.5269 D(x): 0.6508 D(G(z)): 0.3088 / 0.2303\n",
      "[9/25][54/93] Loss_D: 1.2203 Loss_G: 0.6288 D(x): 0.4622 D(G(z)): 0.3405 / 0.5392\n",
      "[9/25][55/93] Loss_D: 1.2302 Loss_G: 1.4337 D(x): 0.7113 D(G(z)): 0.5760 / 0.2495\n",
      "[9/25][56/93] Loss_D: 1.2412 Loss_G: 0.7490 D(x): 0.4381 D(G(z)): 0.3266 / 0.4804\n",
      "[9/25][57/93] Loss_D: 1.2488 Loss_G: 1.0591 D(x): 0.6151 D(G(z)): 0.5206 / 0.3534\n",
      "[9/25][58/93] Loss_D: 1.1425 Loss_G: 1.2430 D(x): 0.5941 D(G(z)): 0.4468 / 0.3008\n",
      "[9/25][59/93] Loss_D: 1.2484 Loss_G: 0.7259 D(x): 0.4604 D(G(z)): 0.3502 / 0.4894\n",
      "[9/25][60/93] Loss_D: 1.0560 Loss_G: 2.1173 D(x): 0.8103 D(G(z)): 0.5587 / 0.1262\n",
      "[9/25][61/93] Loss_D: 1.6919 Loss_G: 0.5635 D(x): 0.2432 D(G(z)): 0.1901 / 0.5806\n",
      "[9/25][62/93] Loss_D: 1.3400 Loss_G: 1.1336 D(x): 0.6900 D(G(z)): 0.6072 / 0.3294\n",
      "[9/25][63/93] Loss_D: 1.1383 Loss_G: 1.2234 D(x): 0.5477 D(G(z)): 0.4013 / 0.2976\n",
      "[9/25][64/93] Loss_D: 1.1679 Loss_G: 1.0373 D(x): 0.5251 D(G(z)): 0.3925 / 0.3641\n",
      "[9/25][65/93] Loss_D: 1.1585 Loss_G: 1.2946 D(x): 0.6134 D(G(z)): 0.4727 / 0.2892\n",
      "[9/25][66/93] Loss_D: 0.9021 Loss_G: 1.6113 D(x): 0.6778 D(G(z)): 0.3667 / 0.2133\n",
      "[9/25][67/93] Loss_D: 1.3237 Loss_G: 0.4514 D(x): 0.4294 D(G(z)): 0.3335 / 0.6671\n",
      "[9/25][68/93] Loss_D: 1.6288 Loss_G: 2.2550 D(x): 0.8019 D(G(z)): 0.7347 / 0.1224\n",
      "[9/25][69/93] Loss_D: 1.9689 Loss_G: 0.4348 D(x): 0.1921 D(G(z)): 0.1307 / 0.6529\n",
      "[9/25][70/93] Loss_D: 1.7426 Loss_G: 1.2913 D(x): 0.8013 D(G(z)): 0.7659 / 0.2988\n",
      "[9/25][71/93] Loss_D: 1.2304 Loss_G: 1.0831 D(x): 0.4357 D(G(z)): 0.2941 / 0.3526\n",
      "[9/25][72/93] Loss_D: 1.0779 Loss_G: 1.4996 D(x): 0.7267 D(G(z)): 0.5146 / 0.2396\n",
      "[9/25][73/93] Loss_D: 1.0775 Loss_G: 0.9746 D(x): 0.5113 D(G(z)): 0.3067 / 0.4043\n",
      "[9/25][74/93] Loss_D: 1.2867 Loss_G: 1.4338 D(x): 0.6870 D(G(z)): 0.5747 / 0.2548\n",
      "[9/25][75/93] Loss_D: 1.3403 Loss_G: 0.9517 D(x): 0.4534 D(G(z)): 0.3932 / 0.4027\n",
      "[9/25][76/93] Loss_D: 1.4897 Loss_G: 1.1185 D(x): 0.5311 D(G(z)): 0.5482 / 0.3376\n",
      "[9/25][77/93] Loss_D: 1.3255 Loss_G: 1.1644 D(x): 0.4934 D(G(z)): 0.4424 / 0.3206\n",
      "[9/25][78/93] Loss_D: 1.3564 Loss_G: 1.0728 D(x): 0.4630 D(G(z)): 0.4167 / 0.3548\n",
      "[9/25][79/93] Loss_D: 1.1330 Loss_G: 1.4280 D(x): 0.6139 D(G(z)): 0.4533 / 0.2502\n",
      "[9/25][80/93] Loss_D: 1.2448 Loss_G: 1.1602 D(x): 0.5226 D(G(z)): 0.4281 / 0.3210\n",
      "[9/25][81/93] Loss_D: 1.2660 Loss_G: 1.1119 D(x): 0.5465 D(G(z)): 0.4670 / 0.3372\n",
      "[9/25][82/93] Loss_D: 1.1421 Loss_G: 2.0389 D(x): 0.6168 D(G(z)): 0.4707 / 0.1403\n",
      "[9/25][83/93] Loss_D: 1.4588 Loss_G: 0.2559 D(x): 0.3413 D(G(z)): 0.2621 / 0.7773\n",
      "[9/25][84/93] Loss_D: 1.7797 Loss_G: 2.9759 D(x): 0.9069 D(G(z)): 0.8046 / 0.0687\n",
      "[9/25][85/93] Loss_D: 1.6514 Loss_G: 1.1266 D(x): 0.2712 D(G(z)): 0.1043 / 0.3416\n",
      "[9/25][86/93] Loss_D: 1.1571 Loss_G: 0.6298 D(x): 0.5799 D(G(z)): 0.4294 / 0.5403\n",
      "[9/25][87/93] Loss_D: 1.4193 Loss_G: 1.4953 D(x): 0.7082 D(G(z)): 0.6370 / 0.2515\n",
      "[9/25][88/93] Loss_D: 1.1575 Loss_G: 0.8831 D(x): 0.4679 D(G(z)): 0.2704 / 0.4247\n",
      "[9/25][89/93] Loss_D: 1.1261 Loss_G: 1.4967 D(x): 0.7583 D(G(z)): 0.5458 / 0.2463\n",
      "[9/25][90/93] Loss_D: 1.0804 Loss_G: 1.2365 D(x): 0.5483 D(G(z)): 0.3379 / 0.3039\n",
      "[9/25][91/93] Loss_D: 1.3169 Loss_G: 0.8946 D(x): 0.5306 D(G(z)): 0.4652 / 0.4190\n",
      "[9/25][92/93] Loss_D: 1.2967 Loss_G: 1.4067 D(x): 0.6356 D(G(z)): 0.5290 / 0.2633\n",
      "[10/25][0/93] Loss_D: 1.4666 Loss_G: 0.8131 D(x): 0.4024 D(G(z)): 0.3901 / 0.4651\n",
      "[10/25][1/93] Loss_D: 1.4146 Loss_G: 1.5658 D(x): 0.5972 D(G(z)): 0.5680 / 0.2184\n",
      "[10/25][2/93] Loss_D: 1.1628 Loss_G: 0.9550 D(x): 0.4553 D(G(z)): 0.2785 / 0.4078\n",
      "[10/25][3/93] Loss_D: 1.2399 Loss_G: 1.2883 D(x): 0.5924 D(G(z)): 0.4852 / 0.2906\n",
      "[10/25][4/93] Loss_D: 1.0898 Loss_G: 1.6894 D(x): 0.6027 D(G(z)): 0.4136 / 0.2038\n",
      "[10/25][5/93] Loss_D: 1.2230 Loss_G: 0.8894 D(x): 0.4643 D(G(z)): 0.3357 / 0.4391\n",
      "[10/25][6/93] Loss_D: 1.5418 Loss_G: 1.5318 D(x): 0.6233 D(G(z)): 0.6360 / 0.2321\n",
      "[10/25][7/93] Loss_D: 1.2903 Loss_G: 0.8041 D(x): 0.4157 D(G(z)): 0.2902 / 0.4620\n",
      "[10/25][8/93] Loss_D: 1.2177 Loss_G: 1.5376 D(x): 0.6888 D(G(z)): 0.5493 / 0.2380\n",
      "[10/25][9/93] Loss_D: 1.6540 Loss_G: 0.6879 D(x): 0.3884 D(G(z)): 0.4528 / 0.5214\n",
      "[10/25][10/93] Loss_D: 1.3615 Loss_G: 1.6905 D(x): 0.6771 D(G(z)): 0.5880 / 0.2034\n",
      "[10/25][11/93] Loss_D: 1.2109 Loss_G: 1.1163 D(x): 0.4792 D(G(z)): 0.3314 / 0.3488\n",
      "[10/25][12/93] Loss_D: 1.0046 Loss_G: 1.5238 D(x): 0.6796 D(G(z)): 0.4389 / 0.2247\n",
      "[10/25][13/93] Loss_D: 1.2966 Loss_G: 1.3662 D(x): 0.5332 D(G(z)): 0.4568 / 0.2692\n",
      "[10/25][14/93] Loss_D: 1.1155 Loss_G: 1.5109 D(x): 0.5938 D(G(z)): 0.4387 / 0.2326\n",
      "[10/25][15/93] Loss_D: 1.4119 Loss_G: 0.4228 D(x): 0.4076 D(G(z)): 0.3692 / 0.6703\n",
      "[10/25][16/93] Loss_D: 1.9894 Loss_G: 2.9651 D(x): 0.7255 D(G(z)): 0.7900 / 0.0601\n",
      "[10/25][17/93] Loss_D: 2.1827 Loss_G: 0.3927 D(x): 0.1535 D(G(z)): 0.1097 / 0.6968\n",
      "[10/25][18/93] Loss_D: 1.8096 Loss_G: 1.7883 D(x): 0.8166 D(G(z)): 0.7670 / 0.1735\n",
      "[10/25][19/93] Loss_D: 1.2694 Loss_G: 1.1728 D(x): 0.3819 D(G(z)): 0.2311 / 0.3225\n",
      "[10/25][20/93] Loss_D: 1.1316 Loss_G: 0.8754 D(x): 0.5630 D(G(z)): 0.4123 / 0.4254\n",
      "[10/25][21/93] Loss_D: 1.1824 Loss_G: 1.5566 D(x): 0.6790 D(G(z)): 0.5317 / 0.2273\n",
      "[10/25][22/93] Loss_D: 1.5142 Loss_G: 0.5789 D(x): 0.3488 D(G(z)): 0.2996 / 0.5683\n",
      "[10/25][23/93] Loss_D: 1.3904 Loss_G: 1.4318 D(x): 0.7253 D(G(z)): 0.6478 / 0.2558\n",
      "[10/25][24/93] Loss_D: 1.3502 Loss_G: 0.8262 D(x): 0.4370 D(G(z)): 0.3507 / 0.4442\n",
      "[10/25][25/93] Loss_D: 1.3246 Loss_G: 1.1629 D(x): 0.5967 D(G(z)): 0.5331 / 0.3231\n",
      "[10/25][26/93] Loss_D: 1.1497 Loss_G: 1.2559 D(x): 0.5578 D(G(z)): 0.4068 / 0.2969\n",
      "[10/25][27/93] Loss_D: 1.0257 Loss_G: 1.2596 D(x): 0.6057 D(G(z)): 0.3932 / 0.2964\n",
      "[10/25][28/93] Loss_D: 0.9244 Loss_G: 1.3312 D(x): 0.6336 D(G(z)): 0.3525 / 0.2774\n",
      "[10/25][29/93] Loss_D: 1.1733 Loss_G: 0.8766 D(x): 0.5324 D(G(z)): 0.3917 / 0.4260\n",
      "[10/25][30/93] Loss_D: 1.2852 Loss_G: 1.7845 D(x): 0.6585 D(G(z)): 0.5656 / 0.1771\n",
      "[10/25][31/93] Loss_D: 1.1693 Loss_G: 1.0214 D(x): 0.4984 D(G(z)): 0.2621 / 0.3711\n",
      "[10/25][32/93] Loss_D: 1.2066 Loss_G: 0.9555 D(x): 0.5773 D(G(z)): 0.4557 / 0.3981\n",
      "[10/25][33/93] Loss_D: 1.3926 Loss_G: 1.6286 D(x): 0.6332 D(G(z)): 0.5752 / 0.2086\n",
      "[10/25][34/93] Loss_D: 1.4857 Loss_G: 0.6156 D(x): 0.3418 D(G(z)): 0.2904 / 0.5586\n",
      "[10/25][35/93] Loss_D: 1.5817 Loss_G: 1.9977 D(x): 0.7295 D(G(z)): 0.6925 / 0.1541\n",
      "[10/25][36/93] Loss_D: 1.6820 Loss_G: 0.6530 D(x): 0.2593 D(G(z)): 0.2305 / 0.5605\n",
      "[10/25][37/93] Loss_D: 1.4000 Loss_G: 1.3083 D(x): 0.7350 D(G(z)): 0.6149 / 0.3035\n",
      "[10/25][38/93] Loss_D: 1.1147 Loss_G: 1.2778 D(x): 0.5504 D(G(z)): 0.3721 / 0.3228\n",
      "[10/25][39/93] Loss_D: 1.1026 Loss_G: 1.3521 D(x): 0.5894 D(G(z)): 0.4103 / 0.2933\n",
      "[10/25][40/93] Loss_D: 1.1500 Loss_G: 0.9228 D(x): 0.5380 D(G(z)): 0.3875 / 0.4292\n",
      "[10/25][41/93] Loss_D: 1.1694 Loss_G: 1.6452 D(x): 0.7163 D(G(z)): 0.5436 / 0.2096\n",
      "[10/25][42/93] Loss_D: 1.3341 Loss_G: 0.5745 D(x): 0.3919 D(G(z)): 0.2772 / 0.5841\n",
      "[10/25][43/93] Loss_D: 1.6590 Loss_G: 2.0421 D(x): 0.7541 D(G(z)): 0.7315 / 0.1450\n",
      "[10/25][44/93] Loss_D: 1.7046 Loss_G: 0.5603 D(x): 0.2493 D(G(z)): 0.1975 / 0.5865\n",
      "[10/25][45/93] Loss_D: 1.4091 Loss_G: 1.2736 D(x): 0.6931 D(G(z)): 0.6209 / 0.2938\n",
      "[10/25][46/93] Loss_D: 1.2101 Loss_G: 1.3836 D(x): 0.5307 D(G(z)): 0.4155 / 0.2614\n",
      "[10/25][47/93] Loss_D: 1.3879 Loss_G: 0.6483 D(x): 0.3966 D(G(z)): 0.3421 / 0.5376\n",
      "[10/25][48/93] Loss_D: 1.3806 Loss_G: 1.7909 D(x): 0.7553 D(G(z)): 0.6554 / 0.1726\n",
      "[10/25][49/93] Loss_D: 1.3359 Loss_G: 0.7088 D(x): 0.3560 D(G(z)): 0.2377 / 0.5045\n",
      "[10/25][50/93] Loss_D: 1.2179 Loss_G: 1.5400 D(x): 0.7554 D(G(z)): 0.5967 / 0.2232\n",
      "[10/25][51/93] Loss_D: 1.0326 Loss_G: 1.0785 D(x): 0.5361 D(G(z)): 0.3173 / 0.3511\n",
      "[10/25][52/93] Loss_D: 1.1566 Loss_G: 1.3955 D(x): 0.6140 D(G(z)): 0.4716 / 0.2577\n",
      "[10/25][53/93] Loss_D: 1.0972 Loss_G: 0.8754 D(x): 0.5049 D(G(z)): 0.3217 / 0.4293\n",
      "[10/25][54/93] Loss_D: 1.2095 Loss_G: 2.5181 D(x): 0.7576 D(G(z)): 0.5920 / 0.0884\n",
      "[10/25][55/93] Loss_D: 1.3084 Loss_G: 0.7870 D(x): 0.3289 D(G(z)): 0.1136 / 0.4666\n",
      "[10/25][56/93] Loss_D: 1.2123 Loss_G: 1.0354 D(x): 0.6841 D(G(z)): 0.5525 / 0.3644\n",
      "[10/25][57/93] Loss_D: 1.1190 Loss_G: 1.5507 D(x): 0.6320 D(G(z)): 0.4664 / 0.2239\n",
      "[10/25][58/93] Loss_D: 1.1802 Loss_G: 0.7693 D(x): 0.4349 D(G(z)): 0.2561 / 0.4727\n",
      "[10/25][59/93] Loss_D: 1.2470 Loss_G: 1.8624 D(x): 0.8008 D(G(z)): 0.6254 / 0.1641\n",
      "[10/25][60/93] Loss_D: 1.1412 Loss_G: 1.1460 D(x): 0.4701 D(G(z)): 0.2162 / 0.3291\n",
      "[10/25][61/93] Loss_D: 1.0424 Loss_G: 0.8711 D(x): 0.6104 D(G(z)): 0.4071 / 0.4292\n",
      "[10/25][62/93] Loss_D: 1.1475 Loss_G: 1.5898 D(x): 0.6946 D(G(z)): 0.5295 / 0.2181\n",
      "[10/25][63/93] Loss_D: 1.3758 Loss_G: 0.5957 D(x): 0.3666 D(G(z)): 0.2825 / 0.5610\n",
      "[10/25][64/93] Loss_D: 1.3971 Loss_G: 1.5175 D(x): 0.7487 D(G(z)): 0.6517 / 0.2287\n",
      "[10/25][65/93] Loss_D: 1.1816 Loss_G: 1.0195 D(x): 0.4388 D(G(z)): 0.2731 / 0.3732\n",
      "[10/25][66/93] Loss_D: 0.9877 Loss_G: 1.5037 D(x): 0.7166 D(G(z)): 0.4666 / 0.2340\n",
      "[10/25][67/93] Loss_D: 1.2181 Loss_G: 0.8942 D(x): 0.4685 D(G(z)): 0.3425 / 0.4219\n",
      "[10/25][68/93] Loss_D: 1.1862 Loss_G: 1.0337 D(x): 0.5875 D(G(z)): 0.4658 / 0.3675\n",
      "[10/25][69/93] Loss_D: 1.1712 Loss_G: 1.4715 D(x): 0.6107 D(G(z)): 0.4724 / 0.2480\n",
      "[10/25][70/93] Loss_D: 1.1490 Loss_G: 0.9286 D(x): 0.5109 D(G(z)): 0.3551 / 0.4149\n",
      "[10/25][71/93] Loss_D: 1.1612 Loss_G: 1.5960 D(x): 0.6357 D(G(z)): 0.4931 / 0.2102\n",
      "[10/25][72/93] Loss_D: 1.1592 Loss_G: 0.6884 D(x): 0.4791 D(G(z)): 0.3162 / 0.5103\n",
      "[10/25][73/93] Loss_D: 1.4443 Loss_G: 2.9080 D(x): 0.7544 D(G(z)): 0.6747 / 0.0593\n",
      "[10/25][74/93] Loss_D: 1.9232 Loss_G: 0.4121 D(x): 0.1906 D(G(z)): 0.1124 / 0.6664\n",
      "[10/25][75/93] Loss_D: 1.4116 Loss_G: 1.7605 D(x): 0.7786 D(G(z)): 0.6820 / 0.1839\n",
      "[10/25][76/93] Loss_D: 1.1590 Loss_G: 0.9332 D(x): 0.4550 D(G(z)): 0.2712 / 0.4037\n",
      "[10/25][77/93] Loss_D: 1.2995 Loss_G: 1.1522 D(x): 0.6249 D(G(z)): 0.5489 / 0.3298\n",
      "[10/25][78/93] Loss_D: 1.1468 Loss_G: 1.3762 D(x): 0.5988 D(G(z)): 0.4578 / 0.2587\n",
      "[10/25][79/93] Loss_D: 1.0949 Loss_G: 1.2156 D(x): 0.5554 D(G(z)): 0.3827 / 0.3043\n",
      "[10/25][80/93] Loss_D: 1.1106 Loss_G: 1.4435 D(x): 0.6161 D(G(z)): 0.4397 / 0.2476\n",
      "[10/25][81/93] Loss_D: 1.1018 Loss_G: 0.9472 D(x): 0.5176 D(G(z)): 0.3353 / 0.4019\n",
      "[10/25][82/93] Loss_D: 1.0548 Loss_G: 1.7785 D(x): 0.6889 D(G(z)): 0.4772 / 0.1775\n",
      "[10/25][83/93] Loss_D: 1.1575 Loss_G: 0.8554 D(x): 0.4741 D(G(z)): 0.3128 / 0.4497\n",
      "[10/25][84/93] Loss_D: 1.1825 Loss_G: 2.0536 D(x): 0.7156 D(G(z)): 0.5577 / 0.1355\n",
      "[10/25][85/93] Loss_D: 1.2768 Loss_G: 0.7114 D(x): 0.3943 D(G(z)): 0.2596 / 0.5074\n",
      "[10/25][86/93] Loss_D: 1.4115 Loss_G: 2.4013 D(x): 0.8292 D(G(z)): 0.6805 / 0.1073\n",
      "[10/25][87/93] Loss_D: 1.8256 Loss_G: 0.3003 D(x): 0.2259 D(G(z)): 0.1824 / 0.7531\n",
      "[10/25][88/93] Loss_D: 1.7158 Loss_G: 3.5177 D(x): 0.9142 D(G(z)): 0.7869 / 0.0401\n",
      "[10/25][89/93] Loss_D: 1.9098 Loss_G: 0.4541 D(x): 0.2336 D(G(z)): 0.0883 / 0.6470\n",
      "[10/25][90/93] Loss_D: 1.5413 Loss_G: 1.8579 D(x): 0.8470 D(G(z)): 0.7364 / 0.1746\n",
      "[10/25][91/93] Loss_D: 1.0525 Loss_G: 1.4819 D(x): 0.4899 D(G(z)): 0.2259 / 0.2355\n",
      "[10/25][92/93] Loss_D: 1.3508 Loss_G: 0.4309 D(x): 0.3813 D(G(z)): 0.3008 / 0.6656\n",
      "[11/25][0/93] Loss_D: 1.5970 Loss_G: 1.7568 D(x): 0.7929 D(G(z)): 0.7247 / 0.1765\n",
      "[11/25][1/93] Loss_D: 1.0989 Loss_G: 1.4537 D(x): 0.4718 D(G(z)): 0.2660 / 0.2403\n",
      "[11/25][2/93] Loss_D: 0.9637 Loss_G: 1.0246 D(x): 0.5619 D(G(z)): 0.3000 / 0.3658\n",
      "[11/25][3/93] Loss_D: 1.0705 Loss_G: 1.1785 D(x): 0.6517 D(G(z)): 0.4612 / 0.3225\n",
      "[11/25][4/93] Loss_D: 1.2118 Loss_G: 1.3066 D(x): 0.5958 D(G(z)): 0.4790 / 0.2837\n",
      "[11/25][5/93] Loss_D: 1.1390 Loss_G: 0.8970 D(x): 0.4834 D(G(z)): 0.3081 / 0.4195\n",
      "[11/25][6/93] Loss_D: 1.2429 Loss_G: 1.3736 D(x): 0.6778 D(G(z)): 0.5584 / 0.2682\n",
      "[11/25][7/93] Loss_D: 1.1325 Loss_G: 1.3251 D(x): 0.5675 D(G(z)): 0.3971 / 0.2876\n",
      "[11/25][8/93] Loss_D: 1.3227 Loss_G: 0.7713 D(x): 0.4400 D(G(z)): 0.3676 / 0.4793\n",
      "[11/25][9/93] Loss_D: 1.4217 Loss_G: 1.7073 D(x): 0.7218 D(G(z)): 0.6513 / 0.1933\n",
      "[11/25][10/93] Loss_D: 1.2311 Loss_G: 0.9890 D(x): 0.4150 D(G(z)): 0.2770 / 0.3926\n",
      "[11/25][11/93] Loss_D: 1.0415 Loss_G: 1.5384 D(x): 0.7242 D(G(z)): 0.4991 / 0.2233\n",
      "[11/25][12/93] Loss_D: 1.1969 Loss_G: 0.9938 D(x): 0.4866 D(G(z)): 0.3590 / 0.3886\n",
      "[11/25][13/93] Loss_D: 1.0961 Loss_G: 1.3582 D(x): 0.6562 D(G(z)): 0.4773 / 0.2673\n",
      "[11/25][14/93] Loss_D: 1.1836 Loss_G: 1.1982 D(x): 0.5218 D(G(z)): 0.3814 / 0.3109\n",
      "[11/25][15/93] Loss_D: 1.1893 Loss_G: 1.0932 D(x): 0.5516 D(G(z)): 0.4282 / 0.3592\n",
      "[11/25][16/93] Loss_D: 1.1363 Loss_G: 1.6647 D(x): 0.5988 D(G(z)): 0.4496 / 0.2019\n",
      "[11/25][17/93] Loss_D: 1.1756 Loss_G: 0.9227 D(x): 0.4889 D(G(z)): 0.3341 / 0.4142\n",
      "[11/25][18/93] Loss_D: 1.2992 Loss_G: 2.5968 D(x): 0.7392 D(G(z)): 0.6123 / 0.0851\n",
      "[11/25][19/93] Loss_D: 1.1723 Loss_G: 1.0606 D(x): 0.4317 D(G(z)): 0.1459 / 0.3635\n",
      "[11/25][20/93] Loss_D: 0.9926 Loss_G: 1.3501 D(x): 0.6873 D(G(z)): 0.4461 / 0.2781\n",
      "[11/25][21/93] Loss_D: 1.0866 Loss_G: 1.6772 D(x): 0.6063 D(G(z)): 0.4256 / 0.2021\n",
      "[11/25][22/93] Loss_D: 1.0252 Loss_G: 1.2390 D(x): 0.5814 D(G(z)): 0.3648 / 0.3000\n",
      "[11/25][23/93] Loss_D: 0.9703 Loss_G: 1.5512 D(x): 0.6693 D(G(z)): 0.4143 / 0.2216\n",
      "[11/25][24/93] Loss_D: 1.1643 Loss_G: 0.6200 D(x): 0.4793 D(G(z)): 0.3252 / 0.5499\n",
      "[11/25][25/93] Loss_D: 1.3966 Loss_G: 3.2204 D(x): 0.9168 D(G(z)): 0.7205 / 0.0466\n",
      "[11/25][26/93] Loss_D: 1.9839 Loss_G: 0.4439 D(x): 0.1719 D(G(z)): 0.0908 / 0.6485\n",
      "[11/25][27/93] Loss_D: 1.5856 Loss_G: 2.2068 D(x): 0.8095 D(G(z)): 0.7296 / 0.1258\n",
      "[11/25][28/93] Loss_D: 1.3705 Loss_G: 0.8221 D(x): 0.3425 D(G(z)): 0.2014 / 0.4534\n",
      "[11/25][29/93] Loss_D: 1.0443 Loss_G: 1.2628 D(x): 0.6941 D(G(z)): 0.4783 / 0.2954\n",
      "[11/25][30/93] Loss_D: 1.0258 Loss_G: 1.8767 D(x): 0.7405 D(G(z)): 0.5066 / 0.1644\n",
      "[11/25][31/93] Loss_D: 1.1512 Loss_G: 1.5896 D(x): 0.5750 D(G(z)): 0.4309 / 0.2140\n",
      "[11/25][32/93] Loss_D: 1.4393 Loss_G: 0.6695 D(x): 0.4202 D(G(z)): 0.3942 / 0.5327\n",
      "[11/25][33/93] Loss_D: 1.6703 Loss_G: 3.1846 D(x): 0.6780 D(G(z)): 0.6988 / 0.0488\n",
      "[11/25][34/93] Loss_D: 1.9170 Loss_G: 0.4537 D(x): 0.1866 D(G(z)): 0.0999 / 0.6465\n",
      "[11/25][35/93] Loss_D: 1.4503 Loss_G: 1.6205 D(x): 0.7801 D(G(z)): 0.6749 / 0.2053\n",
      "[11/25][36/93] Loss_D: 1.1945 Loss_G: 1.5921 D(x): 0.4977 D(G(z)): 0.3634 / 0.2139\n",
      "[11/25][37/93] Loss_D: 1.0982 Loss_G: 1.0692 D(x): 0.5133 D(G(z)): 0.3263 / 0.3607\n",
      "[11/25][38/93] Loss_D: 1.2494 Loss_G: 1.4910 D(x): 0.6402 D(G(z)): 0.5405 / 0.2363\n",
      "[11/25][39/93] Loss_D: 1.3563 Loss_G: 1.2753 D(x): 0.4565 D(G(z)): 0.3994 / 0.2958\n",
      "[11/25][40/93] Loss_D: 1.3795 Loss_G: 0.6746 D(x): 0.4560 D(G(z)): 0.4118 / 0.5268\n",
      "[11/25][41/93] Loss_D: 1.5141 Loss_G: 1.3456 D(x): 0.6377 D(G(z)): 0.6350 / 0.2760\n",
      "[11/25][42/93] Loss_D: 1.0609 Loss_G: 1.3663 D(x): 0.5603 D(G(z)): 0.3548 / 0.2866\n",
      "[11/25][43/93] Loss_D: 1.1084 Loss_G: 1.3103 D(x): 0.5875 D(G(z)): 0.4193 / 0.3170\n",
      "[11/25][44/93] Loss_D: 1.0331 Loss_G: 1.4363 D(x): 0.6298 D(G(z)): 0.4052 / 0.2878\n",
      "[11/25][45/93] Loss_D: 1.2043 Loss_G: 1.4595 D(x): 0.5594 D(G(z)): 0.4333 / 0.2697\n",
      "[11/25][46/93] Loss_D: 1.0962 Loss_G: 1.7890 D(x): 0.6186 D(G(z)): 0.4218 / 0.1951\n",
      "[11/25][47/93] Loss_D: 1.2799 Loss_G: 0.9727 D(x): 0.4774 D(G(z)): 0.3824 / 0.4145\n",
      "[11/25][48/93] Loss_D: 0.9437 Loss_G: 2.3594 D(x): 0.7231 D(G(z)): 0.4397 / 0.1102\n",
      "[11/25][49/93] Loss_D: 1.5245 Loss_G: 0.4831 D(x): 0.3232 D(G(z)): 0.2651 / 0.6512\n",
      "[11/25][50/93] Loss_D: 1.5590 Loss_G: 2.2913 D(x): 0.7901 D(G(z)): 0.7146 / 0.1078\n",
      "[11/25][51/93] Loss_D: 1.2201 Loss_G: 0.8377 D(x): 0.4036 D(G(z)): 0.2069 / 0.4413\n",
      "[11/25][52/93] Loss_D: 1.2053 Loss_G: 1.8179 D(x): 0.7338 D(G(z)): 0.5807 / 0.1684\n",
      "[11/25][53/93] Loss_D: 1.0739 Loss_G: 1.0135 D(x): 0.4699 D(G(z)): 0.2310 / 0.3808\n",
      "[11/25][54/93] Loss_D: 1.2420 Loss_G: 2.1880 D(x): 0.7561 D(G(z)): 0.6082 / 0.1283\n",
      "[11/25][55/93] Loss_D: 1.4310 Loss_G: 0.5534 D(x): 0.3152 D(G(z)): 0.1901 / 0.5958\n",
      "[11/25][56/93] Loss_D: 1.6745 Loss_G: 1.7607 D(x): 0.8320 D(G(z)): 0.7579 / 0.1838\n",
      "[11/25][57/93] Loss_D: 1.4004 Loss_G: 1.0504 D(x): 0.3551 D(G(z)): 0.2695 / 0.3616\n",
      "[11/25][58/93] Loss_D: 1.2353 Loss_G: 1.1956 D(x): 0.5876 D(G(z)): 0.4699 / 0.3119\n",
      "[11/25][59/93] Loss_D: 1.1091 Loss_G: 1.7290 D(x): 0.6156 D(G(z)): 0.4471 / 0.1841\n",
      "[11/25][60/93] Loss_D: 1.1070 Loss_G: 1.0049 D(x): 0.5301 D(G(z)): 0.3351 / 0.3806\n",
      "[11/25][61/93] Loss_D: 1.6682 Loss_G: 1.7156 D(x): 0.5521 D(G(z)): 0.6377 / 0.1975\n",
      "[11/25][62/93] Loss_D: 1.4610 Loss_G: 0.6912 D(x): 0.3795 D(G(z)): 0.3494 / 0.5123\n",
      "[11/25][63/93] Loss_D: 1.4326 Loss_G: 2.0232 D(x): 0.7196 D(G(z)): 0.6485 / 0.1376\n",
      "[11/25][64/93] Loss_D: 1.3709 Loss_G: 0.8701 D(x): 0.3520 D(G(z)): 0.2277 / 0.4365\n",
      "[11/25][65/93] Loss_D: 1.2541 Loss_G: 1.2951 D(x): 0.6928 D(G(z)): 0.5742 / 0.2859\n",
      "[11/25][66/93] Loss_D: 1.0601 Loss_G: 1.3830 D(x): 0.5592 D(G(z)): 0.3656 / 0.2678\n",
      "[11/25][67/93] Loss_D: 1.1808 Loss_G: 1.1252 D(x): 0.5603 D(G(z)): 0.4220 / 0.3456\n",
      "[11/25][68/93] Loss_D: 1.1617 Loss_G: 1.8382 D(x): 0.6585 D(G(z)): 0.5043 / 0.1779\n",
      "[11/25][69/93] Loss_D: 1.1360 Loss_G: 0.8726 D(x): 0.4796 D(G(z)): 0.2763 / 0.4328\n",
      "[11/25][70/93] Loss_D: 1.3278 Loss_G: 1.5613 D(x): 0.6570 D(G(z)): 0.5794 / 0.2200\n",
      "[11/25][71/93] Loss_D: 1.3825 Loss_G: 0.9766 D(x): 0.4134 D(G(z)): 0.3588 / 0.3921\n",
      "[11/25][72/93] Loss_D: 1.1889 Loss_G: 2.1565 D(x): 0.7020 D(G(z)): 0.5460 / 0.1227\n",
      "[11/25][73/93] Loss_D: 1.3890 Loss_G: 0.7525 D(x): 0.3393 D(G(z)): 0.2366 / 0.4919\n",
      "[11/25][74/93] Loss_D: 1.5172 Loss_G: 1.4044 D(x): 0.6577 D(G(z)): 0.6417 / 0.2559\n",
      "[11/25][75/93] Loss_D: 1.2799 Loss_G: 1.1159 D(x): 0.4594 D(G(z)): 0.3741 / 0.3417\n",
      "[11/25][76/93] Loss_D: 1.1781 Loss_G: 1.5743 D(x): 0.6380 D(G(z)): 0.5056 / 0.2166\n",
      "[11/25][77/93] Loss_D: 1.0047 Loss_G: 1.3383 D(x): 0.5538 D(G(z)): 0.3177 / 0.2792\n",
      "[11/25][78/93] Loss_D: 0.9890 Loss_G: 1.5189 D(x): 0.6690 D(G(z)): 0.4207 / 0.2355\n",
      "[11/25][79/93] Loss_D: 0.8466 Loss_G: 2.2625 D(x): 0.6913 D(G(z)): 0.3602 / 0.1125\n",
      "[11/25][80/93] Loss_D: 1.1380 Loss_G: 0.5231 D(x): 0.4264 D(G(z)): 0.2138 / 0.6037\n",
      "[11/25][81/93] Loss_D: 1.4352 Loss_G: 2.7354 D(x): 0.8517 D(G(z)): 0.7060 / 0.0736\n",
      "[11/25][82/93] Loss_D: 1.7297 Loss_G: 0.5398 D(x): 0.2415 D(G(z)): 0.1658 / 0.5982\n",
      "[11/25][83/93] Loss_D: 1.4262 Loss_G: 1.6052 D(x): 0.8185 D(G(z)): 0.6835 / 0.2282\n",
      "[11/25][84/93] Loss_D: 1.3602 Loss_G: 1.2450 D(x): 0.4469 D(G(z)): 0.3899 / 0.3085\n",
      "[11/25][85/93] Loss_D: 1.0060 Loss_G: 1.4213 D(x): 0.6659 D(G(z)): 0.4288 / 0.2561\n",
      "[11/25][86/93] Loss_D: 1.2530 Loss_G: 0.6955 D(x): 0.4410 D(G(z)): 0.3249 / 0.5169\n",
      "[11/25][87/93] Loss_D: 1.4770 Loss_G: 2.0903 D(x): 0.7488 D(G(z)): 0.6716 / 0.1328\n",
      "[11/25][88/93] Loss_D: 1.0347 Loss_G: 1.2133 D(x): 0.4801 D(G(z)): 0.1950 / 0.3108\n",
      "[11/25][89/93] Loss_D: 1.1075 Loss_G: 0.9548 D(x): 0.6094 D(G(z)): 0.4459 / 0.3979\n",
      "[11/25][90/93] Loss_D: 1.2261 Loss_G: 1.8825 D(x): 0.6562 D(G(z)): 0.5389 / 0.1610\n",
      "[11/25][91/93] Loss_D: 1.2422 Loss_G: 0.6938 D(x): 0.4313 D(G(z)): 0.3042 / 0.5144\n",
      "[11/25][92/93] Loss_D: 1.3325 Loss_G: 3.0570 D(x): 0.7804 D(G(z)): 0.6362 / 0.0526\n",
      "[12/25][0/93] Loss_D: 1.8791 Loss_G: 0.5491 D(x): 0.2106 D(G(z)): 0.1278 / 0.5880\n",
      "[12/25][1/93] Loss_D: 1.4724 Loss_G: 1.7458 D(x): 0.7522 D(G(z)): 0.6770 / 0.1846\n",
      "[12/25][2/93] Loss_D: 1.3458 Loss_G: 0.7788 D(x): 0.3810 D(G(z)): 0.2723 / 0.4703\n",
      "[12/25][3/93] Loss_D: 1.3486 Loss_G: 1.2165 D(x): 0.6607 D(G(z)): 0.5940 / 0.3047\n",
      "[12/25][4/93] Loss_D: 1.1115 Loss_G: 1.7149 D(x): 0.6022 D(G(z)): 0.4388 / 0.1856\n",
      "[12/25][5/93] Loss_D: 1.1041 Loss_G: 0.9082 D(x): 0.4911 D(G(z)): 0.3084 / 0.4136\n",
      "[12/25][6/93] Loss_D: 1.0200 Loss_G: 1.6074 D(x): 0.7179 D(G(z)): 0.4889 / 0.2081\n",
      "[12/25][7/93] Loss_D: 0.9543 Loss_G: 1.5357 D(x): 0.6133 D(G(z)): 0.3305 / 0.2223\n",
      "[12/25][8/93] Loss_D: 1.0327 Loss_G: 1.0280 D(x): 0.5701 D(G(z)): 0.3504 / 0.3696\n",
      "[12/25][9/93] Loss_D: 1.1847 Loss_G: 1.8768 D(x): 0.6771 D(G(z)): 0.5311 / 0.1606\n",
      "[12/25][10/93] Loss_D: 1.4415 Loss_G: 0.4909 D(x): 0.3411 D(G(z)): 0.2520 / 0.6247\n",
      "[12/25][11/93] Loss_D: 1.7401 Loss_G: 2.2483 D(x): 0.8012 D(G(z)): 0.7600 / 0.1149\n",
      "[12/25][12/93] Loss_D: 1.7747 Loss_G: 0.5306 D(x): 0.2295 D(G(z)): 0.1929 / 0.5935\n",
      "[12/25][13/93] Loss_D: 1.4744 Loss_G: 1.5422 D(x): 0.7737 D(G(z)): 0.6875 / 0.2208\n",
      "[12/25][14/93] Loss_D: 1.0511 Loss_G: 1.6454 D(x): 0.5668 D(G(z)): 0.3103 / 0.2054\n",
      "[12/25][15/93] Loss_D: 1.4143 Loss_G: 0.4510 D(x): 0.3531 D(G(z)): 0.2830 / 0.6468\n",
      "[12/25][16/93] Loss_D: 1.4599 Loss_G: 2.0182 D(x): 0.8127 D(G(z)): 0.7024 / 0.1409\n",
      "[12/25][17/93] Loss_D: 1.2432 Loss_G: 0.9636 D(x): 0.3929 D(G(z)): 0.2449 / 0.3992\n",
      "[12/25][18/93] Loss_D: 1.0725 Loss_G: 1.8562 D(x): 0.7314 D(G(z)): 0.5077 / 0.1675\n",
      "[12/25][19/93] Loss_D: 0.9669 Loss_G: 1.9701 D(x): 0.6066 D(G(z)): 0.3510 / 0.1513\n",
      "[12/25][20/93] Loss_D: 1.5577 Loss_G: 0.4619 D(x): 0.3270 D(G(z)): 0.2799 / 0.6404\n",
      "[12/25][21/93] Loss_D: 1.4422 Loss_G: 1.8912 D(x): 0.8503 D(G(z)): 0.7003 / 0.1652\n",
      "[12/25][22/93] Loss_D: 1.4104 Loss_G: 0.8081 D(x): 0.3414 D(G(z)): 0.2440 / 0.4574\n",
      "[12/25][23/93] Loss_D: 1.3578 Loss_G: 0.9192 D(x): 0.6115 D(G(z)): 0.5601 / 0.4093\n",
      "[12/25][24/93] Loss_D: 1.2916 Loss_G: 1.2757 D(x): 0.5789 D(G(z)): 0.5020 / 0.2890\n",
      "[12/25][25/93] Loss_D: 0.9447 Loss_G: 1.4612 D(x): 0.6252 D(G(z)): 0.3478 / 0.2412\n",
      "[12/25][26/93] Loss_D: 1.5647 Loss_G: 0.5274 D(x): 0.3681 D(G(z)): 0.3906 / 0.5965\n",
      "[12/25][27/93] Loss_D: 1.4758 Loss_G: 1.2520 D(x): 0.7161 D(G(z)): 0.6717 / 0.2948\n",
      "[12/25][28/93] Loss_D: 1.3233 Loss_G: 0.9084 D(x): 0.4509 D(G(z)): 0.3787 / 0.4119\n",
      "[12/25][29/93] Loss_D: 1.2523 Loss_G: 1.1339 D(x): 0.6044 D(G(z)): 0.5138 / 0.3279\n",
      "[12/25][30/93] Loss_D: 1.4012 Loss_G: 0.9143 D(x): 0.4449 D(G(z)): 0.4223 / 0.4260\n",
      "[12/25][31/93] Loss_D: 1.1511 Loss_G: 1.8337 D(x): 0.7109 D(G(z)): 0.5392 / 0.1647\n",
      "[12/25][32/93] Loss_D: 1.4213 Loss_G: 0.5129 D(x): 0.3285 D(G(z)): 0.2247 / 0.6128\n",
      "[12/25][33/93] Loss_D: 1.4539 Loss_G: 1.7817 D(x): 0.7591 D(G(z)): 0.6752 / 0.1737\n",
      "[12/25][34/93] Loss_D: 1.2649 Loss_G: 0.9583 D(x): 0.4090 D(G(z)): 0.2645 / 0.3918\n",
      "[12/25][35/93] Loss_D: 0.9722 Loss_G: 1.4089 D(x): 0.7197 D(G(z)): 0.4522 / 0.2545\n",
      "[12/25][36/93] Loss_D: 1.1341 Loss_G: 0.9890 D(x): 0.5107 D(G(z)): 0.3277 / 0.3801\n",
      "[12/25][37/93] Loss_D: 1.0992 Loss_G: 1.2647 D(x): 0.6450 D(G(z)): 0.4722 / 0.2875\n",
      "[12/25][38/93] Loss_D: 1.1182 Loss_G: 1.0739 D(x): 0.5450 D(G(z)): 0.3813 / 0.3522\n",
      "[12/25][39/93] Loss_D: 1.1582 Loss_G: 1.0051 D(x): 0.5766 D(G(z)): 0.4412 / 0.3729\n",
      "[12/25][40/93] Loss_D: 1.1934 Loss_G: 1.8006 D(x): 0.6579 D(G(z)): 0.5239 / 0.1752\n",
      "[12/25][41/93] Loss_D: 1.2065 Loss_G: 0.9053 D(x): 0.5007 D(G(z)): 0.2400 / 0.4121\n",
      "[12/25][42/93] Loss_D: 1.2424 Loss_G: 1.3253 D(x): 0.6364 D(G(z)): 0.5332 / 0.2737\n",
      "[12/25][43/93] Loss_D: 1.3829 Loss_G: 0.7300 D(x): 0.4382 D(G(z)): 0.4030 / 0.4945\n",
      "[12/25][44/93] Loss_D: 1.3058 Loss_G: 1.7604 D(x): 0.6633 D(G(z)): 0.5748 / 0.1832\n",
      "[12/25][45/93] Loss_D: 1.4748 Loss_G: 0.5424 D(x): 0.3386 D(G(z)): 0.2882 / 0.5951\n",
      "[12/25][46/93] Loss_D: 1.4183 Loss_G: 1.7854 D(x): 0.7479 D(G(z)): 0.6624 / 0.1729\n",
      "[12/25][47/93] Loss_D: 1.3685 Loss_G: 0.6840 D(x): 0.3580 D(G(z)): 0.2452 / 0.5177\n",
      "[12/25][48/93] Loss_D: 1.2011 Loss_G: 2.2140 D(x): 0.8154 D(G(z)): 0.6137 / 0.1191\n",
      "[12/25][49/93] Loss_D: 1.4681 Loss_G: 0.5951 D(x): 0.3032 D(G(z)): 0.1872 / 0.5783\n",
      "[12/25][50/93] Loss_D: 1.4349 Loss_G: 1.8618 D(x): 0.8335 D(G(z)): 0.6971 / 0.1647\n",
      "[12/25][51/93] Loss_D: 1.4564 Loss_G: 0.6619 D(x): 0.3260 D(G(z)): 0.2207 / 0.5308\n",
      "[12/25][52/93] Loss_D: 1.4333 Loss_G: 1.6355 D(x): 0.7253 D(G(z)): 0.6555 / 0.2015\n",
      "[12/25][53/93] Loss_D: 1.2141 Loss_G: 0.9632 D(x): 0.4355 D(G(z)): 0.2950 / 0.3869\n",
      "[12/25][54/93] Loss_D: 1.1713 Loss_G: 1.2374 D(x): 0.6517 D(G(z)): 0.5117 / 0.3009\n",
      "[12/25][55/93] Loss_D: 1.1247 Loss_G: 1.0466 D(x): 0.5227 D(G(z)): 0.3540 / 0.3636\n",
      "[12/25][56/93] Loss_D: 1.1787 Loss_G: 1.7121 D(x): 0.6760 D(G(z)): 0.5329 / 0.1843\n",
      "[12/25][57/93] Loss_D: 1.4048 Loss_G: 0.8338 D(x): 0.3843 D(G(z)): 0.3232 / 0.4442\n",
      "[12/25][58/93] Loss_D: 1.2231 Loss_G: 1.7260 D(x): 0.6192 D(G(z)): 0.5134 / 0.1836\n",
      "[12/25][59/93] Loss_D: 1.2504 Loss_G: 0.8923 D(x): 0.4679 D(G(z)): 0.3338 / 0.4237\n",
      "[12/25][60/93] Loss_D: 1.0386 Loss_G: 2.2373 D(x): 0.8095 D(G(z)): 0.5418 / 0.1223\n",
      "[12/25][61/93] Loss_D: 1.7314 Loss_G: 0.5267 D(x): 0.2401 D(G(z)): 0.1985 / 0.6011\n",
      "[12/25][62/93] Loss_D: 1.4371 Loss_G: 1.1773 D(x): 0.7545 D(G(z)): 0.6646 / 0.3336\n",
      "[12/25][63/93] Loss_D: 1.0444 Loss_G: 1.7272 D(x): 0.6833 D(G(z)): 0.4633 / 0.1921\n",
      "[12/25][64/93] Loss_D: 1.5953 Loss_G: 0.4895 D(x): 0.3043 D(G(z)): 0.2689 / 0.6248\n",
      "[12/25][65/93] Loss_D: 1.3501 Loss_G: 1.2984 D(x): 0.7853 D(G(z)): 0.6511 / 0.2791\n",
      "[12/25][66/93] Loss_D: 0.9841 Loss_G: 1.2675 D(x): 0.5538 D(G(z)): 0.3125 / 0.2912\n",
      "[12/25][67/93] Loss_D: 1.0741 Loss_G: 1.1012 D(x): 0.6084 D(G(z)): 0.4228 / 0.3398\n",
      "[12/25][68/93] Loss_D: 1.0633 Loss_G: 1.7107 D(x): 0.6665 D(G(z)): 0.4665 / 0.1884\n",
      "[12/25][69/93] Loss_D: 1.5113 Loss_G: 0.7289 D(x): 0.3629 D(G(z)): 0.3502 / 0.4955\n",
      "[12/25][70/93] Loss_D: 1.1765 Loss_G: 1.6643 D(x): 0.7488 D(G(z)): 0.5713 / 0.1948\n",
      "[12/25][71/93] Loss_D: 1.0288 Loss_G: 1.3232 D(x): 0.5303 D(G(z)): 0.3042 / 0.2823\n",
      "[12/25][72/93] Loss_D: 1.0824 Loss_G: 1.2473 D(x): 0.6134 D(G(z)): 0.4240 / 0.2997\n",
      "[12/25][73/93] Loss_D: 1.1453 Loss_G: 1.4795 D(x): 0.6189 D(G(z)): 0.4654 / 0.2357\n",
      "[12/25][74/93] Loss_D: 1.0745 Loss_G: 1.1931 D(x): 0.5402 D(G(z)): 0.3449 / 0.3169\n",
      "[12/25][75/93] Loss_D: 1.1727 Loss_G: 1.7463 D(x): 0.6809 D(G(z)): 0.5162 / 0.1875\n",
      "[12/25][76/93] Loss_D: 1.5223 Loss_G: 0.4730 D(x): 0.3264 D(G(z)): 0.2729 / 0.6409\n",
      "[12/25][77/93] Loss_D: 1.6017 Loss_G: 2.1644 D(x): 0.8139 D(G(z)): 0.7391 / 0.1274\n",
      "[12/25][78/93] Loss_D: 1.0751 Loss_G: 1.2691 D(x): 0.4639 D(G(z)): 0.2152 / 0.2914\n",
      "[12/25][79/93] Loss_D: 1.0216 Loss_G: 1.3042 D(x): 0.6529 D(G(z)): 0.4248 / 0.2866\n",
      "[12/25][80/93] Loss_D: 1.2857 Loss_G: 1.6765 D(x): 0.5700 D(G(z)): 0.4928 / 0.2013\n",
      "[12/25][81/93] Loss_D: 1.2810 Loss_G: 0.9918 D(x): 0.4421 D(G(z)): 0.3308 / 0.4032\n",
      "[12/25][82/93] Loss_D: 1.2310 Loss_G: 2.3786 D(x): 0.6910 D(G(z)): 0.5623 / 0.0966\n",
      "[12/25][83/93] Loss_D: 0.9249 Loss_G: 1.1559 D(x): 0.5029 D(G(z)): 0.1836 / 0.3359\n",
      "[12/25][84/93] Loss_D: 1.5338 Loss_G: 1.0149 D(x): 0.5246 D(G(z)): 0.5621 / 0.3710\n",
      "[12/25][85/93] Loss_D: 1.1307 Loss_G: 1.4240 D(x): 0.5923 D(G(z)): 0.4343 / 0.2542\n",
      "[12/25][86/93] Loss_D: 1.2983 Loss_G: 0.7208 D(x): 0.4576 D(G(z)): 0.3725 / 0.4951\n",
      "[12/25][87/93] Loss_D: 1.2753 Loss_G: 2.2907 D(x): 0.7707 D(G(z)): 0.6260 / 0.1140\n",
      "[12/25][88/93] Loss_D: 1.8003 Loss_G: 0.4833 D(x): 0.2524 D(G(z)): 0.2233 / 0.6319\n",
      "[12/25][89/93] Loss_D: 1.7692 Loss_G: 1.8008 D(x): 0.7839 D(G(z)): 0.7584 / 0.1819\n",
      "[12/25][90/93] Loss_D: 1.0537 Loss_G: 1.0061 D(x): 0.4713 D(G(z)): 0.2134 / 0.3857\n",
      "[12/25][91/93] Loss_D: 1.0488 Loss_G: 1.5702 D(x): 0.7170 D(G(z)): 0.4989 / 0.2218\n",
      "[12/25][92/93] Loss_D: 1.0497 Loss_G: 1.5862 D(x): 0.6040 D(G(z)): 0.3840 / 0.2281\n",
      "[13/25][0/93] Loss_D: 1.3425 Loss_G: 0.5543 D(x): 0.4537 D(G(z)): 0.3880 / 0.5886\n",
      "[13/25][1/93] Loss_D: 1.8209 Loss_G: 3.0223 D(x): 0.7796 D(G(z)): 0.7737 / 0.0547\n",
      "[13/25][2/93] Loss_D: 1.9571 Loss_G: 0.6294 D(x): 0.1990 D(G(z)): 0.1008 / 0.5472\n",
      "[13/25][3/93] Loss_D: 1.4453 Loss_G: 2.3158 D(x): 0.7719 D(G(z)): 0.6764 / 0.1061\n",
      "[13/25][4/93] Loss_D: 1.1266 Loss_G: 0.8999 D(x): 0.4180 D(G(z)): 0.1552 / 0.4126\n",
      "[13/25][5/93] Loss_D: 1.4018 Loss_G: 0.9313 D(x): 0.5902 D(G(z)): 0.5636 / 0.4019\n",
      "[13/25][6/93] Loss_D: 1.0737 Loss_G: 1.6858 D(x): 0.6501 D(G(z)): 0.4614 / 0.1916\n",
      "[13/25][7/93] Loss_D: 0.9257 Loss_G: 1.3273 D(x): 0.5655 D(G(z)): 0.2553 / 0.2731\n",
      "[13/25][8/93] Loss_D: 1.2122 Loss_G: 0.8514 D(x): 0.5374 D(G(z)): 0.4301 / 0.4367\n",
      "[13/25][9/93] Loss_D: 1.2369 Loss_G: 1.5947 D(x): 0.6741 D(G(z)): 0.5555 / 0.2110\n",
      "[13/25][10/93] Loss_D: 1.1490 Loss_G: 0.9582 D(x): 0.4877 D(G(z)): 0.3156 / 0.3951\n",
      "[13/25][11/93] Loss_D: 1.1928 Loss_G: 1.0481 D(x): 0.5978 D(G(z)): 0.4654 / 0.3651\n",
      "[13/25][12/93] Loss_D: 1.0453 Loss_G: 1.6520 D(x): 0.6773 D(G(z)): 0.4645 / 0.2079\n",
      "[13/25][13/93] Loss_D: 1.1808 Loss_G: 0.9019 D(x): 0.4676 D(G(z)): 0.3004 / 0.4306\n",
      "[13/25][14/93] Loss_D: 1.0147 Loss_G: 1.7217 D(x): 0.7906 D(G(z)): 0.5206 / 0.1904\n",
      "[13/25][15/93] Loss_D: 1.2469 Loss_G: 0.8843 D(x): 0.4240 D(G(z)): 0.2610 / 0.4291\n",
      "[13/25][16/93] Loss_D: 1.3568 Loss_G: 1.1577 D(x): 0.6076 D(G(z)): 0.5624 / 0.3241\n",
      "[13/25][17/93] Loss_D: 1.1859 Loss_G: 1.3812 D(x): 0.5855 D(G(z)): 0.4554 / 0.2624\n",
      "[13/25][18/93] Loss_D: 1.2358 Loss_G: 1.0421 D(x): 0.4836 D(G(z)): 0.3750 / 0.3732\n",
      "[13/25][19/93] Loss_D: 1.4202 Loss_G: 1.2530 D(x): 0.5874 D(G(z)): 0.5587 / 0.3039\n",
      "[13/25][20/93] Loss_D: 1.0575 Loss_G: 1.9103 D(x): 0.6360 D(G(z)): 0.3982 / 0.1621\n",
      "[13/25][21/93] Loss_D: 1.5579 Loss_G: 0.3681 D(x): 0.2939 D(G(z)): 0.2399 / 0.7153\n",
      "[13/25][22/93] Loss_D: 1.7244 Loss_G: 1.8519 D(x): 0.8499 D(G(z)): 0.7528 / 0.1645\n",
      "[13/25][23/93] Loss_D: 1.3170 Loss_G: 0.9097 D(x): 0.3712 D(G(z)): 0.2379 / 0.4243\n",
      "[13/25][24/93] Loss_D: 1.1834 Loss_G: 1.2518 D(x): 0.6606 D(G(z)): 0.5129 / 0.2976\n",
      "[13/25][25/93] Loss_D: 0.9942 Loss_G: 1.2598 D(x): 0.5927 D(G(z)): 0.3551 / 0.2979\n",
      "[13/25][26/93] Loss_D: 0.8596 Loss_G: 1.7327 D(x): 0.7420 D(G(z)): 0.4073 / 0.1839\n",
      "[13/25][27/93] Loss_D: 1.1411 Loss_G: 0.7604 D(x): 0.4588 D(G(z)): 0.2737 / 0.4792\n",
      "[13/25][28/93] Loss_D: 1.2809 Loss_G: 2.2004 D(x): 0.7733 D(G(z)): 0.6234 / 0.1187\n",
      "[13/25][29/93] Loss_D: 1.3443 Loss_G: 0.7303 D(x): 0.3507 D(G(z)): 0.2118 / 0.4965\n",
      "[13/25][30/93] Loss_D: 1.3112 Loss_G: 1.7152 D(x): 0.7342 D(G(z)): 0.6156 / 0.1905\n",
      "[13/25][31/93] Loss_D: 1.3550 Loss_G: 0.9032 D(x): 0.3817 D(G(z)): 0.2805 / 0.4258\n",
      "[13/25][32/93] Loss_D: 1.1476 Loss_G: 1.5907 D(x): 0.7053 D(G(z)): 0.5260 / 0.2108\n",
      "[13/25][33/93] Loss_D: 1.0537 Loss_G: 1.1448 D(x): 0.5022 D(G(z)): 0.2849 / 0.3277\n",
      "[13/25][34/93] Loss_D: 1.0817 Loss_G: 1.3623 D(x): 0.6414 D(G(z)): 0.4585 / 0.2645\n",
      "[13/25][35/93] Loss_D: 1.1218 Loss_G: 1.5005 D(x): 0.5685 D(G(z)): 0.3936 / 0.2328\n",
      "[13/25][36/93] Loss_D: 1.2126 Loss_G: 1.0401 D(x): 0.5165 D(G(z)): 0.4009 / 0.3677\n",
      "[13/25][37/93] Loss_D: 1.0868 Loss_G: 1.6790 D(x): 0.6579 D(G(z)): 0.4636 / 0.1934\n",
      "[13/25][38/93] Loss_D: 1.2029 Loss_G: 0.8907 D(x): 0.4674 D(G(z)): 0.3312 / 0.4259\n",
      "[13/25][39/93] Loss_D: 1.2064 Loss_G: 1.8290 D(x): 0.6898 D(G(z)): 0.5511 / 0.1705\n",
      "[13/25][40/93] Loss_D: 1.0993 Loss_G: 1.3110 D(x): 0.5178 D(G(z)): 0.3316 / 0.2921\n",
      "[13/25][41/93] Loss_D: 1.0682 Loss_G: 1.0952 D(x): 0.5877 D(G(z)): 0.3993 / 0.3456\n",
      "[13/25][42/93] Loss_D: 1.2853 Loss_G: 1.9980 D(x): 0.6564 D(G(z)): 0.5548 / 0.1433\n",
      "[13/25][43/93] Loss_D: 1.5804 Loss_G: 0.4998 D(x): 0.3152 D(G(z)): 0.2781 / 0.6384\n",
      "[13/25][44/93] Loss_D: 1.8006 Loss_G: 2.7959 D(x): 0.8276 D(G(z)): 0.7813 / 0.0642\n",
      "[13/25][45/93] Loss_D: 1.5737 Loss_G: 0.6179 D(x): 0.2635 D(G(z)): 0.1234 / 0.5645\n",
      "[13/25][46/93] Loss_D: 1.3469 Loss_G: 1.9779 D(x): 0.8107 D(G(z)): 0.6567 / 0.1493\n",
      "[13/25][47/93] Loss_D: 1.1733 Loss_G: 1.3720 D(x): 0.4993 D(G(z)): 0.3332 / 0.2823\n",
      "[13/25][48/93] Loss_D: 1.1375 Loss_G: 0.9109 D(x): 0.5341 D(G(z)): 0.3742 / 0.4283\n",
      "[13/25][49/93] Loss_D: 1.2262 Loss_G: 1.7013 D(x): 0.7066 D(G(z)): 0.5655 / 0.1982\n",
      "[13/25][50/93] Loss_D: 1.3118 Loss_G: 0.5974 D(x): 0.3961 D(G(z)): 0.2837 / 0.5692\n",
      "[13/25][51/93] Loss_D: 1.3507 Loss_G: 2.2957 D(x): 0.7973 D(G(z)): 0.6608 / 0.1078\n",
      "[13/25][52/93] Loss_D: 1.3339 Loss_G: 0.7638 D(x): 0.3540 D(G(z)): 0.1919 / 0.4793\n",
      "[13/25][53/93] Loss_D: 1.3644 Loss_G: 1.7854 D(x): 0.7579 D(G(z)): 0.6437 / 0.1794\n",
      "[13/25][54/93] Loss_D: 1.5184 Loss_G: 0.8012 D(x): 0.3523 D(G(z)): 0.2926 / 0.4623\n",
      "[13/25][55/93] Loss_D: 1.3279 Loss_G: 1.6759 D(x): 0.6669 D(G(z)): 0.5826 / 0.1921\n",
      "[13/25][56/93] Loss_D: 1.4044 Loss_G: 0.6776 D(x): 0.3574 D(G(z)): 0.2795 / 0.5171\n",
      "[13/25][57/93] Loss_D: 1.2885 Loss_G: 1.7410 D(x): 0.7354 D(G(z)): 0.6072 / 0.1820\n",
      "[13/25][58/93] Loss_D: 1.1014 Loss_G: 1.0693 D(x): 0.4621 D(G(z)): 0.2599 / 0.3471\n",
      "[13/25][59/93] Loss_D: 1.0980 Loss_G: 1.0500 D(x): 0.6114 D(G(z)): 0.4386 / 0.3604\n",
      "[13/25][60/93] Loss_D: 1.2019 Loss_G: 1.2478 D(x): 0.6128 D(G(z)): 0.4947 / 0.2979\n",
      "[13/25][61/93] Loss_D: 1.0177 Loss_G: 1.6845 D(x): 0.6658 D(G(z)): 0.4375 / 0.1983\n",
      "[13/25][62/93] Loss_D: 1.1775 Loss_G: 0.6154 D(x): 0.4697 D(G(z)): 0.3187 / 0.5548\n",
      "[13/25][63/93] Loss_D: 1.6447 Loss_G: 2.7425 D(x): 0.7819 D(G(z)): 0.7353 / 0.0688\n",
      "[13/25][64/93] Loss_D: 1.9192 Loss_G: 0.5554 D(x): 0.1896 D(G(z)): 0.1158 / 0.5836\n",
      "[13/25][65/93] Loss_D: 1.6014 Loss_G: 1.6111 D(x): 0.7914 D(G(z)): 0.7279 / 0.2071\n",
      "[13/25][66/93] Loss_D: 1.1216 Loss_G: 1.2638 D(x): 0.4726 D(G(z)): 0.2834 / 0.2991\n",
      "[13/25][67/93] Loss_D: 1.0160 Loss_G: 1.2912 D(x): 0.6502 D(G(z)): 0.4299 / 0.2849\n",
      "[13/25][68/93] Loss_D: 1.0097 Loss_G: 1.3722 D(x): 0.6399 D(G(z)): 0.4102 / 0.2592\n",
      "[13/25][69/93] Loss_D: 1.2498 Loss_G: 0.8795 D(x): 0.4827 D(G(z)): 0.3812 / 0.4219\n",
      "[13/25][70/93] Loss_D: 1.3540 Loss_G: 1.3889 D(x): 0.5732 D(G(z)): 0.5292 / 0.2611\n",
      "[13/25][71/93] Loss_D: 1.0776 Loss_G: 1.4969 D(x): 0.5916 D(G(z)): 0.3942 / 0.2373\n",
      "[13/25][72/93] Loss_D: 0.9672 Loss_G: 1.6149 D(x): 0.6220 D(G(z)): 0.3504 / 0.2120\n",
      "[13/25][73/93] Loss_D: 1.2373 Loss_G: 0.7252 D(x): 0.4597 D(G(z)): 0.3185 / 0.5058\n",
      "[13/25][74/93] Loss_D: 1.1781 Loss_G: 2.3817 D(x): 0.7555 D(G(z)): 0.5730 / 0.0998\n",
      "[13/25][75/93] Loss_D: 1.2367 Loss_G: 1.5006 D(x): 0.5386 D(G(z)): 0.3513 / 0.2464\n",
      "[13/25][76/93] Loss_D: 1.2228 Loss_G: 0.6612 D(x): 0.4611 D(G(z)): 0.2736 / 0.5262\n",
      "[13/25][77/93] Loss_D: 1.4863 Loss_G: 2.0966 D(x): 0.7285 D(G(z)): 0.6707 / 0.1347\n",
      "[13/25][78/93] Loss_D: 1.5975 Loss_G: 0.5446 D(x): 0.2801 D(G(z)): 0.2179 / 0.5960\n",
      "[13/25][79/93] Loss_D: 1.5411 Loss_G: 1.3928 D(x): 0.7346 D(G(z)): 0.6887 / 0.2720\n",
      "[13/25][80/93] Loss_D: 1.2169 Loss_G: 1.0621 D(x): 0.4907 D(G(z)): 0.3712 / 0.3644\n",
      "[13/25][81/93] Loss_D: 1.1037 Loss_G: 0.9861 D(x): 0.5954 D(G(z)): 0.4135 / 0.3806\n",
      "[13/25][82/93] Loss_D: 1.0933 Loss_G: 1.9289 D(x): 0.7367 D(G(z)): 0.5289 / 0.1508\n",
      "[13/25][83/93] Loss_D: 1.2296 Loss_G: 0.6701 D(x): 0.4034 D(G(z)): 0.2104 / 0.5253\n",
      "[13/25][84/93] Loss_D: 1.7997 Loss_G: 2.2247 D(x): 0.7630 D(G(z)): 0.7506 / 0.1129\n",
      "[13/25][85/93] Loss_D: 1.5524 Loss_G: 0.7335 D(x): 0.3011 D(G(z)): 0.1843 / 0.4870\n",
      "[13/25][86/93] Loss_D: 1.2884 Loss_G: 1.5343 D(x): 0.7181 D(G(z)): 0.6042 / 0.2218\n",
      "[13/25][87/93] Loss_D: 1.1628 Loss_G: 1.0313 D(x): 0.4851 D(G(z)): 0.3303 / 0.3697\n",
      "[13/25][88/93] Loss_D: 1.1624 Loss_G: 1.1801 D(x): 0.5820 D(G(z)): 0.4503 / 0.3165\n",
      "[13/25][89/93] Loss_D: 1.0763 Loss_G: 1.3348 D(x): 0.5929 D(G(z)): 0.4110 / 0.2740\n",
      "[13/25][90/93] Loss_D: 1.0335 Loss_G: 1.5898 D(x): 0.6135 D(G(z)): 0.4058 / 0.2145\n",
      "[13/25][91/93] Loss_D: 1.2326 Loss_G: 1.0252 D(x): 0.5023 D(G(z)): 0.3962 / 0.3675\n",
      "[13/25][92/93] Loss_D: 1.2354 Loss_G: 1.4485 D(x): 0.6065 D(G(z)): 0.5074 / 0.2385\n",
      "[14/25][0/93] Loss_D: 1.2157 Loss_G: 0.9335 D(x): 0.4714 D(G(z)): 0.3449 / 0.4036\n",
      "[14/25][1/93] Loss_D: 1.0829 Loss_G: 1.6460 D(x): 0.6863 D(G(z)): 0.4929 / 0.2017\n",
      "[14/25][2/93] Loss_D: 0.9051 Loss_G: 1.7253 D(x): 0.6377 D(G(z)): 0.3159 / 0.1868\n",
      "[14/25][3/93] Loss_D: 1.0991 Loss_G: 0.9447 D(x): 0.5247 D(G(z)): 0.3214 / 0.4027\n",
      "[14/25][4/93] Loss_D: 1.1227 Loss_G: 2.3889 D(x): 0.7666 D(G(z)): 0.5507 / 0.0994\n",
      "[14/25][5/93] Loss_D: 1.3883 Loss_G: 0.6594 D(x): 0.3505 D(G(z)): 0.2119 / 0.5312\n",
      "[14/25][6/93] Loss_D: 1.6003 Loss_G: 2.0757 D(x): 0.6909 D(G(z)): 0.6832 / 0.1356\n",
      "[14/25][7/93] Loss_D: 1.3880 Loss_G: 0.6182 D(x): 0.3486 D(G(z)): 0.2255 / 0.5493\n",
      "[14/25][8/93] Loss_D: 1.3341 Loss_G: 2.0175 D(x): 0.8326 D(G(z)): 0.6681 / 0.1390\n",
      "[14/25][9/93] Loss_D: 1.1002 Loss_G: 1.3226 D(x): 0.4502 D(G(z)): 0.2289 / 0.2781\n",
      "[14/25][10/93] Loss_D: 1.0703 Loss_G: 1.0421 D(x): 0.6179 D(G(z)): 0.4204 / 0.3744\n",
      "[14/25][11/93] Loss_D: 1.0184 Loss_G: 2.0135 D(x): 0.7788 D(G(z)): 0.5229 / 0.1459\n",
      "[14/25][12/93] Loss_D: 1.2291 Loss_G: 0.8395 D(x): 0.4009 D(G(z)): 0.2268 / 0.4561\n",
      "[14/25][13/93] Loss_D: 1.1716 Loss_G: 1.3627 D(x): 0.7193 D(G(z)): 0.5466 / 0.2736\n",
      "[14/25][14/93] Loss_D: 1.0166 Loss_G: 1.6428 D(x): 0.6455 D(G(z)): 0.4230 / 0.2084\n",
      "[14/25][15/93] Loss_D: 1.1373 Loss_G: 0.9275 D(x): 0.5123 D(G(z)): 0.3380 / 0.4177\n",
      "[14/25][16/93] Loss_D: 1.2090 Loss_G: 2.2857 D(x): 0.7222 D(G(z)): 0.5650 / 0.1083\n",
      "[14/25][17/93] Loss_D: 1.3970 Loss_G: 0.5763 D(x): 0.3444 D(G(z)): 0.2326 / 0.5857\n",
      "[14/25][18/93] Loss_D: 1.6185 Loss_G: 2.8724 D(x): 0.8575 D(G(z)): 0.7453 / 0.0621\n",
      "[14/25][19/93] Loss_D: 1.6149 Loss_G: 0.9854 D(x): 0.3035 D(G(z)): 0.1225 / 0.3993\n",
      "[14/25][20/93] Loss_D: 1.3023 Loss_G: 1.0569 D(x): 0.6591 D(G(z)): 0.5646 / 0.3592\n",
      "[14/25][21/93] Loss_D: 1.2316 Loss_G: 1.4318 D(x): 0.5683 D(G(z)): 0.4517 / 0.2475\n",
      "[14/25][22/93] Loss_D: 1.1373 Loss_G: 1.1013 D(x): 0.5189 D(G(z)): 0.3534 / 0.3426\n",
      "[14/25][23/93] Loss_D: 1.2473 Loss_G: 1.3644 D(x): 0.6052 D(G(z)): 0.4949 / 0.2682\n",
      "[14/25][24/93] Loss_D: 1.2881 Loss_G: 1.0559 D(x): 0.4878 D(G(z)): 0.4010 / 0.3603\n",
      "[14/25][25/93] Loss_D: 1.0343 Loss_G: 1.8299 D(x): 0.7117 D(G(z)): 0.4748 / 0.1669\n",
      "[14/25][26/93] Loss_D: 1.2401 Loss_G: 0.6210 D(x): 0.4298 D(G(z)): 0.2968 / 0.5464\n",
      "[14/25][27/93] Loss_D: 1.2653 Loss_G: 2.5639 D(x): 0.7964 D(G(z)): 0.6320 / 0.0806\n",
      "[14/25][28/93] Loss_D: 1.4635 Loss_G: 0.6229 D(x): 0.2955 D(G(z)): 0.1528 / 0.5438\n",
      "[14/25][29/93] Loss_D: 1.3562 Loss_G: 1.6478 D(x): 0.7773 D(G(z)): 0.6541 / 0.1999\n",
      "[14/25][30/93] Loss_D: 0.9502 Loss_G: 1.4368 D(x): 0.5626 D(G(z)): 0.2865 / 0.2497\n",
      "[14/25][31/93] Loss_D: 1.0359 Loss_G: 0.9255 D(x): 0.5589 D(G(z)): 0.3495 / 0.4075\n",
      "[14/25][32/93] Loss_D: 1.0972 Loss_G: 2.3459 D(x): 0.7825 D(G(z)): 0.5607 / 0.1020\n",
      "[14/25][33/93] Loss_D: 1.5461 Loss_G: 0.6003 D(x): 0.2870 D(G(z)): 0.1973 / 0.5617\n",
      "[14/25][34/93] Loss_D: 1.3845 Loss_G: 1.8308 D(x): 0.7825 D(G(z)): 0.6663 / 0.1675\n",
      "[14/25][35/93] Loss_D: 1.3047 Loss_G: 1.3510 D(x): 0.4249 D(G(z)): 0.2900 / 0.2734\n",
      "[14/25][36/93] Loss_D: 1.2380 Loss_G: 1.3226 D(x): 0.5160 D(G(z)): 0.4130 / 0.2876\n",
      "[14/25][37/93] Loss_D: 1.2158 Loss_G: 1.4075 D(x): 0.5706 D(G(z)): 0.4640 / 0.2597\n",
      "[14/25][38/93] Loss_D: 0.8378 Loss_G: 2.1247 D(x): 0.6977 D(G(z)): 0.3552 / 0.1247\n",
      "[14/25][39/93] Loss_D: 1.0761 Loss_G: 1.3743 D(x): 0.5574 D(G(z)): 0.3521 / 0.2631\n",
      "[14/25][40/93] Loss_D: 1.1270 Loss_G: 1.3715 D(x): 0.6086 D(G(z)): 0.4521 / 0.2677\n",
      "[14/25][41/93] Loss_D: 1.1647 Loss_G: 1.3618 D(x): 0.5690 D(G(z)): 0.4332 / 0.2710\n",
      "[14/25][42/93] Loss_D: 1.1804 Loss_G: 1.5464 D(x): 0.5936 D(G(z)): 0.4666 / 0.2307\n",
      "[14/25][43/93] Loss_D: 0.9990 Loss_G: 2.2285 D(x): 0.6656 D(G(z)): 0.4260 / 0.1146\n",
      "[14/25][44/93] Loss_D: 1.4140 Loss_G: 0.2939 D(x): 0.3588 D(G(z)): 0.2806 / 0.7590\n",
      "[14/25][45/93] Loss_D: 2.0977 Loss_G: 3.7081 D(x): 0.9384 D(G(z)): 0.8570 / 0.0275\n",
      "[14/25][46/93] Loss_D: 2.4537 Loss_G: 0.7261 D(x): 0.1131 D(G(z)): 0.0591 / 0.4940\n",
      "[14/25][47/93] Loss_D: 1.4014 Loss_G: 0.7608 D(x): 0.6430 D(G(z)): 0.5957 / 0.4742\n",
      "[14/25][48/93] Loss_D: 1.2201 Loss_G: 1.9097 D(x): 0.7330 D(G(z)): 0.5847 / 0.1684\n",
      "[14/25][49/93] Loss_D: 1.4877 Loss_G: 0.8900 D(x): 0.3702 D(G(z)): 0.2993 / 0.4182\n",
      "[14/25][50/93] Loss_D: 1.3235 Loss_G: 1.3710 D(x): 0.6418 D(G(z)): 0.5665 / 0.2660\n",
      "[14/25][51/93] Loss_D: 1.2301 Loss_G: 1.2725 D(x): 0.5035 D(G(z)): 0.3982 / 0.3024\n",
      "[14/25][52/93] Loss_D: 1.2274 Loss_G: 1.3474 D(x): 0.5458 D(G(z)): 0.4379 / 0.2864\n",
      "[14/25][53/93] Loss_D: 1.2519 Loss_G: 2.1439 D(x): 0.5919 D(G(z)): 0.4917 / 0.1217\n",
      "[14/25][54/93] Loss_D: 1.0742 Loss_G: 1.2530 D(x): 0.4754 D(G(z)): 0.2511 / 0.2928\n",
      "[14/25][55/93] Loss_D: 1.2756 Loss_G: 1.1763 D(x): 0.5337 D(G(z)): 0.4626 / 0.3264\n",
      "[14/25][56/93] Loss_D: 1.0940 Loss_G: 2.4427 D(x): 0.7031 D(G(z)): 0.5110 / 0.0950\n",
      "[14/25][57/93] Loss_D: 1.2998 Loss_G: 0.7202 D(x): 0.3690 D(G(z)): 0.2119 / 0.4967\n",
      "[14/25][58/93] Loss_D: 1.3469 Loss_G: 1.6483 D(x): 0.7382 D(G(z)): 0.6373 / 0.2053\n",
      "[14/25][59/93] Loss_D: 1.2496 Loss_G: 0.9299 D(x): 0.4440 D(G(z)): 0.3095 / 0.4057\n",
      "[14/25][60/93] Loss_D: 1.1308 Loss_G: 1.7153 D(x): 0.7247 D(G(z)): 0.5345 / 0.1990\n",
      "[14/25][61/93] Loss_D: 0.9666 Loss_G: 1.7160 D(x): 0.6275 D(G(z)): 0.3442 / 0.1936\n",
      "[14/25][62/93] Loss_D: 1.1081 Loss_G: 0.9241 D(x): 0.5168 D(G(z)): 0.3280 / 0.4085\n",
      "[14/25][63/93] Loss_D: 1.4690 Loss_G: 2.6858 D(x): 0.6503 D(G(z)): 0.6310 / 0.0717\n",
      "[14/25][64/93] Loss_D: 1.7704 Loss_G: 0.4824 D(x): 0.2226 D(G(z)): 0.1533 / 0.6304\n",
      "[14/25][65/93] Loss_D: 1.7033 Loss_G: 1.9452 D(x): 0.8056 D(G(z)): 0.7468 / 0.1489\n",
      "[14/25][66/93] Loss_D: 1.1954 Loss_G: 1.3231 D(x): 0.4255 D(G(z)): 0.2440 / 0.2831\n",
      "[14/25][67/93] Loss_D: 1.0953 Loss_G: 1.1876 D(x): 0.6125 D(G(z)): 0.4285 / 0.3183\n",
      "[14/25][68/93] Loss_D: 1.0727 Loss_G: 1.5778 D(x): 0.6680 D(G(z)): 0.4705 / 0.2128\n",
      "[14/25][69/93] Loss_D: 1.0179 Loss_G: 1.2660 D(x): 0.5669 D(G(z)): 0.3240 / 0.2908\n",
      "[14/25][70/93] Loss_D: 1.1857 Loss_G: 0.8303 D(x): 0.5231 D(G(z)): 0.3899 / 0.4442\n",
      "[14/25][71/93] Loss_D: 1.2133 Loss_G: 1.8823 D(x): 0.7406 D(G(z)): 0.5870 / 0.1610\n",
      "[14/25][72/93] Loss_D: 1.2030 Loss_G: 0.9456 D(x): 0.4291 D(G(z)): 0.2257 / 0.4010\n",
      "[14/25][73/93] Loss_D: 1.2126 Loss_G: 1.7235 D(x): 0.7130 D(G(z)): 0.5680 / 0.1846\n",
      "[14/25][74/93] Loss_D: 0.9949 Loss_G: 1.3674 D(x): 0.5423 D(G(z)): 0.2798 / 0.2619\n",
      "[14/25][75/93] Loss_D: 1.0189 Loss_G: 1.1685 D(x): 0.6122 D(G(z)): 0.3948 / 0.3204\n",
      "[14/25][76/93] Loss_D: 1.1144 Loss_G: 1.8007 D(x): 0.6554 D(G(z)): 0.4846 / 0.1719\n",
      "[14/25][77/93] Loss_D: 1.0970 Loss_G: 1.1470 D(x): 0.5166 D(G(z)): 0.3185 / 0.3275\n",
      "[14/25][78/93] Loss_D: 1.1101 Loss_G: 1.9670 D(x): 0.6682 D(G(z)): 0.4904 / 0.1481\n",
      "[14/25][79/93] Loss_D: 1.1593 Loss_G: 1.4214 D(x): 0.4806 D(G(z)): 0.3085 / 0.2497\n",
      "[14/25][80/93] Loss_D: 1.2798 Loss_G: 1.1130 D(x): 0.5432 D(G(z)): 0.4666 / 0.3344\n",
      "[14/25][81/93] Loss_D: 1.1111 Loss_G: 2.3539 D(x): 0.7016 D(G(z)): 0.5195 / 0.1008\n",
      "[14/25][82/93] Loss_D: 1.4674 Loss_G: 0.5026 D(x): 0.3097 D(G(z)): 0.1949 / 0.6186\n",
      "[14/25][83/93] Loss_D: 1.7002 Loss_G: 2.2730 D(x): 0.8510 D(G(z)): 0.7613 / 0.1137\n",
      "[14/25][84/93] Loss_D: 1.7339 Loss_G: 0.6615 D(x): 0.2457 D(G(z)): 0.2012 / 0.5612\n",
      "[14/25][85/93] Loss_D: 1.2715 Loss_G: 2.1671 D(x): 0.8681 D(G(z)): 0.6466 / 0.1216\n",
      "[14/25][86/93] Loss_D: 1.0472 Loss_G: 1.2035 D(x): 0.4983 D(G(z)): 0.2608 / 0.3113\n",
      "[14/25][87/93] Loss_D: 1.0411 Loss_G: 1.5045 D(x): 0.7023 D(G(z)): 0.4668 / 0.2402\n",
      "[14/25][88/93] Loss_D: 1.0032 Loss_G: 1.7209 D(x): 0.6367 D(G(z)): 0.4023 / 0.1907\n",
      "[14/25][89/93] Loss_D: 1.1109 Loss_G: 1.5899 D(x): 0.5624 D(G(z)): 0.3906 / 0.2153\n",
      "[14/25][90/93] Loss_D: 1.0730 Loss_G: 1.6938 D(x): 0.5844 D(G(z)): 0.3851 / 0.1940\n",
      "[14/25][91/93] Loss_D: 1.1931 Loss_G: 1.7485 D(x): 0.5445 D(G(z)): 0.3957 / 0.1874\n",
      "[14/25][92/93] Loss_D: 0.8733 Loss_G: 2.5611 D(x): 0.7400 D(G(z)): 0.4004 / 0.0840\n",
      "[15/25][0/93] Loss_D: 1.1611 Loss_G: 1.0210 D(x): 0.4402 D(G(z)): 0.2414 / 0.3902\n",
      "[15/25][1/93] Loss_D: 1.4050 Loss_G: 1.4739 D(x): 0.5871 D(G(z)): 0.5539 / 0.2428\n",
      "[15/25][2/93] Loss_D: 1.2161 Loss_G: 1.2551 D(x): 0.5140 D(G(z)): 0.3971 / 0.3068\n",
      "[15/25][3/93] Loss_D: 1.1571 Loss_G: 2.2011 D(x): 0.6995 D(G(z)): 0.5320 / 0.1185\n",
      "[15/25][4/93] Loss_D: 1.0155 Loss_G: 1.2236 D(x): 0.5275 D(G(z)): 0.2589 / 0.3100\n",
      "[15/25][5/93] Loss_D: 1.1048 Loss_G: 1.8841 D(x): 0.6763 D(G(z)): 0.4885 / 0.1650\n",
      "[15/25][6/93] Loss_D: 1.2605 Loss_G: 0.8490 D(x): 0.4363 D(G(z)): 0.3180 / 0.4453\n",
      "[15/25][7/93] Loss_D: 1.5312 Loss_G: 2.3913 D(x): 0.7139 D(G(z)): 0.6677 / 0.0989\n",
      "[15/25][8/93] Loss_D: 1.5777 Loss_G: 0.5671 D(x): 0.2911 D(G(z)): 0.2376 / 0.5938\n",
      "[15/25][9/93] Loss_D: 1.4127 Loss_G: 2.6481 D(x): 0.8500 D(G(z)): 0.6944 / 0.0759\n",
      "[15/25][10/93] Loss_D: 1.4302 Loss_G: 0.5634 D(x): 0.3007 D(G(z)): 0.1418 / 0.5840\n",
      "[15/25][11/93] Loss_D: 1.6458 Loss_G: 2.6003 D(x): 0.8720 D(G(z)): 0.7575 / 0.0812\n",
      "[15/25][12/93] Loss_D: 1.3497 Loss_G: 1.1763 D(x): 0.3208 D(G(z)): 0.1198 / 0.3165\n",
      "[15/25][13/93] Loss_D: 1.0011 Loss_G: 1.3139 D(x): 0.7653 D(G(z)): 0.5086 / 0.2789\n",
      "[15/25][14/93] Loss_D: 1.0536 Loss_G: 2.2978 D(x): 0.6916 D(G(z)): 0.4820 / 0.1083\n",
      "[15/25][15/93] Loss_D: 1.2603 Loss_G: 0.6336 D(x): 0.3921 D(G(z)): 0.2292 / 0.5428\n",
      "[15/25][16/93] Loss_D: 1.4927 Loss_G: 2.5938 D(x): 0.7932 D(G(z)): 0.7065 / 0.0798\n",
      "[15/25][17/93] Loss_D: 1.5438 Loss_G: 0.7308 D(x): 0.2639 D(G(z)): 0.1563 / 0.4985\n",
      "[15/25][18/93] Loss_D: 1.2480 Loss_G: 1.8380 D(x): 0.7977 D(G(z)): 0.6262 / 0.1648\n",
      "[15/25][19/93] Loss_D: 1.1973 Loss_G: 1.1612 D(x): 0.4452 D(G(z)): 0.2767 / 0.3216\n",
      "[15/25][20/93] Loss_D: 1.2438 Loss_G: 1.2701 D(x): 0.5964 D(G(z)): 0.5007 / 0.2895\n",
      "[15/25][21/93] Loss_D: 1.0227 Loss_G: 1.8072 D(x): 0.6518 D(G(z)): 0.4247 / 0.1694\n",
      "[15/25][22/93] Loss_D: 1.0879 Loss_G: 0.9636 D(x): 0.4677 D(G(z)): 0.2518 / 0.3906\n",
      "[15/25][23/93] Loss_D: 1.0642 Loss_G: 1.8355 D(x): 0.7351 D(G(z)): 0.5224 / 0.1685\n",
      "[15/25][24/93] Loss_D: 1.1777 Loss_G: 0.9000 D(x): 0.4633 D(G(z)): 0.3103 / 0.4150\n",
      "[15/25][25/93] Loss_D: 1.3516 Loss_G: 2.1368 D(x): 0.7501 D(G(z)): 0.6396 / 0.1295\n",
      "[15/25][26/93] Loss_D: 1.1342 Loss_G: 1.2174 D(x): 0.4541 D(G(z)): 0.2034 / 0.3181\n",
      "[15/25][27/93] Loss_D: 1.1590 Loss_G: 1.1569 D(x): 0.6035 D(G(z)): 0.4644 / 0.3344\n",
      "[15/25][28/93] Loss_D: 1.2059 Loss_G: 1.3182 D(x): 0.5834 D(G(z)): 0.4622 / 0.2853\n",
      "[15/25][29/93] Loss_D: 1.0006 Loss_G: 1.7609 D(x): 0.6552 D(G(z)): 0.4191 / 0.1804\n",
      "[15/25][30/93] Loss_D: 1.1608 Loss_G: 0.8936 D(x): 0.4952 D(G(z)): 0.3336 / 0.4315\n",
      "[15/25][31/93] Loss_D: 1.3960 Loss_G: 2.5245 D(x): 0.7154 D(G(z)): 0.6290 / 0.0866\n",
      "[15/25][32/93] Loss_D: 1.2805 Loss_G: 0.9305 D(x): 0.3886 D(G(z)): 0.2401 / 0.4098\n",
      "[15/25][33/93] Loss_D: 1.3265 Loss_G: 2.0793 D(x): 0.6901 D(G(z)): 0.6030 / 0.1325\n",
      "[15/25][34/93] Loss_D: 1.2479 Loss_G: 1.0291 D(x): 0.4327 D(G(z)): 0.2820 / 0.3769\n",
      "[15/25][35/93] Loss_D: 1.1877 Loss_G: 2.0512 D(x): 0.6662 D(G(z)): 0.5313 / 0.1373\n",
      "[15/25][36/93] Loss_D: 1.2885 Loss_G: 0.6355 D(x): 0.3968 D(G(z)): 0.2696 / 0.5481\n",
      "[15/25][37/93] Loss_D: 1.3342 Loss_G: 3.6920 D(x): 0.8811 D(G(z)): 0.6858 / 0.0272\n",
      "[15/25][38/93] Loss_D: 1.8602 Loss_G: 0.7902 D(x): 0.1953 D(G(z)): 0.0647 / 0.4637\n",
      "[15/25][39/93] Loss_D: 1.2480 Loss_G: 1.3119 D(x): 0.7896 D(G(z)): 0.6253 / 0.2799\n",
      "[15/25][40/93] Loss_D: 0.8794 Loss_G: 2.0234 D(x): 0.7229 D(G(z)): 0.3963 / 0.1431\n",
      "[15/25][41/93] Loss_D: 1.2298 Loss_G: 0.7170 D(x): 0.3977 D(G(z)): 0.2036 / 0.5085\n",
      "[15/25][42/93] Loss_D: 1.2942 Loss_G: 2.1719 D(x): 0.8300 D(G(z)): 0.6520 / 0.1236\n",
      "[15/25][43/93] Loss_D: 1.2990 Loss_G: 0.9069 D(x): 0.3769 D(G(z)): 0.2221 / 0.4208\n",
      "[15/25][44/93] Loss_D: 1.2675 Loss_G: 1.4823 D(x): 0.6894 D(G(z)): 0.5685 / 0.2424\n",
      "[15/25][45/93] Loss_D: 1.1101 Loss_G: 1.7877 D(x): 0.5642 D(G(z)): 0.3899 / 0.1755\n",
      "[15/25][46/93] Loss_D: 1.4314 Loss_G: 0.5738 D(x): 0.3475 D(G(z)): 0.2888 / 0.5754\n",
      "[15/25][47/93] Loss_D: 1.4913 Loss_G: 2.5493 D(x): 0.8206 D(G(z)): 0.7074 / 0.0818\n",
      "[15/25][48/93] Loss_D: 1.3457 Loss_G: 1.0072 D(x): 0.3334 D(G(z)): 0.1815 / 0.3769\n",
      "[15/25][49/93] Loss_D: 1.0505 Loss_G: 1.5338 D(x): 0.7229 D(G(z)): 0.5016 / 0.2228\n",
      "[15/25][50/93] Loss_D: 1.1141 Loss_G: 1.4139 D(x): 0.5608 D(G(z)): 0.3995 / 0.2512\n",
      "[15/25][51/93] Loss_D: 1.0264 Loss_G: 1.2553 D(x): 0.5903 D(G(z)): 0.3711 / 0.2928\n",
      "[15/25][52/93] Loss_D: 1.0186 Loss_G: 1.1369 D(x): 0.5863 D(G(z)): 0.3654 / 0.3365\n",
      "[15/25][53/93] Loss_D: 1.1629 Loss_G: 1.9387 D(x): 0.7013 D(G(z)): 0.5407 / 0.1547\n",
      "[15/25][54/93] Loss_D: 1.1859 Loss_G: 1.2066 D(x): 0.5013 D(G(z)): 0.3540 / 0.3207\n",
      "[15/25][55/93] Loss_D: 1.0871 Loss_G: 1.5831 D(x): 0.6416 D(G(z)): 0.4563 / 0.2214\n",
      "[15/25][56/93] Loss_D: 1.1562 Loss_G: 1.2070 D(x): 0.5395 D(G(z)): 0.3841 / 0.3126\n",
      "[15/25][57/93] Loss_D: 1.3802 Loss_G: 3.1998 D(x): 0.6676 D(G(z)): 0.6005 / 0.0428\n",
      "[15/25][58/93] Loss_D: 2.1215 Loss_G: 0.2670 D(x): 0.1535 D(G(z)): 0.1148 / 0.7758\n",
      "[15/25][59/93] Loss_D: 2.1345 Loss_G: 2.2860 D(x): 0.8649 D(G(z)): 0.8410 / 0.1125\n",
      "[15/25][60/93] Loss_D: 1.2976 Loss_G: 1.4231 D(x): 0.3670 D(G(z)): 0.2160 / 0.2660\n",
      "[15/25][61/93] Loss_D: 1.3657 Loss_G: 0.6845 D(x): 0.4615 D(G(z)): 0.4235 / 0.5141\n",
      "[15/25][62/93] Loss_D: 1.2692 Loss_G: 1.9308 D(x): 0.7623 D(G(z)): 0.6111 / 0.1531\n",
      "[15/25][63/93] Loss_D: 1.1531 Loss_G: 1.2550 D(x): 0.4606 D(G(z)): 0.2858 / 0.3057\n",
      "[15/25][64/93] Loss_D: 0.8132 Loss_G: 1.8175 D(x): 0.7824 D(G(z)): 0.4147 / 0.1775\n",
      "[15/25][65/93] Loss_D: 0.8647 Loss_G: 1.4039 D(x): 0.6103 D(G(z)): 0.2724 / 0.2685\n",
      "[15/25][66/93] Loss_D: 0.9351 Loss_G: 2.3140 D(x): 0.7720 D(G(z)): 0.4780 / 0.1065\n",
      "[15/25][67/93] Loss_D: 1.0705 Loss_G: 1.0669 D(x): 0.4886 D(G(z)): 0.2664 / 0.3582\n",
      "[15/25][68/93] Loss_D: 1.4391 Loss_G: 2.6275 D(x): 0.7046 D(G(z)): 0.6448 / 0.0790\n",
      "[15/25][69/93] Loss_D: 1.7646 Loss_G: 0.5249 D(x): 0.2391 D(G(z)): 0.2317 / 0.6072\n",
      "[15/25][70/93] Loss_D: 1.5571 Loss_G: 1.8301 D(x): 0.7624 D(G(z)): 0.7099 / 0.1690\n",
      "[15/25][71/93] Loss_D: 1.1822 Loss_G: 1.3416 D(x): 0.4427 D(G(z)): 0.2692 / 0.2892\n",
      "[15/25][72/93] Loss_D: 1.1519 Loss_G: 1.1432 D(x): 0.6180 D(G(z)): 0.4668 / 0.3387\n",
      "[15/25][73/93] Loss_D: 1.3698 Loss_G: 2.1223 D(x): 0.5969 D(G(z)): 0.5505 / 0.1262\n",
      "[15/25][74/93] Loss_D: 1.4130 Loss_G: 0.7178 D(x): 0.3730 D(G(z)): 0.2747 / 0.5090\n",
      "[15/25][75/93] Loss_D: 1.4012 Loss_G: 2.3339 D(x): 0.7595 D(G(z)): 0.6595 / 0.1049\n",
      "[15/25][76/93] Loss_D: 1.4464 Loss_G: 0.7392 D(x): 0.3102 D(G(z)): 0.1866 / 0.4928\n",
      "[15/25][77/93] Loss_D: 1.4045 Loss_G: 1.7224 D(x): 0.7180 D(G(z)): 0.6424 / 0.1908\n",
      "[15/25][78/93] Loss_D: 1.0474 Loss_G: 1.5194 D(x): 0.5465 D(G(z)): 0.3329 / 0.2291\n",
      "[15/25][79/93] Loss_D: 1.1705 Loss_G: 1.1283 D(x): 0.5269 D(G(z)): 0.3887 / 0.3391\n",
      "[15/25][80/93] Loss_D: 1.2353 Loss_G: 2.2111 D(x): 0.6842 D(G(z)): 0.5594 / 0.1164\n",
      "[15/25][81/93] Loss_D: 1.3550 Loss_G: 0.5530 D(x): 0.3503 D(G(z)): 0.2214 / 0.5855\n",
      "[15/25][82/93] Loss_D: 1.5147 Loss_G: 2.8617 D(x): 0.8548 D(G(z)): 0.7293 / 0.0612\n",
      "[15/25][83/93] Loss_D: 1.2074 Loss_G: 1.3240 D(x): 0.3800 D(G(z)): 0.1365 / 0.2792\n",
      "[15/25][84/93] Loss_D: 1.1100 Loss_G: 0.8727 D(x): 0.5747 D(G(z)): 0.3997 / 0.4313\n",
      "[15/25][85/93] Loss_D: 1.3303 Loss_G: 1.8372 D(x): 0.6929 D(G(z)): 0.5990 / 0.1719\n",
      "[15/25][86/93] Loss_D: 1.2599 Loss_G: 0.9489 D(x): 0.4101 D(G(z)): 0.2835 / 0.3956\n",
      "[15/25][87/93] Loss_D: 1.0855 Loss_G: 1.2764 D(x): 0.6843 D(G(z)): 0.4947 / 0.2876\n",
      "[15/25][88/93] Loss_D: 1.4171 Loss_G: 1.7255 D(x): 0.6023 D(G(z)): 0.5714 / 0.1930\n",
      "[15/25][89/93] Loss_D: 1.2448 Loss_G: 0.9568 D(x): 0.4352 D(G(z)): 0.2955 / 0.4080\n",
      "[15/25][90/93] Loss_D: 1.5231 Loss_G: 1.5539 D(x): 0.6229 D(G(z)): 0.5964 / 0.2448\n",
      "[15/25][91/93] Loss_D: 1.2899 Loss_G: 1.1821 D(x): 0.4696 D(G(z)): 0.3750 / 0.3552\n",
      "[15/25][92/93] Loss_D: 1.0950 Loss_G: 1.5059 D(x): 0.6094 D(G(z)): 0.4199 / 0.2607\n",
      "[16/25][0/93] Loss_D: 1.3642 Loss_G: 2.3819 D(x): 0.6295 D(G(z)): 0.5512 / 0.1074\n",
      "[16/25][1/93] Loss_D: 1.4275 Loss_G: 0.6179 D(x): 0.3470 D(G(z)): 0.2368 / 0.5641\n",
      "[16/25][2/93] Loss_D: 1.5232 Loss_G: 2.9464 D(x): 0.8449 D(G(z)): 0.7131 / 0.0587\n",
      "[16/25][3/93] Loss_D: 1.9902 Loss_G: 0.5158 D(x): 0.1705 D(G(z)): 0.1135 / 0.6137\n",
      "[16/25][4/93] Loss_D: 1.3906 Loss_G: 1.6325 D(x): 0.8209 D(G(z)): 0.6823 / 0.2155\n",
      "[16/25][5/93] Loss_D: 1.1413 Loss_G: 1.3025 D(x): 0.4976 D(G(z)): 0.3006 / 0.2841\n",
      "[16/25][6/93] Loss_D: 1.0698 Loss_G: 1.1964 D(x): 0.6293 D(G(z)): 0.4275 / 0.3217\n",
      "[16/25][7/93] Loss_D: 1.1596 Loss_G: 1.4785 D(x): 0.6165 D(G(z)): 0.4707 / 0.2465\n",
      "[16/25][8/93] Loss_D: 1.1297 Loss_G: 1.3608 D(x): 0.5317 D(G(z)): 0.3686 / 0.2696\n",
      "[16/25][9/93] Loss_D: 0.8905 Loss_G: 1.8867 D(x): 0.7177 D(G(z)): 0.3944 / 0.1596\n",
      "[16/25][10/93] Loss_D: 1.1353 Loss_G: 0.8920 D(x): 0.4652 D(G(z)): 0.2725 / 0.4423\n",
      "[16/25][11/93] Loss_D: 1.1837 Loss_G: 2.0034 D(x): 0.7111 D(G(z)): 0.5471 / 0.1409\n",
      "[16/25][12/93] Loss_D: 1.2135 Loss_G: 0.9418 D(x): 0.4281 D(G(z)): 0.2810 / 0.4058\n",
      "[16/25][13/93] Loss_D: 1.2470 Loss_G: 1.6763 D(x): 0.7204 D(G(z)): 0.5695 / 0.1990\n",
      "[16/25][14/93] Loss_D: 1.2491 Loss_G: 0.9674 D(x): 0.4423 D(G(z)): 0.3196 / 0.3928\n",
      "[16/25][15/93] Loss_D: 1.2378 Loss_G: 1.6063 D(x): 0.6600 D(G(z)): 0.5458 / 0.2099\n",
      "[16/25][16/93] Loss_D: 1.1476 Loss_G: 1.3375 D(x): 0.5308 D(G(z)): 0.3694 / 0.2800\n",
      "[16/25][17/93] Loss_D: 1.0593 Loss_G: 1.5964 D(x): 0.6442 D(G(z)): 0.4442 / 0.2200\n",
      "[16/25][18/93] Loss_D: 1.3071 Loss_G: 1.0417 D(x): 0.4966 D(G(z)): 0.4266 / 0.3737\n",
      "[16/25][19/93] Loss_D: 1.2456 Loss_G: 2.5990 D(x): 0.7351 D(G(z)): 0.5902 / 0.0815\n",
      "[16/25][20/93] Loss_D: 1.3920 Loss_G: 0.6057 D(x): 0.3319 D(G(z)): 0.1990 / 0.5922\n",
      "[16/25][21/93] Loss_D: 1.5165 Loss_G: 3.4306 D(x): 0.8604 D(G(z)): 0.7240 / 0.0356\n",
      "[16/25][22/93] Loss_D: 1.6441 Loss_G: 0.6980 D(x): 0.2394 D(G(z)): 0.1030 / 0.5072\n",
      "[16/25][23/93] Loss_D: 1.4689 Loss_G: 2.3284 D(x): 0.8244 D(G(z)): 0.7005 / 0.1042\n",
      "[16/25][24/93] Loss_D: 1.2528 Loss_G: 1.0140 D(x): 0.3735 D(G(z)): 0.2003 / 0.3773\n",
      "[16/25][25/93] Loss_D: 0.9673 Loss_G: 1.9025 D(x): 0.8079 D(G(z)): 0.5061 / 0.1595\n",
      "[16/25][26/93] Loss_D: 1.2538 Loss_G: 1.2929 D(x): 0.4633 D(G(z)): 0.3498 / 0.2848\n",
      "[16/25][27/93] Loss_D: 1.3426 Loss_G: 1.1157 D(x): 0.5458 D(G(z)): 0.4981 / 0.3378\n",
      "[16/25][28/93] Loss_D: 1.1872 Loss_G: 1.3881 D(x): 0.5983 D(G(z)): 0.4693 / 0.2691\n",
      "[16/25][29/93] Loss_D: 1.1785 Loss_G: 1.5477 D(x): 0.5893 D(G(z)): 0.4638 / 0.2215\n",
      "[16/25][30/93] Loss_D: 1.2813 Loss_G: 0.7064 D(x): 0.4528 D(G(z)): 0.3637 / 0.5146\n",
      "[16/25][31/93] Loss_D: 1.3790 Loss_G: 2.6822 D(x): 0.7690 D(G(z)): 0.6547 / 0.0753\n",
      "[16/25][32/93] Loss_D: 1.5613 Loss_G: 0.6739 D(x): 0.2876 D(G(z)): 0.1485 / 0.5446\n",
      "[16/25][33/93] Loss_D: 1.5670 Loss_G: 2.7520 D(x): 0.8327 D(G(z)): 0.7279 / 0.0690\n",
      "[16/25][34/93] Loss_D: 1.5521 Loss_G: 0.8270 D(x): 0.2702 D(G(z)): 0.1393 / 0.4733\n",
      "[16/25][35/93] Loss_D: 1.3011 Loss_G: 1.5216 D(x): 0.7457 D(G(z)): 0.6060 / 0.2341\n",
      "[16/25][36/93] Loss_D: 1.2481 Loss_G: 1.7486 D(x): 0.5300 D(G(z)): 0.4375 / 0.1803\n",
      "[16/25][37/93] Loss_D: 1.0003 Loss_G: 1.1361 D(x): 0.5286 D(G(z)): 0.2825 / 0.3347\n",
      "[16/25][38/93] Loss_D: 1.1441 Loss_G: 1.5409 D(x): 0.6574 D(G(z)): 0.5013 / 0.2247\n",
      "[16/25][39/93] Loss_D: 1.1007 Loss_G: 1.6596 D(x): 0.5786 D(G(z)): 0.3995 / 0.1999\n",
      "[16/25][40/93] Loss_D: 1.1783 Loss_G: 1.2372 D(x): 0.5257 D(G(z)): 0.3908 / 0.3062\n",
      "[16/25][41/93] Loss_D: 1.2880 Loss_G: 2.1384 D(x): 0.6325 D(G(z)): 0.5450 / 0.1238\n",
      "[16/25][42/93] Loss_D: 1.6063 Loss_G: 0.5590 D(x): 0.2923 D(G(z)): 0.2689 / 0.5910\n",
      "[16/25][43/93] Loss_D: 1.6368 Loss_G: 2.5872 D(x): 0.7786 D(G(z)): 0.7280 / 0.0838\n",
      "[16/25][44/93] Loss_D: 0.8429 Loss_G: 2.1158 D(x): 0.5610 D(G(z)): 0.1829 / 0.1254\n",
      "[16/25][45/93] Loss_D: 0.8339 Loss_G: 1.2437 D(x): 0.6351 D(G(z)): 0.2643 / 0.3064\n",
      "[16/25][46/93] Loss_D: 1.4452 Loss_G: 1.1182 D(x): 0.5351 D(G(z)): 0.5373 / 0.3492\n",
      "[16/25][47/93] Loss_D: 1.1950 Loss_G: 2.0726 D(x): 0.6387 D(G(z)): 0.5089 / 0.1386\n",
      "[16/25][48/93] Loss_D: 1.3742 Loss_G: 0.7465 D(x): 0.3976 D(G(z)): 0.3228 / 0.4979\n",
      "[16/25][49/93] Loss_D: 1.0524 Loss_G: 2.1939 D(x): 0.7826 D(G(z)): 0.5323 / 0.1258\n",
      "[16/25][50/93] Loss_D: 0.9425 Loss_G: 1.5269 D(x): 0.5872 D(G(z)): 0.3077 / 0.2323\n",
      "[16/25][51/93] Loss_D: 1.0569 Loss_G: 1.7641 D(x): 0.6331 D(G(z)): 0.4279 / 0.1856\n",
      "[16/25][52/93] Loss_D: 0.9939 Loss_G: 1.7153 D(x): 0.6233 D(G(z)): 0.3768 / 0.1931\n",
      "[16/25][53/93] Loss_D: 1.3537 Loss_G: 1.1903 D(x): 0.4807 D(G(z)): 0.4255 / 0.3356\n",
      "[16/25][54/93] Loss_D: 1.3387 Loss_G: 3.0699 D(x): 0.6179 D(G(z)): 0.5487 / 0.0545\n",
      "[16/25][55/93] Loss_D: 1.3808 Loss_G: 0.3754 D(x): 0.3026 D(G(z)): 0.1249 / 0.6979\n",
      "[16/25][56/93] Loss_D: 2.0972 Loss_G: 3.1299 D(x): 0.8788 D(G(z)): 0.8494 / 0.0469\n",
      "[16/25][57/93] Loss_D: 1.5516 Loss_G: 1.1277 D(x): 0.2755 D(G(z)): 0.1029 / 0.3390\n",
      "[16/25][58/93] Loss_D: 0.9781 Loss_G: 1.1360 D(x): 0.6727 D(G(z)): 0.4240 / 0.3419\n",
      "[16/25][59/93] Loss_D: 1.0251 Loss_G: 2.2544 D(x): 0.7584 D(G(z)): 0.5034 / 0.1186\n",
      "[16/25][60/93] Loss_D: 1.2420 Loss_G: 0.9074 D(x): 0.3897 D(G(z)): 0.2016 / 0.4152\n",
      "[16/25][61/93] Loss_D: 1.2178 Loss_G: 1.6834 D(x): 0.7659 D(G(z)): 0.6001 / 0.1930\n",
      "[16/25][62/93] Loss_D: 0.8854 Loss_G: 1.9633 D(x): 0.6410 D(G(z)): 0.3230 / 0.1466\n",
      "[16/25][63/93] Loss_D: 1.2537 Loss_G: 0.9128 D(x): 0.4642 D(G(z)): 0.3567 / 0.4368\n",
      "[16/25][64/93] Loss_D: 1.1694 Loss_G: 2.3867 D(x): 0.7788 D(G(z)): 0.5854 / 0.0987\n",
      "[16/25][65/93] Loss_D: 1.2663 Loss_G: 1.2612 D(x): 0.4094 D(G(z)): 0.2678 / 0.3131\n",
      "[16/25][66/93] Loss_D: 1.0445 Loss_G: 1.8492 D(x): 0.7111 D(G(z)): 0.4840 / 0.1706\n",
      "[16/25][67/93] Loss_D: 1.2627 Loss_G: 1.4593 D(x): 0.4932 D(G(z)): 0.4006 / 0.2464\n",
      "[16/25][68/93] Loss_D: 1.2513 Loss_G: 1.6495 D(x): 0.5888 D(G(z)): 0.4911 / 0.2101\n",
      "[16/25][69/93] Loss_D: 1.1288 Loss_G: 1.4069 D(x): 0.5400 D(G(z)): 0.3819 / 0.2681\n",
      "[16/25][70/93] Loss_D: 1.0752 Loss_G: 1.8872 D(x): 0.6352 D(G(z)): 0.4444 / 0.1592\n",
      "[16/25][71/93] Loss_D: 1.2544 Loss_G: 0.7971 D(x): 0.4350 D(G(z)): 0.3216 / 0.4653\n",
      "[16/25][72/93] Loss_D: 1.3379 Loss_G: 3.1806 D(x): 0.8081 D(G(z)): 0.6632 / 0.0452\n",
      "[16/25][73/93] Loss_D: 1.4525 Loss_G: 1.4016 D(x): 0.3654 D(G(z)): 0.0964 / 0.2641\n",
      "[16/25][74/93] Loss_D: 1.0619 Loss_G: 0.6591 D(x): 0.5509 D(G(z)): 0.3482 / 0.5260\n",
      "[16/25][75/93] Loss_D: 1.3999 Loss_G: 2.1995 D(x): 0.8447 D(G(z)): 0.6859 / 0.1278\n",
      "[16/25][76/93] Loss_D: 1.7081 Loss_G: 1.0168 D(x): 0.2714 D(G(z)): 0.2601 / 0.4087\n",
      "[16/25][77/93] Loss_D: 1.1248 Loss_G: 1.2565 D(x): 0.6474 D(G(z)): 0.4756 / 0.3185\n",
      "[16/25][78/93] Loss_D: 1.0602 Loss_G: 1.1917 D(x): 0.5733 D(G(z)): 0.3746 / 0.3259\n",
      "[16/25][79/93] Loss_D: 1.0981 Loss_G: 2.6115 D(x): 0.7981 D(G(z)): 0.5625 / 0.0792\n",
      "[16/25][80/93] Loss_D: 1.6193 Loss_G: 0.5647 D(x): 0.2560 D(G(z)): 0.1567 / 0.5831\n",
      "[16/25][81/93] Loss_D: 1.5871 Loss_G: 1.9644 D(x): 0.8553 D(G(z)): 0.7376 / 0.1549\n",
      "[16/25][82/93] Loss_D: 1.1137 Loss_G: 1.7586 D(x): 0.5173 D(G(z)): 0.2722 / 0.1856\n",
      "[16/25][83/93] Loss_D: 1.2520 Loss_G: 0.8679 D(x): 0.4660 D(G(z)): 0.3346 / 0.4526\n",
      "[16/25][84/93] Loss_D: 1.1804 Loss_G: 1.7037 D(x): 0.7525 D(G(z)): 0.5607 / 0.2102\n",
      "[16/25][85/93] Loss_D: 1.3080 Loss_G: 1.0249 D(x): 0.4265 D(G(z)): 0.3294 / 0.3832\n",
      "[16/25][86/93] Loss_D: 1.3690 Loss_G: 1.6359 D(x): 0.6703 D(G(z)): 0.5945 / 0.2134\n",
      "[16/25][87/93] Loss_D: 1.2283 Loss_G: 1.2899 D(x): 0.4818 D(G(z)): 0.3670 / 0.2946\n",
      "[16/25][88/93] Loss_D: 1.2747 Loss_G: 0.8517 D(x): 0.4949 D(G(z)): 0.4110 / 0.4556\n",
      "[16/25][89/93] Loss_D: 1.2896 Loss_G: 2.3677 D(x): 0.7068 D(G(z)): 0.5948 / 0.1026\n",
      "[16/25][90/93] Loss_D: 1.2267 Loss_G: 0.9878 D(x): 0.3941 D(G(z)): 0.2094 / 0.4024\n",
      "[16/25][91/93] Loss_D: 1.2707 Loss_G: 1.9041 D(x): 0.7122 D(G(z)): 0.5824 / 0.1578\n",
      "[16/25][92/93] Loss_D: 1.2124 Loss_G: 1.0126 D(x): 0.4345 D(G(z)): 0.2866 / 0.3787\n",
      "[17/25][0/93] Loss_D: 1.1621 Loss_G: 1.9232 D(x): 0.6940 D(G(z)): 0.5347 / 0.1522\n",
      "[17/25][1/93] Loss_D: 0.8500 Loss_G: 1.9197 D(x): 0.6553 D(G(z)): 0.3007 / 0.1529\n",
      "[17/25][2/93] Loss_D: 1.0005 Loss_G: 1.3738 D(x): 0.5915 D(G(z)): 0.3314 / 0.2632\n",
      "[17/25][3/93] Loss_D: 1.2106 Loss_G: 1.5154 D(x): 0.5613 D(G(z)): 0.4490 / 0.2329\n",
      "[17/25][4/93] Loss_D: 1.0442 Loss_G: 1.6292 D(x): 0.6020 D(G(z)): 0.3882 / 0.2040\n",
      "[17/25][5/93] Loss_D: 1.1186 Loss_G: 1.4562 D(x): 0.5697 D(G(z)): 0.4038 / 0.2612\n",
      "[17/25][6/93] Loss_D: 0.9173 Loss_G: 2.3042 D(x): 0.7091 D(G(z)): 0.4092 / 0.1090\n",
      "[17/25][7/93] Loss_D: 1.2127 Loss_G: 0.4136 D(x): 0.4263 D(G(z)): 0.2644 / 0.6754\n",
      "[17/25][8/93] Loss_D: 2.0824 Loss_G: 4.2673 D(x): 0.9019 D(G(z)): 0.8447 / 0.0173\n",
      "[17/25][9/93] Loss_D: 2.8779 Loss_G: 0.6387 D(x): 0.0793 D(G(z)): 0.0528 / 0.5676\n",
      "[17/25][10/93] Loss_D: 1.4053 Loss_G: 1.0088 D(x): 0.7846 D(G(z)): 0.6709 / 0.3756\n",
      "[17/25][11/93] Loss_D: 1.3645 Loss_G: 1.4197 D(x): 0.5634 D(G(z)): 0.5259 / 0.2527\n",
      "[17/25][12/93] Loss_D: 1.1788 Loss_G: 1.1423 D(x): 0.5031 D(G(z)): 0.3566 / 0.3372\n",
      "[17/25][13/93] Loss_D: 0.9920 Loss_G: 1.0516 D(x): 0.5887 D(G(z)): 0.3417 / 0.3790\n",
      "[17/25][14/93] Loss_D: 1.2930 Loss_G: 1.8319 D(x): 0.6976 D(G(z)): 0.5885 / 0.1752\n",
      "[17/25][15/93] Loss_D: 1.3086 Loss_G: 0.9237 D(x): 0.3901 D(G(z)): 0.2792 / 0.4123\n",
      "[17/25][16/93] Loss_D: 1.1826 Loss_G: 1.7676 D(x): 0.7093 D(G(z)): 0.5518 / 0.1798\n",
      "[17/25][17/93] Loss_D: 1.0921 Loss_G: 1.2500 D(x): 0.4808 D(G(z)): 0.2835 / 0.3033\n",
      "[17/25][18/93] Loss_D: 1.1344 Loss_G: 1.6395 D(x): 0.6387 D(G(z)): 0.4855 / 0.2107\n",
      "[17/25][19/93] Loss_D: 1.1597 Loss_G: 1.5747 D(x): 0.5514 D(G(z)): 0.4045 / 0.2227\n",
      "[17/25][20/93] Loss_D: 1.2079 Loss_G: 1.3379 D(x): 0.5212 D(G(z)): 0.4100 / 0.2701\n",
      "[17/25][21/93] Loss_D: 1.1838 Loss_G: 1.4966 D(x): 0.5750 D(G(z)): 0.4546 / 0.2399\n",
      "[17/25][22/93] Loss_D: 1.1215 Loss_G: 1.7516 D(x): 0.6077 D(G(z)): 0.4525 / 0.1819\n",
      "[17/25][23/93] Loss_D: 1.0326 Loss_G: 1.6730 D(x): 0.5940 D(G(z)): 0.3831 / 0.1976\n",
      "[17/25][24/93] Loss_D: 1.2493 Loss_G: 1.4521 D(x): 0.5383 D(G(z)): 0.4373 / 0.2534\n",
      "[17/25][25/93] Loss_D: 1.1104 Loss_G: 2.4023 D(x): 0.6603 D(G(z)): 0.4736 / 0.0960\n",
      "[17/25][26/93] Loss_D: 1.4046 Loss_G: 0.3287 D(x): 0.3472 D(G(z)): 0.2220 / 0.7301\n",
      "[17/25][27/93] Loss_D: 2.0177 Loss_G: 3.4143 D(x): 0.9292 D(G(z)): 0.8419 / 0.0363\n",
      "[17/25][28/93] Loss_D: 1.8463 Loss_G: 1.0435 D(x): 0.2080 D(G(z)): 0.0676 / 0.3623\n",
      "[17/25][29/93] Loss_D: 1.2964 Loss_G: 0.8408 D(x): 0.6342 D(G(z)): 0.5496 / 0.4411\n",
      "[17/25][30/93] Loss_D: 1.0803 Loss_G: 1.4918 D(x): 0.6531 D(G(z)): 0.4683 / 0.2361\n",
      "[17/25][31/93] Loss_D: 1.0451 Loss_G: 1.2879 D(x): 0.5674 D(G(z)): 0.3551 / 0.2830\n",
      "[17/25][32/93] Loss_D: 1.0435 Loss_G: 1.2621 D(x): 0.6317 D(G(z)): 0.4241 / 0.2917\n",
      "[17/25][33/93] Loss_D: 0.8719 Loss_G: 2.0785 D(x): 0.7566 D(G(z)): 0.4234 / 0.1359\n",
      "[17/25][34/93] Loss_D: 1.2926 Loss_G: 0.6221 D(x): 0.3786 D(G(z)): 0.2319 / 0.5512\n",
      "[17/25][35/93] Loss_D: 1.2953 Loss_G: 2.1238 D(x): 0.8618 D(G(z)): 0.6657 / 0.1267\n",
      "[17/25][36/93] Loss_D: 1.0709 Loss_G: 1.5667 D(x): 0.4954 D(G(z)): 0.2844 / 0.2200\n",
      "[17/25][37/93] Loss_D: 1.1832 Loss_G: 1.1850 D(x): 0.5271 D(G(z)): 0.4013 / 0.3308\n",
      "[17/25][38/93] Loss_D: 1.1089 Loss_G: 1.6433 D(x): 0.6435 D(G(z)): 0.4680 / 0.2087\n",
      "[17/25][39/93] Loss_D: 1.2482 Loss_G: 1.3862 D(x): 0.5392 D(G(z)): 0.4398 / 0.2685\n",
      "[17/25][40/93] Loss_D: 1.0888 Loss_G: 1.3839 D(x): 0.5765 D(G(z)): 0.3852 / 0.2654\n",
      "[17/25][41/93] Loss_D: 1.1303 Loss_G: 1.9069 D(x): 0.6422 D(G(z)): 0.4717 / 0.1575\n",
      "[17/25][42/93] Loss_D: 1.0849 Loss_G: 1.0915 D(x): 0.4996 D(G(z)): 0.2966 / 0.3451\n",
      "[17/25][43/93] Loss_D: 1.3383 Loss_G: 2.1595 D(x): 0.6536 D(G(z)): 0.5858 / 0.1272\n",
      "[17/25][44/93] Loss_D: 1.2032 Loss_G: 1.2488 D(x): 0.4625 D(G(z)): 0.3139 / 0.3248\n",
      "[17/25][45/93] Loss_D: 1.1347 Loss_G: 1.9992 D(x): 0.6582 D(G(z)): 0.4889 / 0.1503\n",
      "[17/25][46/93] Loss_D: 0.8634 Loss_G: 2.6253 D(x): 0.7272 D(G(z)): 0.3850 / 0.0808\n",
      "[17/25][47/93] Loss_D: 1.3550 Loss_G: 0.5283 D(x): 0.3507 D(G(z)): 0.1924 / 0.6141\n",
      "[17/25][48/93] Loss_D: 1.6697 Loss_G: 3.2486 D(x): 0.8351 D(G(z)): 0.7538 / 0.0428\n",
      "[17/25][49/93] Loss_D: 1.5503 Loss_G: 1.0153 D(x): 0.2811 D(G(z)): 0.1361 / 0.3895\n",
      "[17/25][50/93] Loss_D: 1.1811 Loss_G: 1.7259 D(x): 0.7533 D(G(z)): 0.5646 / 0.1901\n",
      "[17/25][51/93] Loss_D: 1.0807 Loss_G: 1.6658 D(x): 0.5345 D(G(z)): 0.3383 / 0.1970\n",
      "[17/25][52/93] Loss_D: 1.1008 Loss_G: 1.3599 D(x): 0.5664 D(G(z)): 0.3879 / 0.2643\n",
      "[17/25][53/93] Loss_D: 1.2276 Loss_G: 1.3938 D(x): 0.5649 D(G(z)): 0.4580 / 0.2673\n",
      "[17/25][54/93] Loss_D: 1.0563 Loss_G: 2.1082 D(x): 0.6577 D(G(z)): 0.4562 / 0.1297\n",
      "[17/25][55/93] Loss_D: 0.8618 Loss_G: 1.4414 D(x): 0.5799 D(G(z)): 0.2517 / 0.2518\n",
      "[17/25][56/93] Loss_D: 1.1068 Loss_G: 2.3115 D(x): 0.7115 D(G(z)): 0.5107 / 0.1079\n",
      "[17/25][57/93] Loss_D: 1.3847 Loss_G: 0.6531 D(x): 0.3492 D(G(z)): 0.2297 / 0.5476\n",
      "[17/25][58/93] Loss_D: 1.5123 Loss_G: 2.8717 D(x): 0.8253 D(G(z)): 0.7085 / 0.0654\n",
      "[17/25][59/93] Loss_D: 1.5348 Loss_G: 1.1462 D(x): 0.3061 D(G(z)): 0.2056 / 0.3535\n",
      "[17/25][60/93] Loss_D: 1.2616 Loss_G: 1.5422 D(x): 0.6453 D(G(z)): 0.5310 / 0.2302\n",
      "[17/25][61/93] Loss_D: 1.1149 Loss_G: 1.7948 D(x): 0.5881 D(G(z)): 0.4137 / 0.1801\n",
      "[17/25][62/93] Loss_D: 0.7579 Loss_G: 2.2037 D(x): 0.7334 D(G(z)): 0.3425 / 0.1215\n",
      "[17/25][63/93] Loss_D: 0.9977 Loss_G: 1.4884 D(x): 0.5694 D(G(z)): 0.3164 / 0.2507\n",
      "[17/25][64/93] Loss_D: 1.1153 Loss_G: 2.5619 D(x): 0.7014 D(G(z)): 0.5112 / 0.0893\n",
      "[17/25][65/93] Loss_D: 1.1815 Loss_G: 1.0137 D(x): 0.4539 D(G(z)): 0.2852 / 0.3966\n",
      "[17/25][66/93] Loss_D: 1.4802 Loss_G: 3.6084 D(x): 0.7883 D(G(z)): 0.6874 / 0.0321\n",
      "[17/25][67/93] Loss_D: 1.6006 Loss_G: 0.6798 D(x): 0.2540 D(G(z)): 0.1125 / 0.5426\n",
      "[17/25][68/93] Loss_D: 1.4132 Loss_G: 2.3544 D(x): 0.8559 D(G(z)): 0.6916 / 0.1117\n",
      "[17/25][69/93] Loss_D: 1.2191 Loss_G: 1.4585 D(x): 0.4780 D(G(z)): 0.3154 / 0.2468\n",
      "[17/25][70/93] Loss_D: 1.1518 Loss_G: 1.3085 D(x): 0.5763 D(G(z)): 0.4310 / 0.2857\n",
      "[17/25][71/93] Loss_D: 1.0387 Loss_G: 2.9123 D(x): 0.7093 D(G(z)): 0.4891 / 0.0596\n",
      "[17/25][72/93] Loss_D: 1.1139 Loss_G: 0.6119 D(x): 0.4438 D(G(z)): 0.2112 / 0.5671\n",
      "[17/25][73/93] Loss_D: 1.6522 Loss_G: 3.8019 D(x): 0.8464 D(G(z)): 0.7517 / 0.0264\n",
      "[17/25][74/93] Loss_D: 2.1343 Loss_G: 0.7240 D(x): 0.1442 D(G(z)): 0.0617 / 0.5060\n",
      "[17/25][75/93] Loss_D: 1.2416 Loss_G: 1.5545 D(x): 0.7453 D(G(z)): 0.5912 / 0.2213\n",
      "[17/25][76/93] Loss_D: 0.8697 Loss_G: 2.1880 D(x): 0.6993 D(G(z)): 0.3722 / 0.1187\n",
      "[17/25][77/93] Loss_D: 1.3247 Loss_G: 0.6560 D(x): 0.3542 D(G(z)): 0.2220 / 0.5352\n",
      "[17/25][78/93] Loss_D: 1.5260 Loss_G: 1.9954 D(x): 0.8301 D(G(z)): 0.7028 / 0.1486\n",
      "[17/25][79/93] Loss_D: 0.9265 Loss_G: 1.8245 D(x): 0.5652 D(G(z)): 0.2336 / 0.1779\n",
      "[17/25][80/93] Loss_D: 1.1326 Loss_G: 0.7174 D(x): 0.4619 D(G(z)): 0.2791 / 0.5102\n",
      "[17/25][81/93] Loss_D: 1.3143 Loss_G: 2.2987 D(x): 0.8198 D(G(z)): 0.6578 / 0.1074\n",
      "[17/25][82/93] Loss_D: 0.9140 Loss_G: 1.8918 D(x): 0.5561 D(G(z)): 0.2163 / 0.1664\n",
      "[17/25][83/93] Loss_D: 1.1619 Loss_G: 0.6692 D(x): 0.4810 D(G(z)): 0.3091 / 0.5398\n",
      "[17/25][84/93] Loss_D: 1.5805 Loss_G: 3.2905 D(x): 0.8271 D(G(z)): 0.7344 / 0.0412\n",
      "[17/25][85/93] Loss_D: 1.8336 Loss_G: 0.8888 D(x): 0.2014 D(G(z)): 0.0875 / 0.4458\n",
      "[17/25][86/93] Loss_D: 1.2143 Loss_G: 1.8241 D(x): 0.8491 D(G(z)): 0.6222 / 0.1761\n",
      "[17/25][87/93] Loss_D: 1.2526 Loss_G: 1.5379 D(x): 0.4851 D(G(z)): 0.3712 / 0.2282\n",
      "[17/25][88/93] Loss_D: 1.1473 Loss_G: 1.8584 D(x): 0.6169 D(G(z)): 0.4576 / 0.1799\n",
      "[17/25][89/93] Loss_D: 1.1121 Loss_G: 1.4902 D(x): 0.5414 D(G(z)): 0.3712 / 0.2468\n",
      "[17/25][90/93] Loss_D: 1.3741 Loss_G: 1.5022 D(x): 0.5190 D(G(z)): 0.4888 / 0.2388\n",
      "[17/25][91/93] Loss_D: 1.2548 Loss_G: 1.8390 D(x): 0.5712 D(G(z)): 0.4743 / 0.1714\n",
      "[17/25][92/93] Loss_D: 1.2847 Loss_G: 1.0825 D(x): 0.4544 D(G(z)): 0.3431 / 0.3549\n",
      "[18/25][0/93] Loss_D: 1.1836 Loss_G: 2.9742 D(x): 0.7387 D(G(z)): 0.5660 / 0.0553\n",
      "[18/25][1/93] Loss_D: 1.5410 Loss_G: 0.3870 D(x): 0.2723 D(G(z)): 0.1529 / 0.6973\n",
      "[18/25][2/93] Loss_D: 1.9699 Loss_G: 2.8388 D(x): 0.9182 D(G(z)): 0.8303 / 0.0658\n",
      "[18/25][3/93] Loss_D: 1.5976 Loss_G: 1.2062 D(x): 0.2655 D(G(z)): 0.1609 / 0.3271\n",
      "[18/25][4/93] Loss_D: 1.1411 Loss_G: 1.1729 D(x): 0.6303 D(G(z)): 0.4757 / 0.3249\n",
      "[18/25][5/93] Loss_D: 1.2170 Loss_G: 1.8057 D(x): 0.6499 D(G(z)): 0.5300 / 0.1740\n",
      "[18/25][6/93] Loss_D: 1.1304 Loss_G: 1.2920 D(x): 0.5063 D(G(z)): 0.3269 / 0.2955\n",
      "[18/25][7/93] Loss_D: 1.1125 Loss_G: 1.9351 D(x): 0.6733 D(G(z)): 0.4840 / 0.1628\n",
      "[18/25][8/93] Loss_D: 1.1148 Loss_G: 1.8878 D(x): 0.6278 D(G(z)): 0.4358 / 0.1589\n",
      "[18/25][9/93] Loss_D: 1.5153 Loss_G: 0.7012 D(x): 0.3356 D(G(z)): 0.3082 / 0.5317\n",
      "[18/25][10/93] Loss_D: 1.6153 Loss_G: 2.0665 D(x): 0.7472 D(G(z)): 0.7120 / 0.1358\n",
      "[18/25][11/93] Loss_D: 1.3574 Loss_G: 1.0556 D(x): 0.3717 D(G(z)): 0.2584 / 0.3728\n",
      "[18/25][12/93] Loss_D: 1.2870 Loss_G: 1.4752 D(x): 0.6392 D(G(z)): 0.5501 / 0.2543\n",
      "[18/25][13/93] Loss_D: 0.8745 Loss_G: 2.1144 D(x): 0.7048 D(G(z)): 0.3863 / 0.1303\n",
      "[18/25][14/93] Loss_D: 0.9570 Loss_G: 1.5726 D(x): 0.5756 D(G(z)): 0.2909 / 0.2296\n",
      "[18/25][15/93] Loss_D: 1.2287 Loss_G: 1.3510 D(x): 0.5403 D(G(z)): 0.4292 / 0.2935\n",
      "[18/25][16/93] Loss_D: 1.3136 Loss_G: 2.4540 D(x): 0.6075 D(G(z)): 0.5292 / 0.0982\n",
      "[18/25][17/93] Loss_D: 0.9029 Loss_G: 1.4939 D(x): 0.5844 D(G(z)): 0.2118 / 0.2384\n",
      "[18/25][18/93] Loss_D: 0.9683 Loss_G: 2.2991 D(x): 0.7394 D(G(z)): 0.4543 / 0.1079\n",
      "[18/25][19/93] Loss_D: 1.5275 Loss_G: 0.8755 D(x): 0.3838 D(G(z)): 0.3694 / 0.4572\n",
      "[18/25][20/93] Loss_D: 1.1251 Loss_G: 2.4393 D(x): 0.7586 D(G(z)): 0.5479 / 0.1057\n",
      "[18/25][21/93] Loss_D: 1.2174 Loss_G: 0.6648 D(x): 0.4141 D(G(z)): 0.2504 / 0.5461\n",
      "[18/25][22/93] Loss_D: 1.6255 Loss_G: 4.2098 D(x): 0.8603 D(G(z)): 0.7544 / 0.0173\n",
      "[18/25][23/93] Loss_D: 2.2568 Loss_G: 0.8187 D(x): 0.1364 D(G(z)): 0.0396 / 0.4700\n",
      "[18/25][24/93] Loss_D: 1.3649 Loss_G: 1.8759 D(x): 0.8445 D(G(z)): 0.6817 / 0.1620\n",
      "[18/25][25/93] Loss_D: 0.9748 Loss_G: 1.7472 D(x): 0.5939 D(G(z)): 0.3440 / 0.1871\n",
      "[18/25][26/93] Loss_D: 1.0856 Loss_G: 0.9960 D(x): 0.4983 D(G(z)): 0.2954 / 0.3914\n",
      "[18/25][27/93] Loss_D: 0.9546 Loss_G: 2.0402 D(x): 0.7955 D(G(z)): 0.4912 / 0.1503\n",
      "[18/25][28/93] Loss_D: 1.0660 Loss_G: 2.0082 D(x): 0.6029 D(G(z)): 0.3942 / 0.1483\n",
      "[18/25][29/93] Loss_D: 1.5268 Loss_G: 1.0504 D(x): 0.3747 D(G(z)): 0.3299 / 0.3788\n",
      "[18/25][30/93] Loss_D: 1.4631 Loss_G: 2.1098 D(x): 0.6133 D(G(z)): 0.6026 / 0.1340\n",
      "[18/25][31/93] Loss_D: 1.1874 Loss_G: 1.1633 D(x): 0.4253 D(G(z)): 0.2556 / 0.3306\n",
      "[18/25][32/93] Loss_D: 1.2813 Loss_G: 2.4595 D(x): 0.7102 D(G(z)): 0.5963 / 0.0959\n",
      "[18/25][33/93] Loss_D: 1.3562 Loss_G: 0.9376 D(x): 0.3619 D(G(z)): 0.2459 / 0.4132\n",
      "[18/25][34/93] Loss_D: 1.1903 Loss_G: 2.2193 D(x): 0.7717 D(G(z)): 0.5871 / 0.1170\n",
      "[18/25][35/93] Loss_D: 1.3283 Loss_G: 0.8798 D(x): 0.3774 D(G(z)): 0.2539 / 0.4244\n",
      "[18/25][36/93] Loss_D: 1.1067 Loss_G: 2.0587 D(x): 0.7957 D(G(z)): 0.5733 / 0.1370\n",
      "[18/25][37/93] Loss_D: 1.1635 Loss_G: 1.0950 D(x): 0.4335 D(G(z)): 0.2496 / 0.3514\n",
      "[18/25][38/93] Loss_D: 1.0195 Loss_G: 1.5790 D(x): 0.7141 D(G(z)): 0.4765 / 0.2211\n",
      "[18/25][39/93] Loss_D: 1.0162 Loss_G: 2.0270 D(x): 0.6486 D(G(z)): 0.4240 / 0.1441\n",
      "[18/25][40/93] Loss_D: 1.0503 Loss_G: 1.0949 D(x): 0.5329 D(G(z)): 0.3040 / 0.3522\n",
      "[18/25][41/93] Loss_D: 1.1883 Loss_G: 2.4029 D(x): 0.7416 D(G(z)): 0.5745 / 0.0961\n",
      "[18/25][42/93] Loss_D: 1.2506 Loss_G: 1.1699 D(x): 0.4179 D(G(z)): 0.2343 / 0.3327\n",
      "[18/25][43/93] Loss_D: 1.3017 Loss_G: 1.6748 D(x): 0.6295 D(G(z)): 0.5477 / 0.2033\n",
      "[18/25][44/93] Loss_D: 1.1295 Loss_G: 1.3895 D(x): 0.5199 D(G(z)): 0.3515 / 0.2626\n",
      "[18/25][45/93] Loss_D: 1.2233 Loss_G: 2.4636 D(x): 0.6756 D(G(z)): 0.5421 / 0.0928\n",
      "[18/25][46/93] Loss_D: 1.3632 Loss_G: 1.0438 D(x): 0.4035 D(G(z)): 0.3167 / 0.3899\n",
      "[18/25][47/93] Loss_D: 1.2033 Loss_G: 2.7247 D(x): 0.7612 D(G(z)): 0.5822 / 0.0683\n",
      "[18/25][48/93] Loss_D: 1.2596 Loss_G: 0.9299 D(x): 0.3847 D(G(z)): 0.1764 / 0.4150\n",
      "[18/25][49/93] Loss_D: 1.0707 Loss_G: 2.7030 D(x): 0.8948 D(G(z)): 0.6058 / 0.0739\n",
      "[18/25][50/93] Loss_D: 1.2403 Loss_G: 1.0147 D(x): 0.3866 D(G(z)): 0.1874 / 0.3810\n",
      "[18/25][51/93] Loss_D: 1.3382 Loss_G: 2.4663 D(x): 0.7717 D(G(z)): 0.6342 / 0.0933\n",
      "[18/25][52/93] Loss_D: 1.3352 Loss_G: 1.0138 D(x): 0.3552 D(G(z)): 0.1995 / 0.3927\n",
      "[18/25][53/93] Loss_D: 1.3462 Loss_G: 1.8761 D(x): 0.7145 D(G(z)): 0.5955 / 0.1706\n",
      "[18/25][54/93] Loss_D: 1.0566 Loss_G: 1.8293 D(x): 0.5607 D(G(z)): 0.3488 / 0.1838\n",
      "[18/25][55/93] Loss_D: 1.0644 Loss_G: 1.9185 D(x): 0.6296 D(G(z)): 0.4195 / 0.1591\n",
      "[18/25][56/93] Loss_D: 1.2856 Loss_G: 1.1475 D(x): 0.4609 D(G(z)): 0.3557 / 0.3494\n",
      "[18/25][57/93] Loss_D: 1.2617 Loss_G: 2.5466 D(x): 0.7074 D(G(z)): 0.5840 / 0.0932\n",
      "[18/25][58/93] Loss_D: 1.1794 Loss_G: 0.9970 D(x): 0.4204 D(G(z)): 0.1931 / 0.4194\n",
      "[18/25][59/93] Loss_D: 1.3567 Loss_G: 2.6610 D(x): 0.8003 D(G(z)): 0.6542 / 0.0777\n",
      "[18/25][60/93] Loss_D: 1.0518 Loss_G: 1.3973 D(x): 0.4940 D(G(z)): 0.2461 / 0.2714\n",
      "[18/25][61/93] Loss_D: 1.2537 Loss_G: 0.9593 D(x): 0.5364 D(G(z)): 0.4249 / 0.4105\n",
      "[18/25][62/93] Loss_D: 1.4457 Loss_G: 2.8976 D(x): 0.7934 D(G(z)): 0.6835 / 0.0671\n",
      "[18/25][63/93] Loss_D: 1.6936 Loss_G: 0.9817 D(x): 0.2539 D(G(z)): 0.1413 / 0.4427\n",
      "[18/25][64/93] Loss_D: 1.2809 Loss_G: 1.6952 D(x): 0.7290 D(G(z)): 0.5923 / 0.2012\n",
      "[18/25][65/93] Loss_D: 1.0814 Loss_G: 1.8356 D(x): 0.5833 D(G(z)): 0.3920 / 0.1722\n",
      "[18/25][66/93] Loss_D: 1.2374 Loss_G: 1.1547 D(x): 0.4679 D(G(z)): 0.3476 / 0.3628\n",
      "[18/25][67/93] Loss_D: 1.3530 Loss_G: 2.7901 D(x): 0.7279 D(G(z)): 0.6141 / 0.0763\n",
      "[18/25][68/93] Loss_D: 1.2699 Loss_G: 1.1335 D(x): 0.3704 D(G(z)): 0.1873 / 0.3636\n",
      "[18/25][69/93] Loss_D: 0.9687 Loss_G: 2.5579 D(x): 0.8401 D(G(z)): 0.5324 / 0.0890\n",
      "[18/25][70/93] Loss_D: 1.1450 Loss_G: 1.2565 D(x): 0.4653 D(G(z)): 0.2682 / 0.3062\n",
      "[18/25][71/93] Loss_D: 1.0160 Loss_G: 1.8220 D(x): 0.6965 D(G(z)): 0.4596 / 0.1768\n",
      "[18/25][72/93] Loss_D: 1.1265 Loss_G: 2.0469 D(x): 0.6178 D(G(z)): 0.4471 / 0.1468\n",
      "[18/25][73/93] Loss_D: 1.2958 Loss_G: 1.3403 D(x): 0.4717 D(G(z)): 0.3810 / 0.2948\n",
      "[18/25][74/93] Loss_D: 1.2440 Loss_G: 2.4506 D(x): 0.6673 D(G(z)): 0.5373 / 0.0965\n",
      "[18/25][75/93] Loss_D: 1.3139 Loss_G: 0.8820 D(x): 0.3933 D(G(z)): 0.2474 / 0.4467\n",
      "[18/25][76/93] Loss_D: 1.5005 Loss_G: 4.0180 D(x): 0.8134 D(G(z)): 0.7038 / 0.0229\n",
      "[18/25][77/93] Loss_D: 1.6913 Loss_G: 0.9968 D(x): 0.2352 D(G(z)): 0.1080 / 0.4048\n",
      "[18/25][78/93] Loss_D: 1.3816 Loss_G: 1.9371 D(x): 0.7604 D(G(z)): 0.6527 / 0.1530\n",
      "[18/25][79/93] Loss_D: 1.2181 Loss_G: 1.5244 D(x): 0.4761 D(G(z)): 0.3518 / 0.2309\n",
      "[18/25][80/93] Loss_D: 1.2636 Loss_G: 1.4329 D(x): 0.5288 D(G(z)): 0.4460 / 0.2646\n",
      "[18/25][81/93] Loss_D: 1.0489 Loss_G: 2.0034 D(x): 0.6514 D(G(z)): 0.4453 / 0.1490\n",
      "[18/25][82/93] Loss_D: 0.9260 Loss_G: 1.8121 D(x): 0.6052 D(G(z)): 0.2947 / 0.1748\n",
      "[18/25][83/93] Loss_D: 1.1100 Loss_G: 1.3227 D(x): 0.5366 D(G(z)): 0.3619 / 0.2909\n",
      "[18/25][84/93] Loss_D: 1.0149 Loss_G: 3.1829 D(x): 0.7840 D(G(z)): 0.5222 / 0.0480\n",
      "[18/25][85/93] Loss_D: 1.3473 Loss_G: 0.8123 D(x): 0.3302 D(G(z)): 0.1272 / 0.4643\n",
      "[18/25][86/93] Loss_D: 1.5367 Loss_G: 2.4393 D(x): 0.8650 D(G(z)): 0.7368 / 0.0945\n",
      "[18/25][87/93] Loss_D: 1.3363 Loss_G: 1.1154 D(x): 0.3412 D(G(z)): 0.1787 / 0.3442\n",
      "[18/25][88/93] Loss_D: 1.3340 Loss_G: 1.2383 D(x): 0.6304 D(G(z)): 0.5655 / 0.3082\n",
      "[18/25][89/93] Loss_D: 1.1555 Loss_G: 1.8714 D(x): 0.6332 D(G(z)): 0.4817 / 0.1602\n",
      "[18/25][90/93] Loss_D: 1.2151 Loss_G: 1.4277 D(x): 0.5187 D(G(z)): 0.3971 / 0.2495\n",
      "[18/25][91/93] Loss_D: 1.3128 Loss_G: 0.8808 D(x): 0.4649 D(G(z)): 0.3938 / 0.4420\n",
      "[18/25][92/93] Loss_D: 1.5934 Loss_G: 3.0971 D(x): 0.7448 D(G(z)): 0.7073 / 0.0488\n",
      "[19/25][0/93] Loss_D: 1.7029 Loss_G: 0.8380 D(x): 0.2556 D(G(z)): 0.1462 / 0.4647\n",
      "[19/25][1/93] Loss_D: 1.3661 Loss_G: 1.3945 D(x): 0.6578 D(G(z)): 0.5862 / 0.2613\n",
      "[19/25][2/93] Loss_D: 1.3409 Loss_G: 1.0624 D(x): 0.4826 D(G(z)): 0.4324 / 0.3591\n",
      "[19/25][3/93] Loss_D: 1.0421 Loss_G: 1.6430 D(x): 0.6690 D(G(z)): 0.4537 / 0.2124\n",
      "[19/25][4/93] Loss_D: 1.0790 Loss_G: 1.1068 D(x): 0.5317 D(G(z)): 0.3441 / 0.3452\n",
      "[19/25][5/93] Loss_D: 1.2065 Loss_G: 1.6973 D(x): 0.6677 D(G(z)): 0.5307 / 0.1972\n",
      "[19/25][6/93] Loss_D: 0.9578 Loss_G: 1.7296 D(x): 0.6244 D(G(z)): 0.3654 / 0.1871\n",
      "[19/25][7/93] Loss_D: 1.0447 Loss_G: 1.3549 D(x): 0.5837 D(G(z)): 0.3691 / 0.2753\n",
      "[19/25][8/93] Loss_D: 1.1485 Loss_G: 1.7753 D(x): 0.6151 D(G(z)): 0.4604 / 0.1807\n",
      "[19/25][9/93] Loss_D: 1.1607 Loss_G: 2.0978 D(x): 0.5942 D(G(z)): 0.4483 / 0.1334\n",
      "[19/25][10/93] Loss_D: 1.3516 Loss_G: 1.0313 D(x): 0.4399 D(G(z)): 0.3831 / 0.4255\n",
      "[19/25][11/93] Loss_D: 1.2865 Loss_G: 4.4748 D(x): 0.8141 D(G(z)): 0.6367 / 0.0134\n",
      "[19/25][12/93] Loss_D: 2.5560 Loss_G: 0.6955 D(x): 0.1010 D(G(z)): 0.0393 / 0.5269\n",
      "[19/25][13/93] Loss_D: 1.4011 Loss_G: 1.8658 D(x): 0.8337 D(G(z)): 0.6927 / 0.1663\n",
      "[19/25][14/93] Loss_D: 1.0991 Loss_G: 1.3923 D(x): 0.5158 D(G(z)): 0.2990 / 0.2612\n",
      "[19/25][15/93] Loss_D: 1.1994 Loss_G: 0.9466 D(x): 0.5264 D(G(z)): 0.4101 / 0.4027\n",
      "[19/25][16/93] Loss_D: 1.3258 Loss_G: 1.9382 D(x): 0.6826 D(G(z)): 0.5986 / 0.1530\n",
      "[19/25][17/93] Loss_D: 1.3078 Loss_G: 1.0752 D(x): 0.3888 D(G(z)): 0.2622 / 0.3619\n",
      "[19/25][18/93] Loss_D: 1.2308 Loss_G: 1.5994 D(x): 0.6937 D(G(z)): 0.5641 / 0.2150\n",
      "[19/25][19/93] Loss_D: 0.9995 Loss_G: 1.8605 D(x): 0.6083 D(G(z)): 0.3619 / 0.1651\n",
      "[19/25][20/93] Loss_D: 1.3670 Loss_G: 0.7023 D(x): 0.4028 D(G(z)): 0.3390 / 0.5198\n",
      "[19/25][21/93] Loss_D: 1.1892 Loss_G: 2.3949 D(x): 0.8442 D(G(z)): 0.6227 / 0.1028\n",
      "[19/25][22/93] Loss_D: 1.1660 Loss_G: 1.3270 D(x): 0.4322 D(G(z)): 0.2187 / 0.2800\n",
      "[19/25][23/93] Loss_D: 1.0450 Loss_G: 1.8664 D(x): 0.7128 D(G(z)): 0.4937 / 0.1655\n",
      "[19/25][24/93] Loss_D: 1.2704 Loss_G: 1.2170 D(x): 0.4712 D(G(z)): 0.3792 / 0.3133\n",
      "[19/25][25/93] Loss_D: 1.3588 Loss_G: 1.7088 D(x): 0.5925 D(G(z)): 0.5406 / 0.1920\n",
      "[19/25][26/93] Loss_D: 1.5485 Loss_G: 0.9076 D(x): 0.3765 D(G(z)): 0.3855 / 0.4436\n",
      "[19/25][27/93] Loss_D: 1.4947 Loss_G: 2.3645 D(x): 0.6571 D(G(z)): 0.6356 / 0.0991\n",
      "[19/25][28/93] Loss_D: 1.3706 Loss_G: 0.9483 D(x): 0.3567 D(G(z)): 0.2526 / 0.4047\n",
      "[19/25][29/93] Loss_D: 1.2417 Loss_G: 1.5976 D(x): 0.6547 D(G(z)): 0.5421 / 0.2142\n",
      "[19/25][30/93] Loss_D: 0.9561 Loss_G: 1.8777 D(x): 0.6201 D(G(z)): 0.3665 / 0.1611\n",
      "[19/25][31/93] Loss_D: 1.0170 Loss_G: 1.1802 D(x): 0.5499 D(G(z)): 0.2995 / 0.3208\n",
      "[19/25][32/93] Loss_D: 1.1762 Loss_G: 1.8816 D(x): 0.7069 D(G(z)): 0.5495 / 0.1666\n",
      "[19/25][33/93] Loss_D: 1.0201 Loss_G: 1.3689 D(x): 0.5659 D(G(z)): 0.3027 / 0.2664\n",
      "[19/25][34/93] Loss_D: 1.1423 Loss_G: 1.5232 D(x): 0.6132 D(G(z)): 0.4645 / 0.2341\n",
      "[19/25][35/93] Loss_D: 1.2092 Loss_G: 1.6518 D(x): 0.5669 D(G(z)): 0.4515 / 0.2032\n",
      "[19/25][36/93] Loss_D: 1.1733 Loss_G: 1.0194 D(x): 0.4925 D(G(z)): 0.3422 / 0.3795\n",
      "[19/25][37/93] Loss_D: 1.4170 Loss_G: 2.9060 D(x): 0.7127 D(G(z)): 0.6460 / 0.0589\n",
      "[19/25][38/93] Loss_D: 1.2741 Loss_G: 0.7897 D(x): 0.3482 D(G(z)): 0.1318 / 0.4731\n",
      "[19/25][39/93] Loss_D: 1.4949 Loss_G: 2.7544 D(x): 0.7937 D(G(z)): 0.7013 / 0.0672\n",
      "[19/25][40/93] Loss_D: 1.5076 Loss_G: 0.7365 D(x): 0.2763 D(G(z)): 0.1390 / 0.5021\n",
      "[19/25][41/93] Loss_D: 1.5900 Loss_G: 2.4471 D(x): 0.8228 D(G(z)): 0.7355 / 0.0916\n",
      "[19/25][42/93] Loss_D: 1.1554 Loss_G: 1.3903 D(x): 0.4139 D(G(z)): 0.1780 / 0.2600\n",
      "[19/25][43/93] Loss_D: 1.0612 Loss_G: 1.6215 D(x): 0.6779 D(G(z)): 0.4721 / 0.2196\n",
      "[19/25][44/93] Loss_D: 1.1054 Loss_G: 1.7636 D(x): 0.6177 D(G(z)): 0.4455 / 0.1933\n",
      "[19/25][45/93] Loss_D: 1.1058 Loss_G: 1.5838 D(x): 0.5965 D(G(z)): 0.4094 / 0.2219\n",
      "[19/25][46/93] Loss_D: 1.0972 Loss_G: 1.6102 D(x): 0.6074 D(G(z)): 0.4363 / 0.2175\n",
      "[19/25][47/93] Loss_D: 1.1162 Loss_G: 1.5863 D(x): 0.5772 D(G(z)): 0.4084 / 0.2243\n",
      "[19/25][48/93] Loss_D: 1.2791 Loss_G: 2.8668 D(x): 0.6591 D(G(z)): 0.5543 / 0.0638\n",
      "[19/25][49/93] Loss_D: 1.0703 Loss_G: 1.1147 D(x): 0.4870 D(G(z)): 0.1905 / 0.3520\n",
      "[19/25][50/93] Loss_D: 1.2682 Loss_G: 1.9595 D(x): 0.6739 D(G(z)): 0.5569 / 0.1505\n",
      "[19/25][51/93] Loss_D: 1.1560 Loss_G: 1.1439 D(x): 0.4771 D(G(z)): 0.3085 / 0.3410\n",
      "[19/25][52/93] Loss_D: 1.2037 Loss_G: 2.8342 D(x): 0.7406 D(G(z)): 0.5669 / 0.0621\n",
      "[19/25][53/93] Loss_D: 1.0393 Loss_G: 1.3129 D(x): 0.5108 D(G(z)): 0.1373 / 0.2837\n",
      "[19/25][54/93] Loss_D: 1.1216 Loss_G: 1.4044 D(x): 0.6371 D(G(z)): 0.4714 / 0.2584\n",
      "[19/25][55/93] Loss_D: 1.1983 Loss_G: 1.7590 D(x): 0.5964 D(G(z)): 0.4531 / 0.1937\n",
      "[19/25][56/93] Loss_D: 1.0196 Loss_G: 1.5441 D(x): 0.5912 D(G(z)): 0.3719 / 0.2279\n",
      "[19/25][57/93] Loss_D: 1.0947 Loss_G: 1.9610 D(x): 0.6232 D(G(z)): 0.4431 / 0.1491\n",
      "[19/25][58/93] Loss_D: 1.0218 Loss_G: 1.1181 D(x): 0.5619 D(G(z)): 0.3310 / 0.3487\n",
      "[19/25][59/93] Loss_D: 1.3011 Loss_G: 3.7190 D(x): 0.7495 D(G(z)): 0.6222 / 0.0271\n",
      "[19/25][60/93] Loss_D: 2.0438 Loss_G: 0.4168 D(x): 0.1606 D(G(z)): 0.0787 / 0.6717\n",
      "[19/25][61/93] Loss_D: 1.8923 Loss_G: 2.5624 D(x): 0.9014 D(G(z)): 0.8248 / 0.0840\n",
      "[19/25][62/93] Loss_D: 1.6689 Loss_G: 1.0076 D(x): 0.2422 D(G(z)): 0.1717 / 0.3962\n",
      "[19/25][63/93] Loss_D: 1.1314 Loss_G: 1.3440 D(x): 0.7210 D(G(z)): 0.5381 / 0.2674\n",
      "[19/25][64/93] Loss_D: 1.0338 Loss_G: 1.6480 D(x): 0.6401 D(G(z)): 0.4279 / 0.1982\n",
      "[19/25][65/93] Loss_D: 1.0675 Loss_G: 1.0006 D(x): 0.4895 D(G(z)): 0.2701 / 0.3767\n",
      "[19/25][66/93] Loss_D: 1.3901 Loss_G: 1.6058 D(x): 0.6748 D(G(z)): 0.6049 / 0.2074\n",
      "[19/25][67/93] Loss_D: 1.1474 Loss_G: 1.3334 D(x): 0.5061 D(G(z)): 0.3467 / 0.2848\n",
      "[19/25][68/93] Loss_D: 1.0010 Loss_G: 1.9245 D(x): 0.6908 D(G(z)): 0.4404 / 0.1609\n",
      "[19/25][69/93] Loss_D: 1.3464 Loss_G: 1.2794 D(x): 0.4506 D(G(z)): 0.3893 / 0.3193\n",
      "[19/25][70/93] Loss_D: 1.1501 Loss_G: 2.5467 D(x): 0.7387 D(G(z)): 0.5409 / 0.0913\n",
      "[19/25][71/93] Loss_D: 1.3722 Loss_G: 0.8128 D(x): 0.3514 D(G(z)): 0.2335 / 0.5196\n",
      "[19/25][72/93] Loss_D: 1.5056 Loss_G: 2.7518 D(x): 0.8552 D(G(z)): 0.7225 / 0.0700\n",
      "[19/25][73/93] Loss_D: 1.1167 Loss_G: 1.7566 D(x): 0.4646 D(G(z)): 0.1753 / 0.1812\n",
      "[19/25][74/93] Loss_D: 1.1909 Loss_G: 0.6991 D(x): 0.4616 D(G(z)): 0.3051 / 0.5173\n",
      "[19/25][75/93] Loss_D: 1.4317 Loss_G: 2.4468 D(x): 0.7962 D(G(z)): 0.6801 / 0.0951\n",
      "[19/25][76/93] Loss_D: 1.4785 Loss_G: 0.9603 D(x): 0.3154 D(G(z)): 0.1917 / 0.4033\n",
      "[19/25][77/93] Loss_D: 1.2546 Loss_G: 1.7183 D(x): 0.7379 D(G(z)): 0.5994 / 0.1876\n",
      "[19/25][78/93] Loss_D: 1.0452 Loss_G: 1.9569 D(x): 0.5801 D(G(z)): 0.3555 / 0.1502\n",
      "[19/25][79/93] Loss_D: 1.2195 Loss_G: 1.0781 D(x): 0.4653 D(G(z)): 0.3252 / 0.3661\n",
      "[19/25][80/93] Loss_D: 1.1886 Loss_G: 1.7864 D(x): 0.6712 D(G(z)): 0.5276 / 0.1832\n",
      "[19/25][81/93] Loss_D: 1.3023 Loss_G: 1.2615 D(x): 0.4665 D(G(z)): 0.3907 / 0.3049\n",
      "[19/25][82/93] Loss_D: 1.2026 Loss_G: 2.2661 D(x): 0.7144 D(G(z)): 0.5485 / 0.1135\n",
      "[19/25][83/93] Loss_D: 1.3241 Loss_G: 0.9755 D(x): 0.3906 D(G(z)): 0.2106 / 0.4004\n",
      "[19/25][84/93] Loss_D: 1.2910 Loss_G: 1.2453 D(x): 0.6376 D(G(z)): 0.5476 / 0.3121\n",
      "[19/25][85/93] Loss_D: 1.3923 Loss_G: 2.1158 D(x): 0.6441 D(G(z)): 0.5508 / 0.1569\n",
      "[19/25][86/93] Loss_D: 1.3908 Loss_G: 1.2875 D(x): 0.4102 D(G(z)): 0.3241 / 0.3375\n",
      "[19/25][87/93] Loss_D: 1.1123 Loss_G: 1.8177 D(x): 0.6734 D(G(z)): 0.4721 / 0.1836\n",
      "[19/25][88/93] Loss_D: 1.1026 Loss_G: 1.8565 D(x): 0.6067 D(G(z)): 0.3901 / 0.1740\n",
      "[19/25][89/93] Loss_D: 1.3214 Loss_G: 1.0384 D(x): 0.4819 D(G(z)): 0.3922 / 0.3904\n",
      "[19/25][90/93] Loss_D: 1.4396 Loss_G: 2.4506 D(x): 0.6765 D(G(z)): 0.6261 / 0.1007\n",
      "[19/25][91/93] Loss_D: 1.3357 Loss_G: 0.9468 D(x): 0.3686 D(G(z)): 0.2028 / 0.4447\n",
      "[19/25][92/93] Loss_D: 1.5519 Loss_G: 2.7415 D(x): 0.7824 D(G(z)): 0.6990 / 0.0779\n",
      "[20/25][0/93] Loss_D: 0.9004 Loss_G: 2.1110 D(x): 0.5785 D(G(z)): 0.2153 / 0.1398\n",
      "[20/25][1/93] Loss_D: 1.4194 Loss_G: 0.6562 D(x): 0.3716 D(G(z)): 0.2944 / 0.5906\n",
      "[20/25][2/93] Loss_D: 1.9862 Loss_G: 3.6888 D(x): 0.8597 D(G(z)): 0.8205 / 0.0276\n",
      "[20/25][3/93] Loss_D: 1.9028 Loss_G: 1.0200 D(x): 0.1778 D(G(z)): 0.0765 / 0.3865\n",
      "[20/25][4/93] Loss_D: 1.1683 Loss_G: 1.3301 D(x): 0.7287 D(G(z)): 0.5434 / 0.2870\n",
      "[20/25][5/93] Loss_D: 1.0574 Loss_G: 2.0508 D(x): 0.6830 D(G(z)): 0.4745 / 0.1355\n",
      "[20/25][6/93] Loss_D: 1.2369 Loss_G: 0.9800 D(x): 0.4236 D(G(z)): 0.2853 / 0.3839\n",
      "[20/25][7/93] Loss_D: 1.1775 Loss_G: 1.6826 D(x): 0.7221 D(G(z)): 0.5616 / 0.1925\n",
      "[20/25][8/93] Loss_D: 0.9516 Loss_G: 1.5190 D(x): 0.5742 D(G(z)): 0.3111 / 0.2335\n",
      "[20/25][9/93] Loss_D: 0.9638 Loss_G: 1.4097 D(x): 0.6272 D(G(z)): 0.3765 / 0.2558\n",
      "[20/25][10/93] Loss_D: 1.0614 Loss_G: 1.9245 D(x): 0.6539 D(G(z)): 0.4599 / 0.1510\n",
      "[20/25][11/93] Loss_D: 1.0485 Loss_G: 1.3919 D(x): 0.5424 D(G(z)): 0.3119 / 0.2668\n",
      "[20/25][12/93] Loss_D: 1.1973 Loss_G: 2.4195 D(x): 0.6800 D(G(z)): 0.5311 / 0.0955\n",
      "[20/25][13/93] Loss_D: 1.4992 Loss_G: 0.6226 D(x): 0.3267 D(G(z)): 0.2540 / 0.5675\n",
      "[20/25][14/93] Loss_D: 1.7220 Loss_G: 3.0249 D(x): 0.7862 D(G(z)): 0.7440 / 0.0556\n",
      "[20/25][15/93] Loss_D: 1.5247 Loss_G: 1.1356 D(x): 0.2762 D(G(z)): 0.1462 / 0.3603\n",
      "[20/25][16/93] Loss_D: 1.1641 Loss_G: 1.7047 D(x): 0.7414 D(G(z)): 0.5561 / 0.1947\n",
      "[20/25][17/93] Loss_D: 0.9529 Loss_G: 2.1845 D(x): 0.6728 D(G(z)): 0.4000 / 0.1220\n",
      "[20/25][18/93] Loss_D: 1.3655 Loss_G: 0.7858 D(x): 0.3744 D(G(z)): 0.2696 / 0.4697\n",
      "[20/25][19/93] Loss_D: 1.4397 Loss_G: 1.7908 D(x): 0.7020 D(G(z)): 0.6443 / 0.1862\n",
      "[20/25][20/93] Loss_D: 1.2756 Loss_G: 1.3055 D(x): 0.4503 D(G(z)): 0.3494 / 0.3065\n",
      "[20/25][21/93] Loss_D: 1.1934 Loss_G: 1.7849 D(x): 0.6531 D(G(z)): 0.5216 / 0.1853\n",
      "[20/25][22/93] Loss_D: 1.1929 Loss_G: 1.4396 D(x): 0.5158 D(G(z)): 0.3709 / 0.2649\n",
      "[20/25][23/93] Loss_D: 0.8791 Loss_G: 2.2231 D(x): 0.7298 D(G(z)): 0.4032 / 0.1154\n",
      "[20/25][24/93] Loss_D: 1.3307 Loss_G: 0.7516 D(x): 0.4126 D(G(z)): 0.3119 / 0.4981\n",
      "[20/25][25/93] Loss_D: 1.6919 Loss_G: 3.0244 D(x): 0.7600 D(G(z)): 0.7228 / 0.0602\n",
      "[20/25][26/93] Loss_D: 1.8009 Loss_G: 0.6244 D(x): 0.2043 D(G(z)): 0.1230 / 0.5723\n",
      "[20/25][27/93] Loss_D: 1.5939 Loss_G: 2.1760 D(x): 0.8230 D(G(z)): 0.7178 / 0.1314\n",
      "[20/25][28/93] Loss_D: 1.1863 Loss_G: 1.3152 D(x): 0.4198 D(G(z)): 0.2252 / 0.2806\n",
      "[20/25][29/93] Loss_D: 1.0451 Loss_G: 1.1424 D(x): 0.6177 D(G(z)): 0.4112 / 0.3415\n",
      "[20/25][30/93] Loss_D: 1.1809 Loss_G: 1.7545 D(x): 0.6558 D(G(z)): 0.5159 / 0.1868\n",
      "[20/25][31/93] Loss_D: 1.0894 Loss_G: 1.3720 D(x): 0.5441 D(G(z)): 0.3568 / 0.2682\n",
      "[20/25][32/93] Loss_D: 0.9920 Loss_G: 1.9898 D(x): 0.7268 D(G(z)): 0.4602 / 0.1561\n",
      "[20/25][33/93] Loss_D: 1.3861 Loss_G: 0.9845 D(x): 0.4040 D(G(z)): 0.3446 / 0.4216\n",
      "[20/25][34/93] Loss_D: 1.3133 Loss_G: 1.7354 D(x): 0.6577 D(G(z)): 0.5754 / 0.1886\n",
      "[20/25][35/93] Loss_D: 1.1096 Loss_G: 1.5438 D(x): 0.5100 D(G(z)): 0.3241 / 0.2410\n",
      "[20/25][36/93] Loss_D: 1.0174 Loss_G: 1.1809 D(x): 0.5790 D(G(z)): 0.3575 / 0.3214\n",
      "[20/25][37/93] Loss_D: 1.1738 Loss_G: 2.0402 D(x): 0.6599 D(G(z)): 0.5088 / 0.1544\n",
      "[20/25][38/93] Loss_D: 0.6216 Loss_G: 2.6635 D(x): 0.7451 D(G(z)): 0.2595 / 0.0762\n",
      "[20/25][39/93] Loss_D: 1.6073 Loss_G: 0.4693 D(x): 0.2735 D(G(z)): 0.1970 / 0.6543\n",
      "[20/25][40/93] Loss_D: 2.0139 Loss_G: 2.2993 D(x): 0.9061 D(G(z)): 0.8247 / 0.1136\n",
      "[20/25][41/93] Loss_D: 1.4424 Loss_G: 1.2431 D(x): 0.3072 D(G(z)): 0.1623 / 0.3235\n",
      "[20/25][42/93] Loss_D: 1.3532 Loss_G: 1.2493 D(x): 0.6310 D(G(z)): 0.5545 / 0.3246\n",
      "[20/25][43/93] Loss_D: 1.0836 Loss_G: 1.8043 D(x): 0.6653 D(G(z)): 0.4787 / 0.1708\n",
      "[20/25][44/93] Loss_D: 1.2120 Loss_G: 1.0618 D(x): 0.4419 D(G(z)): 0.2996 / 0.3795\n",
      "[20/25][45/93] Loss_D: 1.2963 Loss_G: 1.5492 D(x): 0.6564 D(G(z)): 0.5693 / 0.2306\n",
      "[20/25][46/93] Loss_D: 1.1785 Loss_G: 1.5867 D(x): 0.5397 D(G(z)): 0.4071 / 0.2218\n",
      "[20/25][47/93] Loss_D: 1.1286 Loss_G: 2.0286 D(x): 0.6412 D(G(z)): 0.4630 / 0.1410\n",
      "[20/25][48/93] Loss_D: 1.2803 Loss_G: 0.9725 D(x): 0.4012 D(G(z)): 0.2734 / 0.4111\n",
      "[20/25][49/93] Loss_D: 1.2876 Loss_G: 1.8848 D(x): 0.7107 D(G(z)): 0.5974 / 0.1627\n",
      "[20/25][50/93] Loss_D: 1.1896 Loss_G: 1.2705 D(x): 0.4670 D(G(z)): 0.3153 / 0.2912\n",
      "[20/25][51/93] Loss_D: 0.9934 Loss_G: 1.8949 D(x): 0.7141 D(G(z)): 0.4697 / 0.1591\n",
      "[20/25][52/93] Loss_D: 1.0897 Loss_G: 0.9449 D(x): 0.4800 D(G(z)): 0.2742 / 0.4035\n",
      "[20/25][53/93] Loss_D: 1.2086 Loss_G: 2.0793 D(x): 0.7397 D(G(z)): 0.5827 / 0.1337\n",
      "[20/25][54/93] Loss_D: 1.1810 Loss_G: 1.3431 D(x): 0.4866 D(G(z)): 0.3188 / 0.2842\n",
      "[20/25][55/93] Loss_D: 1.1076 Loss_G: 1.7123 D(x): 0.6524 D(G(z)): 0.4689 / 0.1928\n",
      "[20/25][56/93] Loss_D: 1.2880 Loss_G: 1.1462 D(x): 0.4814 D(G(z)): 0.3854 / 0.3304\n",
      "[20/25][57/93] Loss_D: 1.3243 Loss_G: 2.1858 D(x): 0.6547 D(G(z)): 0.5693 / 0.1187\n",
      "[20/25][58/93] Loss_D: 1.5405 Loss_G: 0.7671 D(x): 0.3235 D(G(z)): 0.2818 / 0.4933\n",
      "[20/25][59/93] Loss_D: 1.3143 Loss_G: 2.5284 D(x): 0.7938 D(G(z)): 0.6401 / 0.0862\n",
      "[20/25][60/93] Loss_D: 1.3171 Loss_G: 0.9596 D(x): 0.3394 D(G(z)): 0.1793 / 0.4098\n",
      "[20/25][61/93] Loss_D: 1.1702 Loss_G: 1.8094 D(x): 0.7485 D(G(z)): 0.5668 / 0.1745\n",
      "[20/25][62/93] Loss_D: 1.1054 Loss_G: 1.5582 D(x): 0.5287 D(G(z)): 0.3495 / 0.2197\n",
      "[20/25][63/93] Loss_D: 1.0456 Loss_G: 1.3557 D(x): 0.5855 D(G(z)): 0.3800 / 0.2752\n",
      "[20/25][64/93] Loss_D: 1.1879 Loss_G: 2.1593 D(x): 0.6267 D(G(z)): 0.5007 / 0.1298\n",
      "[20/25][65/93] Loss_D: 1.0418 Loss_G: 1.7245 D(x): 0.5459 D(G(z)): 0.3285 / 0.1949\n",
      "[20/25][66/93] Loss_D: 1.1801 Loss_G: 1.4378 D(x): 0.5435 D(G(z)): 0.4181 / 0.2540\n",
      "[20/25][67/93] Loss_D: 1.1480 Loss_G: 2.2909 D(x): 0.6238 D(G(z)): 0.4770 / 0.1097\n",
      "[20/25][68/93] Loss_D: 1.2558 Loss_G: 0.8251 D(x): 0.4204 D(G(z)): 0.2851 / 0.4600\n",
      "[20/25][69/93] Loss_D: 1.2985 Loss_G: 3.3884 D(x): 0.7744 D(G(z)): 0.6389 / 0.0373\n",
      "[20/25][70/93] Loss_D: 1.6886 Loss_G: 0.5070 D(x): 0.2455 D(G(z)): 0.1325 / 0.6147\n",
      "[20/25][71/93] Loss_D: 1.5952 Loss_G: 2.5606 D(x): 0.8488 D(G(z)): 0.7479 / 0.0873\n",
      "[20/25][72/93] Loss_D: 1.7438 Loss_G: 0.7546 D(x): 0.2626 D(G(z)): 0.2313 / 0.4888\n",
      "[20/25][73/93] Loss_D: 1.2830 Loss_G: 1.8797 D(x): 0.7913 D(G(z)): 0.6384 / 0.1692\n",
      "[20/25][74/93] Loss_D: 0.9303 Loss_G: 1.6626 D(x): 0.5797 D(G(z)): 0.2991 / 0.1986\n",
      "[20/25][75/93] Loss_D: 1.0525 Loss_G: 1.1237 D(x): 0.5701 D(G(z)): 0.3647 / 0.3397\n",
      "[20/25][76/93] Loss_D: 1.1616 Loss_G: 2.6641 D(x): 0.7843 D(G(z)): 0.5828 / 0.0773\n",
      "[20/25][77/93] Loss_D: 1.1461 Loss_G: 1.0386 D(x): 0.4271 D(G(z)): 0.1771 / 0.3715\n",
      "[20/25][78/93] Loss_D: 1.3980 Loss_G: 1.5681 D(x): 0.6520 D(G(z)): 0.5880 / 0.2239\n",
      "[20/25][79/93] Loss_D: 1.2232 Loss_G: 1.6699 D(x): 0.5502 D(G(z)): 0.4355 / 0.1972\n",
      "[20/25][80/93] Loss_D: 1.2960 Loss_G: 1.2728 D(x): 0.5027 D(G(z)): 0.4187 / 0.2927\n",
      "[20/25][81/93] Loss_D: 1.1148 Loss_G: 2.1333 D(x): 0.6576 D(G(z)): 0.4783 / 0.1265\n",
      "[20/25][82/93] Loss_D: 1.3721 Loss_G: 0.8337 D(x): 0.3852 D(G(z)): 0.3034 / 0.4632\n",
      "[20/25][83/93] Loss_D: 1.5390 Loss_G: 2.8453 D(x): 0.7624 D(G(z)): 0.6918 / 0.0658\n",
      "[20/25][84/93] Loss_D: 1.2689 Loss_G: 1.1103 D(x): 0.3649 D(G(z)): 0.1623 / 0.3482\n",
      "[20/25][85/93] Loss_D: 1.2098 Loss_G: 1.4682 D(x): 0.6680 D(G(z)): 0.5374 / 0.2435\n",
      "[20/25][86/93] Loss_D: 1.1665 Loss_G: 1.5276 D(x): 0.5962 D(G(z)): 0.4542 / 0.2306\n",
      "[20/25][87/93] Loss_D: 1.1464 Loss_G: 1.2663 D(x): 0.5433 D(G(z)): 0.3891 / 0.3082\n",
      "[20/25][88/93] Loss_D: 1.2344 Loss_G: 1.9147 D(x): 0.6547 D(G(z)): 0.5301 / 0.1626\n",
      "[20/25][89/93] Loss_D: 1.2596 Loss_G: 1.3915 D(x): 0.4802 D(G(z)): 0.3741 / 0.2688\n",
      "[20/25][90/93] Loss_D: 1.1011 Loss_G: 1.9801 D(x): 0.6581 D(G(z)): 0.4653 / 0.1524\n",
      "[20/25][91/93] Loss_D: 1.1532 Loss_G: 1.7573 D(x): 0.5391 D(G(z)): 0.3919 / 0.1865\n",
      "[20/25][92/93] Loss_D: 1.0731 Loss_G: 1.6477 D(x): 0.5986 D(G(z)): 0.3994 / 0.2130\n",
      "[21/25][0/93] Loss_D: 1.2072 Loss_G: 1.7269 D(x): 0.5521 D(G(z)): 0.4357 / 0.1944\n",
      "[21/25][1/93] Loss_D: 1.1996 Loss_G: 1.5917 D(x): 0.5489 D(G(z)): 0.4256 / 0.2232\n",
      "[21/25][2/93] Loss_D: 1.2325 Loss_G: 2.2464 D(x): 0.6067 D(G(z)): 0.5004 / 0.1229\n",
      "[21/25][3/93] Loss_D: 1.1838 Loss_G: 0.9119 D(x): 0.4466 D(G(z)): 0.2678 / 0.4341\n",
      "[21/25][4/93] Loss_D: 1.2827 Loss_G: 2.9929 D(x): 0.7883 D(G(z)): 0.6288 / 0.0544\n",
      "[21/25][5/93] Loss_D: 1.2511 Loss_G: 0.9363 D(x): 0.3763 D(G(z)): 0.1512 / 0.4076\n",
      "[21/25][6/93] Loss_D: 1.3743 Loss_G: 2.0110 D(x): 0.7152 D(G(z)): 0.6290 / 0.1576\n",
      "[21/25][7/93] Loss_D: 0.8698 Loss_G: 1.9473 D(x): 0.6110 D(G(z)): 0.2917 / 0.1650\n",
      "[21/25][8/93] Loss_D: 0.7327 Loss_G: 2.2712 D(x): 0.7633 D(G(z)): 0.3493 / 0.1149\n",
      "[21/25][9/93] Loss_D: 1.0881 Loss_G: 0.8380 D(x): 0.4775 D(G(z)): 0.2665 / 0.4754\n",
      "[21/25][10/93] Loss_D: 1.5065 Loss_G: 3.5861 D(x): 0.8034 D(G(z)): 0.7084 / 0.0291\n",
      "[21/25][11/93] Loss_D: 1.8318 Loss_G: 0.8620 D(x): 0.2063 D(G(z)): 0.0770 / 0.4314\n",
      "[21/25][12/93] Loss_D: 1.2893 Loss_G: 1.3522 D(x): 0.7291 D(G(z)): 0.6110 / 0.2669\n",
      "[21/25][13/93] Loss_D: 1.1071 Loss_G: 1.5197 D(x): 0.5769 D(G(z)): 0.4142 / 0.2292\n",
      "[21/25][14/93] Loss_D: 1.0587 Loss_G: 1.2963 D(x): 0.5700 D(G(z)): 0.3744 / 0.2882\n",
      "[21/25][15/93] Loss_D: 0.9418 Loss_G: 2.1599 D(x): 0.7507 D(G(z)): 0.4635 / 0.1196\n",
      "[21/25][16/93] Loss_D: 1.3149 Loss_G: 0.7065 D(x): 0.3619 D(G(z)): 0.2119 / 0.5144\n",
      "[21/25][17/93] Loss_D: 1.3060 Loss_G: 2.0468 D(x): 0.8184 D(G(z)): 0.6574 / 0.1380\n",
      "[21/25][18/93] Loss_D: 1.1815 Loss_G: 1.1347 D(x): 0.4433 D(G(z)): 0.2680 / 0.3431\n",
      "[21/25][19/93] Loss_D: 1.1163 Loss_G: 1.6097 D(x): 0.6823 D(G(z)): 0.4993 / 0.2206\n",
      "[21/25][20/93] Loss_D: 0.9744 Loss_G: 1.9904 D(x): 0.6698 D(G(z)): 0.4092 / 0.1482\n",
      "[21/25][21/93] Loss_D: 1.1089 Loss_G: 1.0890 D(x): 0.5042 D(G(z)): 0.2924 / 0.3629\n",
      "[21/25][22/93] Loss_D: 1.3923 Loss_G: 3.5189 D(x): 0.7838 D(G(z)): 0.6647 / 0.0322\n",
      "[21/25][23/93] Loss_D: 2.1585 Loss_G: 0.3454 D(x): 0.1436 D(G(z)): 0.0868 / 0.7190\n",
      "[21/25][24/93] Loss_D: 1.8791 Loss_G: 2.2217 D(x): 0.8841 D(G(z)): 0.8105 / 0.1158\n",
      "[21/25][25/93] Loss_D: 1.2332 Loss_G: 1.2168 D(x): 0.3808 D(G(z)): 0.1853 / 0.3091\n",
      "[21/25][26/93] Loss_D: 1.1205 Loss_G: 1.2239 D(x): 0.6284 D(G(z)): 0.4646 / 0.3102\n",
      "[21/25][27/93] Loss_D: 1.0380 Loss_G: 2.2756 D(x): 0.7259 D(G(z)): 0.5001 / 0.1086\n",
      "[21/25][28/93] Loss_D: 1.2633 Loss_G: 0.9276 D(x): 0.3849 D(G(z)): 0.2170 / 0.4093\n",
      "[21/25][29/93] Loss_D: 1.3021 Loss_G: 2.0627 D(x): 0.7484 D(G(z)): 0.6266 / 0.1324\n",
      "[21/25][30/93] Loss_D: 1.1432 Loss_G: 1.2006 D(x): 0.4417 D(G(z)): 0.2457 / 0.3210\n",
      "[21/25][31/93] Loss_D: 1.2597 Loss_G: 1.9187 D(x): 0.6659 D(G(z)): 0.5519 / 0.1603\n",
      "[21/25][32/93] Loss_D: 1.4115 Loss_G: 0.9539 D(x): 0.3979 D(G(z)): 0.3411 / 0.4049\n",
      "[21/25][33/93] Loss_D: 1.3696 Loss_G: 2.4221 D(x): 0.6802 D(G(z)): 0.6128 / 0.0973\n",
      "[21/25][34/93] Loss_D: 1.5277 Loss_G: 0.7089 D(x): 0.3135 D(G(z)): 0.2531 / 0.5282\n",
      "[21/25][35/93] Loss_D: 1.3189 Loss_G: 2.1786 D(x): 0.8021 D(G(z)): 0.6490 / 0.1192\n",
      "[21/25][36/93] Loss_D: 1.1204 Loss_G: 1.2740 D(x): 0.4377 D(G(z)): 0.2285 / 0.2947\n",
      "[21/25][37/93] Loss_D: 1.1206 Loss_G: 1.5587 D(x): 0.6667 D(G(z)): 0.4968 / 0.2273\n",
      "[21/25][38/93] Loss_D: 0.9963 Loss_G: 2.0789 D(x): 0.6663 D(G(z)): 0.4261 / 0.1321\n",
      "[21/25][39/93] Loss_D: 1.1798 Loss_G: 1.0593 D(x): 0.4788 D(G(z)): 0.3195 / 0.3754\n",
      "[21/25][40/93] Loss_D: 1.3078 Loss_G: 2.4756 D(x): 0.7024 D(G(z)): 0.5927 / 0.0894\n",
      "[21/25][41/93] Loss_D: 1.3320 Loss_G: 0.7237 D(x): 0.3594 D(G(z)): 0.1845 / 0.4998\n",
      "[21/25][42/93] Loss_D: 1.4493 Loss_G: 3.3834 D(x): 0.8573 D(G(z)): 0.7127 / 0.0356\n",
      "[21/25][43/93] Loss_D: 1.5478 Loss_G: 0.9906 D(x): 0.2545 D(G(z)): 0.0799 / 0.3973\n",
      "[21/25][44/93] Loss_D: 1.1016 Loss_G: 1.8179 D(x): 0.7701 D(G(z)): 0.5518 / 0.1730\n",
      "[21/25][45/93] Loss_D: 0.8325 Loss_G: 2.5793 D(x): 0.7161 D(G(z)): 0.3746 / 0.0811\n",
      "[21/25][46/93] Loss_D: 1.0903 Loss_G: 0.9883 D(x): 0.4289 D(G(z)): 0.1790 / 0.3877\n",
      "[21/25][47/93] Loss_D: 1.1019 Loss_G: 2.4633 D(x): 0.8135 D(G(z)): 0.5834 / 0.0908\n",
      "[21/25][48/93] Loss_D: 1.0613 Loss_G: 1.3553 D(x): 0.4912 D(G(z)): 0.2760 / 0.2793\n",
      "[21/25][49/93] Loss_D: 1.1195 Loss_G: 3.4872 D(x): 0.7978 D(G(z)): 0.5695 / 0.0373\n",
      "[21/25][50/93] Loss_D: 1.5329 Loss_G: 0.8460 D(x): 0.2757 D(G(z)): 0.1251 / 0.4734\n",
      "[21/25][51/93] Loss_D: 1.4135 Loss_G: 2.7980 D(x): 0.8480 D(G(z)): 0.6925 / 0.0661\n",
      "[21/25][52/93] Loss_D: 1.0895 Loss_G: 1.2189 D(x): 0.4486 D(G(z)): 0.1991 / 0.3245\n",
      "[21/25][53/93] Loss_D: 1.2016 Loss_G: 2.9512 D(x): 0.8167 D(G(z)): 0.6179 / 0.0636\n",
      "[21/25][54/93] Loss_D: 1.3874 Loss_G: 0.9328 D(x): 0.3255 D(G(z)): 0.1869 / 0.4380\n",
      "[21/25][55/93] Loss_D: 1.5114 Loss_G: 2.9833 D(x): 0.8312 D(G(z)): 0.7090 / 0.0586\n",
      "[21/25][56/93] Loss_D: 1.4480 Loss_G: 1.1235 D(x): 0.3174 D(G(z)): 0.1756 / 0.3557\n",
      "[21/25][57/93] Loss_D: 1.3552 Loss_G: 2.4318 D(x): 0.7142 D(G(z)): 0.6160 / 0.1002\n",
      "[21/25][58/93] Loss_D: 1.3775 Loss_G: 1.3496 D(x): 0.3749 D(G(z)): 0.2637 / 0.3050\n",
      "[21/25][59/93] Loss_D: 1.2363 Loss_G: 2.0469 D(x): 0.7060 D(G(z)): 0.5646 / 0.1479\n",
      "[21/25][60/93] Loss_D: 0.9336 Loss_G: 2.0532 D(x): 0.6161 D(G(z)): 0.3299 / 0.1375\n",
      "[21/25][61/93] Loss_D: 1.1871 Loss_G: 1.3755 D(x): 0.5021 D(G(z)): 0.3489 / 0.2875\n",
      "[21/25][62/93] Loss_D: 1.2840 Loss_G: 1.6850 D(x): 0.6424 D(G(z)): 0.5417 / 0.2030\n",
      "[21/25][63/93] Loss_D: 1.3183 Loss_G: 1.2312 D(x): 0.4780 D(G(z)): 0.4151 / 0.3124\n",
      "[21/25][64/93] Loss_D: 1.0592 Loss_G: 1.8433 D(x): 0.6771 D(G(z)): 0.4672 / 0.1719\n",
      "[21/25][65/93] Loss_D: 0.9092 Loss_G: 1.7538 D(x): 0.6116 D(G(z)): 0.3136 / 0.1823\n",
      "[21/25][66/93] Loss_D: 1.0356 Loss_G: 1.2038 D(x): 0.5604 D(G(z)): 0.3473 / 0.3222\n",
      "[21/25][67/93] Loss_D: 1.1105 Loss_G: 3.0657 D(x): 0.7533 D(G(z)): 0.5455 / 0.0510\n",
      "[21/25][68/93] Loss_D: 1.3115 Loss_G: 0.5199 D(x): 0.3472 D(G(z)): 0.1569 / 0.6336\n",
      "[21/25][69/93] Loss_D: 1.8337 Loss_G: 3.2841 D(x): 0.9320 D(G(z)): 0.8040 / 0.0454\n",
      "[21/25][70/93] Loss_D: 1.3664 Loss_G: 2.0234 D(x): 0.3439 D(G(z)): 0.1084 / 0.1488\n",
      "[21/25][71/93] Loss_D: 0.9240 Loss_G: 1.2922 D(x): 0.6096 D(G(z)): 0.3174 / 0.3058\n",
      "[21/25][72/93] Loss_D: 1.3515 Loss_G: 2.3522 D(x): 0.7202 D(G(z)): 0.5947 / 0.1180\n",
      "[21/25][73/93] Loss_D: 1.3357 Loss_G: 1.1040 D(x): 0.4094 D(G(z)): 0.2850 / 0.4352\n",
      "[21/25][74/93] Loss_D: 1.3980 Loss_G: 2.3811 D(x): 0.7653 D(G(z)): 0.6423 / 0.1144\n",
      "[21/25][75/93] Loss_D: 1.2471 Loss_G: 1.5412 D(x): 0.4462 D(G(z)): 0.2869 / 0.2320\n",
      "[21/25][76/93] Loss_D: 1.0096 Loss_G: 1.2845 D(x): 0.5919 D(G(z)): 0.3582 / 0.3136\n",
      "[21/25][77/93] Loss_D: 1.0558 Loss_G: 2.6894 D(x): 0.8161 D(G(z)): 0.5456 / 0.0786\n",
      "[21/25][78/93] Loss_D: 1.1912 Loss_G: 1.3035 D(x): 0.3999 D(G(z)): 0.1573 / 0.2960\n",
      "[21/25][79/93] Loss_D: 1.0286 Loss_G: 2.0338 D(x): 0.7662 D(G(z)): 0.5113 / 0.1429\n",
      "[21/25][80/93] Loss_D: 0.9879 Loss_G: 1.6317 D(x): 0.5615 D(G(z)): 0.2963 / 0.2136\n",
      "[21/25][81/93] Loss_D: 1.1101 Loss_G: 2.1352 D(x): 0.6677 D(G(z)): 0.4747 / 0.1288\n",
      "[21/25][82/93] Loss_D: 1.1601 Loss_G: 1.2401 D(x): 0.4434 D(G(z)): 0.2622 / 0.3295\n",
      "[21/25][83/93] Loss_D: 1.3339 Loss_G: 1.9002 D(x): 0.6352 D(G(z)): 0.5620 / 0.1651\n",
      "[21/25][84/93] Loss_D: 1.2194 Loss_G: 1.2581 D(x): 0.4577 D(G(z)): 0.3268 / 0.3025\n",
      "[21/25][85/93] Loss_D: 1.2095 Loss_G: 2.2519 D(x): 0.6635 D(G(z)): 0.5299 / 0.1165\n",
      "[21/25][86/93] Loss_D: 1.0544 Loss_G: 1.8138 D(x): 0.5741 D(G(z)): 0.3027 / 0.1725\n",
      "[21/25][87/93] Loss_D: 1.1622 Loss_G: 1.3327 D(x): 0.5550 D(G(z)): 0.3961 / 0.3012\n",
      "[21/25][88/93] Loss_D: 0.8698 Loss_G: 2.3351 D(x): 0.7452 D(G(z)): 0.4175 / 0.1096\n",
      "[21/25][89/93] Loss_D: 1.1393 Loss_G: 1.3205 D(x): 0.5134 D(G(z)): 0.3356 / 0.3082\n",
      "[21/25][90/93] Loss_D: 1.1727 Loss_G: 2.2641 D(x): 0.6809 D(G(z)): 0.5224 / 0.1309\n",
      "[21/25][91/93] Loss_D: 0.9108 Loss_G: 2.1177 D(x): 0.6124 D(G(z)): 0.3071 / 0.1589\n",
      "[21/25][92/93] Loss_D: 1.3437 Loss_G: 2.1920 D(x): 0.5687 D(G(z)): 0.5053 / 0.1520\n",
      "[22/25][0/93] Loss_D: 1.1038 Loss_G: 3.3179 D(x): 0.6556 D(G(z)): 0.4579 / 0.0492\n",
      "[22/25][1/93] Loss_D: 1.3631 Loss_G: 0.9652 D(x): 0.3590 D(G(z)): 0.2305 / 0.4744\n",
      "[22/25][2/93] Loss_D: 1.7417 Loss_G: 4.2699 D(x): 0.8784 D(G(z)): 0.7727 / 0.0159\n",
      "[22/25][3/93] Loss_D: 2.1232 Loss_G: 0.7137 D(x): 0.1607 D(G(z)): 0.0666 / 0.5501\n",
      "[22/25][4/93] Loss_D: 1.4245 Loss_G: 2.0368 D(x): 0.8734 D(G(z)): 0.6942 / 0.1388\n",
      "[22/25][5/93] Loss_D: 1.0843 Loss_G: 1.4432 D(x): 0.4584 D(G(z)): 0.2273 / 0.2623\n",
      "[22/25][6/93] Loss_D: 1.1898 Loss_G: 1.1948 D(x): 0.5872 D(G(z)): 0.4516 / 0.3211\n",
      "[22/25][7/93] Loss_D: 0.9995 Loss_G: 2.1997 D(x): 0.7403 D(G(z)): 0.4893 / 0.1146\n",
      "[22/25][8/93] Loss_D: 1.2296 Loss_G: 0.9762 D(x): 0.4088 D(G(z)): 0.2348 / 0.3943\n",
      "[22/25][9/93] Loss_D: 1.3205 Loss_G: 1.9988 D(x): 0.7232 D(G(z)): 0.6140 / 0.1466\n",
      "[22/25][10/93] Loss_D: 0.8670 Loss_G: 2.4884 D(x): 0.6803 D(G(z)): 0.3433 / 0.0917\n",
      "[22/25][11/93] Loss_D: 1.3270 Loss_G: 0.8976 D(x): 0.3843 D(G(z)): 0.2357 / 0.4417\n",
      "[22/25][12/93] Loss_D: 1.4802 Loss_G: 2.3612 D(x): 0.7109 D(G(z)): 0.6490 / 0.1063\n",
      "[22/25][13/93] Loss_D: 1.3631 Loss_G: 1.2222 D(x): 0.3894 D(G(z)): 0.2918 / 0.3201\n",
      "[22/25][14/93] Loss_D: 1.2669 Loss_G: 1.7980 D(x): 0.6213 D(G(z)): 0.5259 / 0.1750\n",
      "[22/25][15/93] Loss_D: 1.0204 Loss_G: 1.5681 D(x): 0.5669 D(G(z)): 0.3471 / 0.2221\n",
      "[22/25][16/93] Loss_D: 1.1490 Loss_G: 1.1898 D(x): 0.5609 D(G(z)): 0.4133 / 0.3318\n",
      "[22/25][17/93] Loss_D: 1.1578 Loss_G: 2.6056 D(x): 0.6746 D(G(z)): 0.5109 / 0.0781\n",
      "[22/25][18/93] Loss_D: 0.9842 Loss_G: 1.1419 D(x): 0.5128 D(G(z)): 0.2312 / 0.3326\n",
      "[22/25][19/93] Loss_D: 1.1426 Loss_G: 2.5865 D(x): 0.7576 D(G(z)): 0.5664 / 0.0812\n",
      "[22/25][20/93] Loss_D: 1.4830 Loss_G: 0.5626 D(x): 0.3063 D(G(z)): 0.1784 / 0.5939\n",
      "[22/25][21/93] Loss_D: 1.6991 Loss_G: 2.7196 D(x): 0.8687 D(G(z)): 0.7743 / 0.0723\n",
      "[22/25][22/93] Loss_D: 1.5271 Loss_G: 1.1037 D(x): 0.2856 D(G(z)): 0.1630 / 0.3529\n",
      "[22/25][23/93] Loss_D: 1.3026 Loss_G: 1.1952 D(x): 0.6221 D(G(z)): 0.5367 / 0.3237\n",
      "[22/25][24/93] Loss_D: 1.0273 Loss_G: 2.1104 D(x): 0.6966 D(G(z)): 0.4708 / 0.1268\n",
      "[22/25][25/93] Loss_D: 0.8558 Loss_G: 1.7442 D(x): 0.6419 D(G(z)): 0.2740 / 0.1845\n",
      "[22/25][26/93] Loss_D: 1.2490 Loss_G: 1.0229 D(x): 0.5135 D(G(z)): 0.4173 / 0.3895\n",
      "[22/25][27/93] Loss_D: 1.1257 Loss_G: 2.6186 D(x): 0.7764 D(G(z)): 0.5705 / 0.0786\n",
      "[22/25][28/93] Loss_D: 0.9838 Loss_G: 2.2125 D(x): 0.5853 D(G(z)): 0.2910 / 0.1215\n",
      "[22/25][29/93] Loss_D: 1.4747 Loss_G: 0.5640 D(x): 0.3659 D(G(z)): 0.3136 / 0.5978\n",
      "[22/25][30/93] Loss_D: 1.7177 Loss_G: 2.9911 D(x): 0.8188 D(G(z)): 0.7458 / 0.0582\n",
      "[22/25][31/93] Loss_D: 1.1527 Loss_G: 1.8188 D(x): 0.4585 D(G(z)): 0.1501 / 0.1853\n",
      "[22/25][32/93] Loss_D: 1.4172 Loss_G: 1.0571 D(x): 0.4824 D(G(z)): 0.4618 / 0.3922\n",
      "[22/25][33/93] Loss_D: 1.3134 Loss_G: 2.3701 D(x): 0.6849 D(G(z)): 0.5773 / 0.1095\n",
      "[22/25][34/93] Loss_D: 1.2862 Loss_G: 1.1088 D(x): 0.3968 D(G(z)): 0.2494 / 0.3760\n",
      "[22/25][35/93] Loss_D: 1.2915 Loss_G: 2.1755 D(x): 0.7205 D(G(z)): 0.5825 / 0.1336\n",
      "[22/25][36/93] Loss_D: 1.2682 Loss_G: 1.6080 D(x): 0.4500 D(G(z)): 0.3401 / 0.2353\n",
      "[22/25][37/93] Loss_D: 1.0807 Loss_G: 1.9006 D(x): 0.6476 D(G(z)): 0.4593 / 0.1717\n",
      "[22/25][38/93] Loss_D: 1.1158 Loss_G: 1.4471 D(x): 0.5312 D(G(z)): 0.3576 / 0.2724\n",
      "[22/25][39/93] Loss_D: 1.1613 Loss_G: 2.5474 D(x): 0.6964 D(G(z)): 0.5330 / 0.0903\n",
      "[22/25][40/93] Loss_D: 0.9302 Loss_G: 1.5621 D(x): 0.5624 D(G(z)): 0.2543 / 0.2406\n",
      "[22/25][41/93] Loss_D: 1.1620 Loss_G: 3.2655 D(x): 0.7330 D(G(z)): 0.5546 / 0.0452\n",
      "[22/25][42/93] Loss_D: 1.6089 Loss_G: 0.3934 D(x): 0.2883 D(G(z)): 0.1973 / 0.6969\n",
      "[22/25][43/93] Loss_D: 2.1340 Loss_G: 3.5217 D(x): 0.8965 D(G(z)): 0.8492 / 0.0346\n",
      "[22/25][44/93] Loss_D: 1.8688 Loss_G: 0.9552 D(x): 0.1878 D(G(z)): 0.0952 / 0.4194\n",
      "[22/25][45/93] Loss_D: 1.2790 Loss_G: 1.3213 D(x): 0.6944 D(G(z)): 0.5740 / 0.2830\n",
      "[22/25][46/93] Loss_D: 1.4154 Loss_G: 2.4092 D(x): 0.6469 D(G(z)): 0.5984 / 0.0947\n",
      "[22/25][47/93] Loss_D: 1.3025 Loss_G: 1.1496 D(x): 0.3702 D(G(z)): 0.2045 / 0.3319\n",
      "[22/25][48/93] Loss_D: 1.3440 Loss_G: 1.3319 D(x): 0.6008 D(G(z)): 0.5334 / 0.2756\n",
      "[22/25][49/93] Loss_D: 1.2386 Loss_G: 2.2598 D(x): 0.6362 D(G(z)): 0.5232 / 0.1093\n",
      "[22/25][50/93] Loss_D: 1.1946 Loss_G: 1.0689 D(x): 0.4077 D(G(z)): 0.2170 / 0.3580\n",
      "[22/25][51/93] Loss_D: 1.2274 Loss_G: 2.3175 D(x): 0.7799 D(G(z)): 0.6113 / 0.1073\n",
      "[22/25][52/93] Loss_D: 1.1667 Loss_G: 1.1708 D(x): 0.4126 D(G(z)): 0.2055 / 0.3310\n",
      "[22/25][53/93] Loss_D: 1.2860 Loss_G: 2.1402 D(x): 0.7588 D(G(z)): 0.6112 / 0.1261\n",
      "[22/25][54/93] Loss_D: 1.2442 Loss_G: 1.0842 D(x): 0.3998 D(G(z)): 0.2225 / 0.3543\n",
      "[22/25][55/93] Loss_D: 1.2385 Loss_G: 2.0816 D(x): 0.7719 D(G(z)): 0.6110 / 0.1378\n",
      "[22/25][56/93] Loss_D: 1.1812 Loss_G: 1.2646 D(x): 0.4447 D(G(z)): 0.2828 / 0.3053\n",
      "[22/25][57/93] Loss_D: 1.2136 Loss_G: 1.8921 D(x): 0.6715 D(G(z)): 0.5377 / 0.1651\n",
      "[22/25][58/93] Loss_D: 1.0629 Loss_G: 1.5056 D(x): 0.5374 D(G(z)): 0.3179 / 0.2378\n",
      "[22/25][59/93] Loss_D: 1.0961 Loss_G: 1.6630 D(x): 0.6011 D(G(z)): 0.4281 / 0.2060\n",
      "[22/25][60/93] Loss_D: 1.1362 Loss_G: 1.6120 D(x): 0.5646 D(G(z)): 0.4060 / 0.2185\n",
      "[22/25][61/93] Loss_D: 1.1226 Loss_G: 1.5258 D(x): 0.5546 D(G(z)): 0.3975 / 0.2403\n",
      "[22/25][62/93] Loss_D: 0.9838 Loss_G: 2.7414 D(x): 0.7124 D(G(z)): 0.4598 / 0.0704\n",
      "[22/25][63/93] Loss_D: 1.4184 Loss_G: 0.5540 D(x): 0.3244 D(G(z)): 0.2004 / 0.6016\n",
      "[22/25][64/93] Loss_D: 1.5836 Loss_G: 2.8429 D(x): 0.8085 D(G(z)): 0.7310 / 0.0635\n",
      "[22/25][65/93] Loss_D: 1.5223 Loss_G: 1.1165 D(x): 0.2829 D(G(z)): 0.1274 / 0.3488\n",
      "[22/25][66/93] Loss_D: 1.1534 Loss_G: 1.6305 D(x): 0.7360 D(G(z)): 0.5539 / 0.2133\n",
      "[22/25][67/93] Loss_D: 1.1871 Loss_G: 1.1791 D(x): 0.4920 D(G(z)): 0.3492 / 0.3273\n",
      "[22/25][68/93] Loss_D: 1.1827 Loss_G: 2.1287 D(x): 0.7356 D(G(z)): 0.5672 / 0.1297\n",
      "[22/25][69/93] Loss_D: 1.0858 Loss_G: 1.3375 D(x): 0.4769 D(G(z)): 0.2635 / 0.2800\n",
      "[22/25][70/93] Loss_D: 1.2341 Loss_G: 2.2087 D(x): 0.6655 D(G(z)): 0.5433 / 0.1217\n",
      "[22/25][71/93] Loss_D: 1.1560 Loss_G: 1.3039 D(x): 0.4557 D(G(z)): 0.2681 / 0.3256\n",
      "[22/25][72/93] Loss_D: 1.3320 Loss_G: 2.7215 D(x): 0.7146 D(G(z)): 0.6030 / 0.0732\n",
      "[22/25][73/93] Loss_D: 1.3566 Loss_G: 0.8467 D(x): 0.3678 D(G(z)): 0.2391 / 0.4586\n",
      "[22/25][74/93] Loss_D: 1.3782 Loss_G: 2.7840 D(x): 0.8274 D(G(z)): 0.6732 / 0.0692\n",
      "[22/25][75/93] Loss_D: 1.1668 Loss_G: 1.6214 D(x): 0.4325 D(G(z)): 0.2285 / 0.2198\n",
      "[22/25][76/93] Loss_D: 1.0755 Loss_G: 1.1523 D(x): 0.5530 D(G(z)): 0.3518 / 0.3441\n",
      "[22/25][77/93] Loss_D: 1.3033 Loss_G: 1.9929 D(x): 0.6970 D(G(z)): 0.5785 / 0.1575\n",
      "[22/25][78/93] Loss_D: 1.1075 Loss_G: 1.4114 D(x): 0.5208 D(G(z)): 0.3186 / 0.2588\n",
      "[22/25][79/93] Loss_D: 1.3409 Loss_G: 1.2608 D(x): 0.5351 D(G(z)): 0.4796 / 0.3197\n",
      "[22/25][80/93] Loss_D: 1.3596 Loss_G: 2.8576 D(x): 0.7164 D(G(z)): 0.6053 / 0.0713\n",
      "[22/25][81/93] Loss_D: 1.6062 Loss_G: 0.6625 D(x): 0.2629 D(G(z)): 0.1649 / 0.5741\n",
      "[22/25][82/93] Loss_D: 1.6495 Loss_G: 2.6732 D(x): 0.8883 D(G(z)): 0.7691 / 0.0734\n",
      "[22/25][83/93] Loss_D: 1.2092 Loss_G: 1.3875 D(x): 0.3720 D(G(z)): 0.1570 / 0.2859\n",
      "[22/25][84/93] Loss_D: 1.1067 Loss_G: 1.4474 D(x): 0.6629 D(G(z)): 0.4837 / 0.2524\n",
      "[22/25][85/93] Loss_D: 0.9881 Loss_G: 2.1450 D(x): 0.6842 D(G(z)): 0.4323 / 0.1318\n",
      "[22/25][86/93] Loss_D: 0.9841 Loss_G: 1.6758 D(x): 0.5649 D(G(z)): 0.3000 / 0.2102\n",
      "[22/25][87/93] Loss_D: 1.3323 Loss_G: 1.6527 D(x): 0.5408 D(G(z)): 0.4760 / 0.2424\n",
      "[22/25][88/93] Loss_D: 1.1938 Loss_G: 2.9681 D(x): 0.6612 D(G(z)): 0.5217 / 0.0581\n",
      "[22/25][89/93] Loss_D: 1.5588 Loss_G: 0.4448 D(x): 0.2884 D(G(z)): 0.1902 / 0.6753\n",
      "[22/25][90/93] Loss_D: 2.1140 Loss_G: 3.3114 D(x): 0.8899 D(G(z)): 0.8440 / 0.0424\n",
      "[22/25][91/93] Loss_D: 1.4785 Loss_G: 1.3343 D(x): 0.2908 D(G(z)): 0.1203 / 0.2811\n",
      "[22/25][92/93] Loss_D: 1.2019 Loss_G: 0.9932 D(x): 0.5835 D(G(z)): 0.4659 / 0.3919\n",
      "[23/25][0/93] Loss_D: 1.2346 Loss_G: 2.0088 D(x): 0.7346 D(G(z)): 0.5918 / 0.1431\n",
      "[23/25][1/93] Loss_D: 1.1660 Loss_G: 1.3366 D(x): 0.4411 D(G(z)): 0.2683 / 0.2755\n",
      "[23/25][2/93] Loss_D: 1.1348 Loss_G: 1.0515 D(x): 0.5580 D(G(z)): 0.4055 / 0.3615\n",
      "[23/25][3/93] Loss_D: 1.1903 Loss_G: 2.4484 D(x): 0.7227 D(G(z)): 0.5685 / 0.0906\n",
      "[23/25][4/93] Loss_D: 1.2640 Loss_G: 0.7905 D(x): 0.3612 D(G(z)): 0.1837 / 0.4696\n",
      "[23/25][5/93] Loss_D: 1.2304 Loss_G: 2.3233 D(x): 0.8095 D(G(z)): 0.6261 / 0.1083\n",
      "[23/25][6/93] Loss_D: 1.0871 Loss_G: 1.4892 D(x): 0.4638 D(G(z)): 0.2407 / 0.2403\n",
      "[23/25][7/93] Loss_D: 1.0106 Loss_G: 1.5524 D(x): 0.6653 D(G(z)): 0.4403 / 0.2249\n",
      "[23/25][8/93] Loss_D: 0.9019 Loss_G: 1.8519 D(x): 0.6723 D(G(z)): 0.3800 / 0.1666\n",
      "[23/25][9/93] Loss_D: 1.0989 Loss_G: 1.2410 D(x): 0.5303 D(G(z)): 0.3454 / 0.3159\n",
      "[23/25][10/93] Loss_D: 1.2241 Loss_G: 2.5074 D(x): 0.6989 D(G(z)): 0.5585 / 0.0897\n",
      "[23/25][11/93] Loss_D: 0.8181 Loss_G: 1.9531 D(x): 0.6078 D(G(z)): 0.2514 / 0.1536\n",
      "[23/25][12/93] Loss_D: 1.1536 Loss_G: 0.9531 D(x): 0.4796 D(G(z)): 0.2960 / 0.4173\n",
      "[23/25][13/93] Loss_D: 1.2156 Loss_G: 2.8743 D(x): 0.8503 D(G(z)): 0.6380 / 0.0614\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, niter, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu,\n",
    "                    '%s/real_samples.png' % outf,\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
    "                    normalize=True)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

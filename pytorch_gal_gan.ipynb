{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  2788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11764a070>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing parameters:\n",
    "\n",
    "dataroot='gals/'\n",
    "device = torch.device(\"cpu\") # If GPU then use \"cuda:0\"\n",
    "ngpu = 0 #number of GPUs to use \n",
    "nz = 12 #size of the latent z vector\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "workers = 2 #number of data loading workers\n",
    "batchSize = 64 #input batch size\n",
    "imageSize = 64 #the height / width of the input image to network\n",
    "niter = 20 #number of epochs to train for\n",
    "lr = 0.0002 #learning rate, default=0.0002\n",
    "beta1 = 0.5 #beta1 for adam. default=0.5\n",
    "outf='outputs' #folder to output images and model checkpoints\n",
    "\n",
    "\n",
    "manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.MNIST(root=dataroot, download=True,\n",
    "                     transform=transforms.Compose([transforms.Resize(imageSize),transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),]))\n",
    "nc=1\n",
    "\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,\n",
    "                                         shuffle=True, num_workers=int(workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(12, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "netG = Generator(ngpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "#if netG != '':\n",
    "#    netG.load_state_dict(torch.load(netG))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "#if netD != '':\n",
    "#    netD.load_state_dict(torch.load(netD))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/20][0/95] Loss_D: 1.6685 Loss_G: 7.1184 D(x): 0.8715 D(G(z)): 0.7034 / 0.0029\n",
      "[0/20][1/95] Loss_D: 0.5554 Loss_G: 7.2554 D(x): 0.9849 D(G(z)): 0.3597 / 0.0019\n",
      "[0/20][2/95] Loss_D: 0.3255 Loss_G: 7.4734 D(x): 0.9791 D(G(z)): 0.2330 / 0.0011\n",
      "[0/20][3/95] Loss_D: 0.2912 Loss_G: 7.4924 D(x): 0.9588 D(G(z)): 0.1872 / 0.0011\n",
      "[0/20][4/95] Loss_D: 0.6449 Loss_G: 7.2823 D(x): 0.9258 D(G(z)): 0.2160 / 0.0011\n",
      "[0/20][5/95] Loss_D: 0.2449 Loss_G: 8.2914 D(x): 0.9709 D(G(z)): 0.1666 / 0.0005\n",
      "[0/20][6/95] Loss_D: 0.1627 Loss_G: 7.9094 D(x): 0.9795 D(G(z)): 0.0909 / 0.0008\n",
      "[0/20][7/95] Loss_D: 0.0761 Loss_G: 7.7590 D(x): 0.9973 D(G(z)): 0.0682 / 0.0006\n",
      "[0/20][8/95] Loss_D: 0.0837 Loss_G: 7.6327 D(x): 0.9881 D(G(z)): 0.0642 / 0.0008\n",
      "[0/20][9/95] Loss_D: 0.0629 Loss_G: 7.8037 D(x): 0.9996 D(G(z)): 0.0580 / 0.0007\n",
      "[0/20][10/95] Loss_D: 0.0611 Loss_G: 7.8222 D(x): 0.9919 D(G(z)): 0.0495 / 0.0007\n",
      "[0/20][11/95] Loss_D: 0.0636 Loss_G: 7.9800 D(x): 0.9974 D(G(z)): 0.0578 / 0.0006\n",
      "[0/20][12/95] Loss_D: 0.1095 Loss_G: 7.3707 D(x): 0.9630 D(G(z)): 0.0343 / 0.0012\n",
      "[0/20][13/95] Loss_D: 0.4191 Loss_G: 7.1117 D(x): 0.9659 D(G(z)): 0.0558 / 0.0012\n",
      "[0/20][14/95] Loss_D: 0.0749 Loss_G: 8.4625 D(x): 0.9914 D(G(z)): 0.0618 / 0.0003\n",
      "[0/20][15/95] Loss_D: 0.0173 Loss_G: 7.9133 D(x): 0.9986 D(G(z)): 0.0155 / 0.0006\n",
      "[0/20][16/95] Loss_D: 0.0317 Loss_G: 7.2974 D(x): 0.9957 D(G(z)): 0.0265 / 0.0010\n",
      "[0/20][17/95] Loss_D: 0.0624 Loss_G: 8.9496 D(x): 0.9979 D(G(z)): 0.0567 / 0.0002\n",
      "[0/20][18/95] Loss_D: 0.0432 Loss_G: 8.1061 D(x): 0.9811 D(G(z)): 0.0144 / 0.0005\n",
      "[0/20][19/95] Loss_D: 0.0292 Loss_G: 7.2385 D(x): 0.9895 D(G(z)): 0.0166 / 0.0009\n",
      "[0/20][20/95] Loss_D: 0.0663 Loss_G: 9.3618 D(x): 0.9922 D(G(z)): 0.0538 / 0.0001\n",
      "[0/20][21/95] Loss_D: 0.0067 Loss_G: 8.7661 D(x): 0.9996 D(G(z)): 0.0063 / 0.0002\n",
      "[0/20][22/95] Loss_D: 0.0109 Loss_G: 7.4407 D(x): 0.9996 D(G(z)): 0.0105 / 0.0007\n",
      "[0/20][23/95] Loss_D: 0.0705 Loss_G: 10.6514 D(x): 0.9999 D(G(z)): 0.0648 / 0.0000\n",
      "[0/20][24/95] Loss_D: 0.0033 Loss_G: 10.4549 D(x): 0.9984 D(G(z)): 0.0017 / 0.0000\n",
      "[0/20][25/95] Loss_D: 0.0050 Loss_G: 8.5275 D(x): 0.9971 D(G(z)): 0.0020 / 0.0003\n",
      "[0/20][26/95] Loss_D: 0.0211 Loss_G: 7.2400 D(x): 0.9967 D(G(z)): 0.0173 / 0.0009\n",
      "[0/20][27/95] Loss_D: 0.0418 Loss_G: 8.9598 D(x): 0.9924 D(G(z)): 0.0329 / 0.0002\n",
      "[0/20][28/95] Loss_D: 0.0166 Loss_G: 8.7466 D(x): 0.9921 D(G(z)): 0.0082 / 0.0002\n",
      "[0/20][29/95] Loss_D: 0.0085 Loss_G: 7.9049 D(x): 0.9998 D(G(z)): 0.0083 / 0.0005\n",
      "[0/20][30/95] Loss_D: 0.0202 Loss_G: 8.3996 D(x): 0.9993 D(G(z)): 0.0192 / 0.0003\n",
      "[0/20][31/95] Loss_D: 0.0152 Loss_G: 8.3780 D(x): 0.9968 D(G(z)): 0.0116 / 0.0003\n",
      "[0/20][32/95] Loss_D: 0.0152 Loss_G: 8.2451 D(x): 0.9979 D(G(z)): 0.0129 / 0.0004\n",
      "[0/20][33/95] Loss_D: 0.0241 Loss_G: 7.7131 D(x): 0.9887 D(G(z)): 0.0108 / 0.0006\n",
      "[0/20][34/95] Loss_D: 0.0205 Loss_G: 8.6800 D(x): 0.9992 D(G(z)): 0.0193 / 0.0002\n",
      "[0/20][35/95] Loss_D: 0.0092 Loss_G: 8.5361 D(x): 0.9985 D(G(z)): 0.0077 / 0.0002\n",
      "[0/20][36/95] Loss_D: 0.0135 Loss_G: 8.1778 D(x): 0.9964 D(G(z)): 0.0095 / 0.0004\n",
      "[0/20][37/95] Loss_D: 0.0110 Loss_G: 8.0487 D(x): 0.9975 D(G(z)): 0.0084 / 0.0004\n",
      "[0/20][38/95] Loss_D: 0.0151 Loss_G: 8.8070 D(x): 0.9996 D(G(z)): 0.0144 / 0.0002\n",
      "[0/20][39/95] Loss_D: 0.0058 Loss_G: 8.8076 D(x): 0.9996 D(G(z)): 0.0054 / 0.0002\n",
      "[0/20][40/95] Loss_D: 0.0102 Loss_G: 8.3047 D(x): 0.9972 D(G(z)): 0.0072 / 0.0004\n",
      "[0/20][41/95] Loss_D: 0.0089 Loss_G: 8.1642 D(x): 0.9980 D(G(z)): 0.0069 / 0.0004\n",
      "[0/20][42/95] Loss_D: 0.0112 Loss_G: 8.6691 D(x): 0.9993 D(G(z)): 0.0104 / 0.0002\n",
      "[0/20][43/95] Loss_D: 0.0065 Loss_G: 8.5157 D(x): 0.9979 D(G(z)): 0.0043 / 0.0003\n",
      "[0/20][44/95] Loss_D: 0.0165 Loss_G: 7.9397 D(x): 0.9916 D(G(z)): 0.0070 / 0.0005\n",
      "[0/20][45/95] Loss_D: 0.0122 Loss_G: 8.8831 D(x): 0.9990 D(G(z)): 0.0111 / 0.0002\n",
      "[0/20][46/95] Loss_D: 0.0043 Loss_G: 8.8905 D(x): 0.9994 D(G(z)): 0.0036 / 0.0002\n",
      "[0/20][47/95] Loss_D: 0.0052 Loss_G: 8.3772 D(x): 0.9990 D(G(z)): 0.0042 / 0.0004\n",
      "[0/20][48/95] Loss_D: 0.0114 Loss_G: 8.0839 D(x): 0.9947 D(G(z)): 0.0054 / 0.0005\n",
      "[0/20][49/95] Loss_D: 0.0110 Loss_G: 9.0384 D(x): 0.9995 D(G(z)): 0.0105 / 0.0002\n",
      "[0/20][50/95] Loss_D: 0.0038 Loss_G: 8.9092 D(x): 0.9991 D(G(z)): 0.0029 / 0.0002\n",
      "[0/20][51/95] Loss_D: 0.0032 Loss_G: 8.5172 D(x): 0.9998 D(G(z)): 0.0030 / 0.0003\n",
      "[0/20][52/95] Loss_D: 0.0058 Loss_G: 8.2296 D(x): 0.9999 D(G(z)): 0.0057 / 0.0004\n",
      "[0/20][53/95] Loss_D: 0.0096 Loss_G: 9.2816 D(x): 0.9998 D(G(z)): 0.0093 / 0.0001\n",
      "[0/20][54/95] Loss_D: 0.0028 Loss_G: 9.2517 D(x): 0.9993 D(G(z)): 0.0021 / 0.0001\n",
      "[0/20][55/95] Loss_D: 0.0028 Loss_G: 8.4472 D(x): 0.9994 D(G(z)): 0.0022 / 0.0003\n",
      "[0/20][56/95] Loss_D: 0.0083 Loss_G: 7.8134 D(x): 0.9954 D(G(z)): 0.0036 / 0.0006\n",
      "[0/20][57/95] Loss_D: 0.0060 Loss_G: 7.9762 D(x): 0.9984 D(G(z)): 0.0043 / 0.0005\n",
      "[0/20][58/95] Loss_D: 0.6877 Loss_G: 7.5005 D(x): 0.9698 D(G(z)): 0.0038 / 0.0008\n",
      "[0/20][59/95] Loss_D: 0.0133 Loss_G: 9.7383 D(x): 0.9993 D(G(z)): 0.0124 / 0.0001\n",
      "[0/20][60/95] Loss_D: 0.0011 Loss_G: 9.9568 D(x): 0.9999 D(G(z)): 0.0010 / 0.0001\n",
      "[0/20][61/95] Loss_D: 0.0007 Loss_G: 9.2405 D(x): 1.0000 D(G(z)): 0.0007 / 0.0001\n",
      "[0/20][62/95] Loss_D: 0.0026 Loss_G: 7.9738 D(x): 0.9990 D(G(z)): 0.0015 / 0.0005\n",
      "[0/20][63/95] Loss_D: 0.0049 Loss_G: 7.8867 D(x): 0.9999 D(G(z)): 0.0048 / 0.0005\n",
      "[0/20][64/95] Loss_D: 0.0053 Loss_G: 8.5746 D(x): 0.9999 D(G(z)): 0.0052 / 0.0003\n",
      "[0/20][65/95] Loss_D: 0.0031 Loss_G: 8.6873 D(x): 1.0000 D(G(z)): 0.0030 / 0.0002\n",
      "[0/20][66/95] Loss_D: 0.0031 Loss_G: 8.4723 D(x): 0.9998 D(G(z)): 0.0028 / 0.0003\n",
      "[0/20][67/95] Loss_D: 0.0048 Loss_G: 8.4382 D(x): 0.9995 D(G(z)): 0.0043 / 0.0003\n",
      "[0/20][68/95] Loss_D: 0.0043 Loss_G: 8.6486 D(x): 0.9993 D(G(z)): 0.0036 / 0.0003\n",
      "[0/20][69/95] Loss_D: 0.0042 Loss_G: 8.3503 D(x): 0.9985 D(G(z)): 0.0027 / 0.0003\n",
      "[0/20][70/95] Loss_D: 0.0096 Loss_G: 7.7271 D(x): 0.9939 D(G(z)): 0.0027 / 0.0006\n",
      "[0/20][71/95] Loss_D: 0.0054 Loss_G: 8.5556 D(x): 0.9999 D(G(z)): 0.0053 / 0.0003\n",
      "[0/20][72/95] Loss_D: 0.0036 Loss_G: 8.9081 D(x): 0.9998 D(G(z)): 0.0033 / 0.0002\n",
      "[0/20][73/95] Loss_D: 0.0122 Loss_G: 7.5107 D(x): 0.9922 D(G(z)): 0.0041 / 0.0008\n",
      "[0/20][74/95] Loss_D: 0.0199 Loss_G: 14.2011 D(x): 1.0000 D(G(z)): 0.0196 / 0.0000\n",
      "[0/20][75/95] Loss_D: 0.0009 Loss_G: 15.4485 D(x): 0.9991 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][76/95] Loss_D: 0.0086 Loss_G: 13.1542 D(x): 0.9924 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][77/95] Loss_D: 0.0019 Loss_G: 9.5210 D(x): 0.9982 D(G(z)): 0.0001 / 0.0001\n",
      "[0/20][78/95] Loss_D: 0.0067 Loss_G: 9.0746 D(x): 0.9999 D(G(z)): 0.0066 / 0.0002\n",
      "[0/20][79/95] Loss_D: 0.0094 Loss_G: 12.4273 D(x): 0.9999 D(G(z)): 0.0092 / 0.0000\n",
      "[0/20][80/95] Loss_D: 0.0012 Loss_G: 12.1376 D(x): 0.9990 D(G(z)): 0.0002 / 0.0000\n",
      "[0/20][81/95] Loss_D: 0.0158 Loss_G: 5.6667 D(x): 0.9873 D(G(z)): 0.0003 / 0.0099\n",
      "[0/20][82/95] Loss_D: 0.6069 Loss_G: 47.3850 D(x): 1.0000 D(G(z)): 0.4040 / 0.0000\n",
      "[0/20][83/95] Loss_D: 38.2134 Loss_G: 51.6193 D(x): 0.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][84/95] Loss_D: 41.5631 Loss_G: 53.2295 D(x): 0.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][85/95] Loss_D: 42.2110 Loss_G: 53.2607 D(x): 0.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][86/95] Loss_D: 42.7096 Loss_G: 53.6653 D(x): 0.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][87/95] Loss_D: 42.8116 Loss_G: 54.1355 D(x): 0.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][88/95] Loss_D: 43.0575 Loss_G: 53.5286 D(x): 0.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][89/95] Loss_D: 41.2387 Loss_G: 51.9083 D(x): 0.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][90/95] Loss_D: 37.2319 Loss_G: 44.5178 D(x): 0.0000 D(G(z)): 0.0000 / 0.0000\n",
      "[0/20][91/95] Loss_D: 25.2057 Loss_G: 26.6451 D(x): 0.0917 D(G(z)): 0.0003 / 0.0862\n",
      "[0/20][92/95] Loss_D: 12.1362 Loss_G: 18.9358 D(x): 0.4237 D(G(z)): 0.1527 / 0.1833\n",
      "[0/20][93/95] Loss_D: 2.6471 Loss_G: 16.1382 D(x): 0.8593 D(G(z)): 0.3428 / 0.0012\n",
      "[0/20][94/95] Loss_D: 0.6680 Loss_G: 20.5329 D(x): 1.0000 D(G(z)): 0.3042 / 0.0000\n",
      "[1/20][0/95] Loss_D: 0.6174 Loss_G: 12.9153 D(x): 0.9669 D(G(z)): 0.0035 / 0.0000\n",
      "[1/20][1/95] Loss_D: 0.9852 Loss_G: 25.7587 D(x): 0.9056 D(G(z)): 0.2122 / 0.0000\n",
      "[1/20][2/95] Loss_D: 5.0038 Loss_G: 1.2677 D(x): 0.0111 D(G(z)): 0.0000 / 0.4919\n",
      "[1/20][3/95] Loss_D: 4.3600 Loss_G: 15.3031 D(x): 0.9954 D(G(z)): 0.8237 / 0.0001\n",
      "[1/20][4/95] Loss_D: 0.1318 Loss_G: 17.5458 D(x): 0.9769 D(G(z)): 0.0007 / 0.0000\n",
      "[1/20][5/95] Loss_D: 0.0854 Loss_G: 14.2234 D(x): 0.9680 D(G(z)): 0.0019 / 0.0007\n",
      "[1/20][6/95] Loss_D: 0.2568 Loss_G: 7.8947 D(x): 0.9299 D(G(z)): 0.0126 / 0.0105\n",
      "[1/20][7/95] Loss_D: 1.3450 Loss_G: 9.8135 D(x): 0.9172 D(G(z)): 0.5017 / 0.0051\n",
      "[1/20][8/95] Loss_D: 0.8301 Loss_G: 7.3029 D(x): 0.7352 D(G(z)): 0.0255 / 0.0140\n",
      "[1/20][9/95] Loss_D: 0.5584 Loss_G: 5.0960 D(x): 0.9275 D(G(z)): 0.1212 / 0.0236\n",
      "[1/20][10/95] Loss_D: 0.8832 Loss_G: 9.6868 D(x): 0.9397 D(G(z)): 0.3679 / 0.0011\n",
      "[1/20][11/95] Loss_D: 1.1449 Loss_G: 6.0554 D(x): 0.7233 D(G(z)): 0.0102 / 0.0059\n",
      "[1/20][12/95] Loss_D: 0.4848 Loss_G: 7.3716 D(x): 0.9568 D(G(z)): 0.2334 / 0.0032\n",
      "[1/20][13/95] Loss_D: 0.4822 Loss_G: 6.8181 D(x): 0.8784 D(G(z)): 0.1113 / 0.0041\n",
      "[1/20][14/95] Loss_D: 0.4365 Loss_G: 7.5362 D(x): 0.9012 D(G(z)): 0.1606 / 0.0034\n",
      "[1/20][15/95] Loss_D: 0.4713 Loss_G: 3.9973 D(x): 0.8022 D(G(z)): 0.0958 / 0.0398\n",
      "[1/20][16/95] Loss_D: 2.0459 Loss_G: 18.3948 D(x): 0.9205 D(G(z)): 0.7827 / 0.0000\n",
      "[1/20][17/95] Loss_D: 11.5542 Loss_G: 6.5472 D(x): 0.0001 D(G(z)): 0.0000 / 0.0024\n",
      "[1/20][18/95] Loss_D: 0.7304 Loss_G: 1.0247 D(x): 0.8891 D(G(z)): 0.1263 / 0.4202\n",
      "[1/20][19/95] Loss_D: 3.1505 Loss_G: 8.5580 D(x): 0.9648 D(G(z)): 0.8618 / 0.0176\n",
      "[1/20][20/95] Loss_D: 1.5597 Loss_G: 7.2042 D(x): 0.4804 D(G(z)): 0.0290 / 0.0224\n",
      "[1/20][21/95] Loss_D: 0.4698 Loss_G: 4.6535 D(x): 0.8327 D(G(z)): 0.0690 / 0.0611\n",
      "[1/20][22/95] Loss_D: 0.5755 Loss_G: 3.1532 D(x): 0.8760 D(G(z)): 0.2680 / 0.0777\n",
      "[1/20][23/95] Loss_D: 0.9646 Loss_G: 6.5132 D(x): 0.9197 D(G(z)): 0.5023 / 0.0104\n",
      "[1/20][24/95] Loss_D: 1.0617 Loss_G: 3.5918 D(x): 0.5019 D(G(z)): 0.0392 / 0.0621\n",
      "[1/20][25/95] Loss_D: 0.8844 Loss_G: 5.3396 D(x): 0.8731 D(G(z)): 0.4375 / 0.0149\n",
      "[1/20][26/95] Loss_D: 0.5599 Loss_G: 3.9809 D(x): 0.7597 D(G(z)): 0.0882 / 0.0319\n",
      "[1/20][27/95] Loss_D: 0.7124 Loss_G: 7.4657 D(x): 0.8890 D(G(z)): 0.3886 / 0.0045\n",
      "[1/20][28/95] Loss_D: 1.1154 Loss_G: 2.3449 D(x): 0.5464 D(G(z)): 0.0366 / 0.1365\n",
      "[1/20][29/95] Loss_D: 2.3606 Loss_G: 10.8410 D(x): 0.9422 D(G(z)): 0.8508 / 0.0006\n",
      "[1/20][30/95] Loss_D: 3.4120 Loss_G: 2.7222 D(x): 0.0778 D(G(z)): 0.0071 / 0.1212\n",
      "[1/20][31/95] Loss_D: 2.0850 Loss_G: 7.2288 D(x): 0.9251 D(G(z)): 0.7961 / 0.0049\n",
      "[1/20][32/95] Loss_D: 1.0490 Loss_G: 4.7917 D(x): 0.5055 D(G(z)): 0.0474 / 0.0446\n",
      "[1/20][33/95] Loss_D: 0.7888 Loss_G: 3.2482 D(x): 0.7858 D(G(z)): 0.2644 / 0.0707\n",
      "[1/20][34/95] Loss_D: 0.6559 Loss_G: 6.2521 D(x): 0.9063 D(G(z)): 0.3824 / 0.0060\n",
      "[1/20][35/95] Loss_D: 0.8402 Loss_G: 3.7514 D(x): 0.5627 D(G(z)): 0.0249 / 0.0457\n",
      "[1/20][36/95] Loss_D: 0.6465 Loss_G: 5.4423 D(x): 0.8964 D(G(z)): 0.3474 / 0.0139\n",
      "[1/20][37/95] Loss_D: 0.4205 Loss_G: 4.3977 D(x): 0.7749 D(G(z)): 0.0880 / 0.0346\n",
      "[1/20][38/95] Loss_D: 0.6184 Loss_G: 5.1915 D(x): 0.8269 D(G(z)): 0.2658 / 0.0196\n",
      "[1/20][39/95] Loss_D: 0.9950 Loss_G: 1.1784 D(x): 0.5638 D(G(z)): 0.1896 / 0.3726\n",
      "[1/20][40/95] Loss_D: 3.2454 Loss_G: 12.5404 D(x): 0.9849 D(G(z)): 0.9172 / 0.0001\n",
      "[1/20][41/95] Loss_D: 6.8879 Loss_G: 7.4008 D(x): 0.0207 D(G(z)): 0.0006 / 0.0036\n",
      "[1/20][42/95] Loss_D: 1.5481 Loss_G: 0.1021 D(x): 0.3039 D(G(z)): 0.0381 / 0.9087\n",
      "[1/20][43/95] Loss_D: 4.7182 Loss_G: 4.2666 D(x): 0.9906 D(G(z)): 0.9726 / 0.0215\n",
      "[1/20][44/95] Loss_D: 0.3597 Loss_G: 6.6262 D(x): 0.8215 D(G(z)): 0.1152 / 0.0054\n",
      "[1/20][45/95] Loss_D: 0.6350 Loss_G: 4.3479 D(x): 0.7368 D(G(z)): 0.0528 / 0.0358\n",
      "[1/20][46/95] Loss_D: 0.5025 Loss_G: 3.2196 D(x): 0.8174 D(G(z)): 0.1763 / 0.0726\n",
      "[1/20][47/95] Loss_D: 1.6587 Loss_G: 1.2838 D(x): 0.3905 D(G(z)): 0.3446 / 0.3180\n",
      "[1/20][48/95] Loss_D: 1.1785 Loss_G: 6.9467 D(x): 0.8470 D(G(z)): 0.5998 / 0.0049\n",
      "[1/20][49/95] Loss_D: 1.7305 Loss_G: 1.2500 D(x): 0.2456 D(G(z)): 0.0141 / 0.3314\n",
      "[1/20][50/95] Loss_D: 2.0399 Loss_G: 6.6698 D(x): 0.9571 D(G(z)): 0.8136 / 0.0033\n",
      "[1/20][51/95] Loss_D: 1.5272 Loss_G: 2.3837 D(x): 0.3093 D(G(z)): 0.0250 / 0.1293\n",
      "[1/20][52/95] Loss_D: 0.8187 Loss_G: 3.2080 D(x): 0.8699 D(G(z)): 0.4370 / 0.0630\n",
      "[1/20][53/95] Loss_D: 0.6876 Loss_G: 3.7380 D(x): 0.7440 D(G(z)): 0.2691 / 0.0486\n",
      "[1/20][54/95] Loss_D: 1.4876 Loss_G: 0.4064 D(x): 0.4158 D(G(z)): 0.1507 / 0.6784\n",
      "[1/20][55/95] Loss_D: 2.2389 Loss_G: 7.3790 D(x): 0.9821 D(G(z)): 0.8685 / 0.0040\n",
      "[1/20][56/95] Loss_D: 1.7562 Loss_G: 4.6156 D(x): 0.3171 D(G(z)): 0.0091 / 0.0235\n",
      "[1/20][57/95] Loss_D: 0.7288 Loss_G: 0.7842 D(x): 0.6182 D(G(z)): 0.0943 / 0.5107\n",
      "[1/20][58/95] Loss_D: 1.8224 Loss_G: 4.6540 D(x): 0.9605 D(G(z)): 0.7685 / 0.0283\n",
      "[1/20][59/95] Loss_D: 0.1961 Loss_G: 5.9854 D(x): 0.9004 D(G(z)): 0.0782 / 0.0082\n",
      "[1/20][60/95] Loss_D: 2.9566 Loss_G: 0.7019 D(x): 0.1489 D(G(z)): 0.0275 / 0.5450\n",
      "[1/20][61/95] Loss_D: 1.5542 Loss_G: 3.1054 D(x): 0.9570 D(G(z)): 0.7121 / 0.0880\n",
      "[1/20][62/95] Loss_D: 1.1227 Loss_G: 2.4082 D(x): 0.5389 D(G(z)): 0.1745 / 0.1358\n",
      "[1/20][63/95] Loss_D: 0.5463 Loss_G: 2.9125 D(x): 0.8482 D(G(z)): 0.2786 / 0.0980\n",
      "[1/20][64/95] Loss_D: 0.8129 Loss_G: 1.9711 D(x): 0.6699 D(G(z)): 0.2502 / 0.1959\n",
      "[1/20][65/95] Loss_D: 0.8532 Loss_G: 3.3465 D(x): 0.8092 D(G(z)): 0.4386 / 0.0531\n",
      "[1/20][66/95] Loss_D: 1.2661 Loss_G: 0.6674 D(x): 0.4157 D(G(z)): 0.1879 / 0.5356\n",
      "[1/20][67/95] Loss_D: 1.3284 Loss_G: 4.4301 D(x): 0.8736 D(G(z)): 0.6707 / 0.0223\n",
      "[1/20][68/95] Loss_D: 1.7394 Loss_G: 0.7134 D(x): 0.2653 D(G(z)): 0.0577 / 0.5235\n",
      "[1/20][69/95] Loss_D: 1.4066 Loss_G: 3.7970 D(x): 0.9265 D(G(z)): 0.6813 / 0.0467\n",
      "[1/20][70/95] Loss_D: 0.5807 Loss_G: 3.2345 D(x): 0.6689 D(G(z)): 0.1170 / 0.0567\n",
      "[1/20][71/95] Loss_D: 1.0739 Loss_G: 0.5665 D(x): 0.4685 D(G(z)): 0.1456 / 0.5943\n",
      "[1/20][72/95] Loss_D: 1.7454 Loss_G: 3.4206 D(x): 0.9571 D(G(z)): 0.7908 / 0.0756\n",
      "[1/20][73/95] Loss_D: 0.7868 Loss_G: 2.9277 D(x): 0.6201 D(G(z)): 0.1885 / 0.0871\n",
      "[1/20][74/95] Loss_D: 0.3988 Loss_G: 2.7219 D(x): 0.8113 D(G(z)): 0.1529 / 0.1089\n",
      "[1/20][75/95] Loss_D: 1.8678 Loss_G: 0.2802 D(x): 0.2990 D(G(z)): 0.2558 / 0.7735\n",
      "[1/20][76/95] Loss_D: 2.6610 Loss_G: 2.0194 D(x): 0.8835 D(G(z)): 0.8772 / 0.1912\n",
      "[1/20][77/95] Loss_D: 1.5859 Loss_G: 1.4649 D(x): 0.3626 D(G(z)): 0.2387 / 0.2972\n",
      "[1/20][78/95] Loss_D: 1.0648 Loss_G: 1.9972 D(x): 0.7402 D(G(z)): 0.4517 / 0.1840\n",
      "[1/20][79/95] Loss_D: 1.2391 Loss_G: 1.3223 D(x): 0.4859 D(G(z)): 0.2864 / 0.3216\n",
      "[1/20][80/95] Loss_D: 1.1861 Loss_G: 2.4011 D(x): 0.7584 D(G(z)): 0.4954 / 0.1269\n",
      "[1/20][81/95] Loss_D: 0.9928 Loss_G: 1.8188 D(x): 0.5677 D(G(z)): 0.2575 / 0.2033\n",
      "[1/20][82/95] Loss_D: 1.2640 Loss_G: 1.1451 D(x): 0.5338 D(G(z)): 0.3768 / 0.3518\n",
      "[1/20][83/95] Loss_D: 1.2804 Loss_G: 3.9592 D(x): 0.7735 D(G(z)): 0.5862 / 0.0247\n",
      "[1/20][84/95] Loss_D: 2.1363 Loss_G: 0.3886 D(x): 0.2345 D(G(z)): 0.0622 / 0.6956\n",
      "[1/20][85/95] Loss_D: 2.0265 Loss_G: 3.3634 D(x): 0.9232 D(G(z)): 0.8005 / 0.0507\n",
      "[1/20][86/95] Loss_D: 1.4489 Loss_G: 1.5801 D(x): 0.3699 D(G(z)): 0.1172 / 0.2550\n",
      "[1/20][87/95] Loss_D: 1.1991 Loss_G: 1.4343 D(x): 0.6726 D(G(z)): 0.4611 / 0.2946\n",
      "[1/20][88/95] Loss_D: 1.0265 Loss_G: 1.8243 D(x): 0.6850 D(G(z)): 0.4150 / 0.2050\n",
      "[1/20][89/95] Loss_D: 0.8430 Loss_G: 1.7447 D(x): 0.6850 D(G(z)): 0.3084 / 0.2132\n",
      "[1/20][90/95] Loss_D: 0.8317 Loss_G: 2.1112 D(x): 0.7544 D(G(z)): 0.3555 / 0.1653\n",
      "[1/20][91/95] Loss_D: 1.0826 Loss_G: 1.4790 D(x): 0.5622 D(G(z)): 0.3085 / 0.3080\n",
      "[1/20][92/95] Loss_D: 1.4663 Loss_G: 2.2305 D(x): 0.6339 D(G(z)): 0.5378 / 0.1450\n",
      "[1/20][93/95] Loss_D: 1.5315 Loss_G: 0.9155 D(x): 0.3901 D(G(z)): 0.3108 / 0.4408\n",
      "[1/20][94/95] Loss_D: 1.8373 Loss_G: 3.8542 D(x): 0.7138 D(G(z)): 0.7256 / 0.0359\n",
      "[2/20][0/95] Loss_D: 1.9973 Loss_G: 0.6396 D(x): 0.2254 D(G(z)): 0.1388 / 0.5614\n",
      "[2/20][1/95] Loss_D: 1.6723 Loss_G: 2.4846 D(x): 0.7904 D(G(z)): 0.6999 / 0.1046\n",
      "[2/20][2/95] Loss_D: 1.3350 Loss_G: 1.7561 D(x): 0.4379 D(G(z)): 0.2322 / 0.2014\n",
      "[2/20][3/95] Loss_D: 1.3094 Loss_G: 1.5341 D(x): 0.5427 D(G(z)): 0.4019 / 0.2358\n",
      "[2/20][4/95] Loss_D: 1.2359 Loss_G: 2.7518 D(x): 0.6164 D(G(z)): 0.4671 / 0.0969\n",
      "[2/20][5/95] Loss_D: 1.7685 Loss_G: 0.3002 D(x): 0.3005 D(G(z)): 0.2190 / 0.7586\n",
      "[2/20][6/95] Loss_D: 2.2299 Loss_G: 3.5917 D(x): 0.8461 D(G(z)): 0.8196 / 0.0469\n",
      "[2/20][7/95] Loss_D: 2.1228 Loss_G: 0.8200 D(x): 0.2147 D(G(z)): 0.0704 / 0.4960\n",
      "[2/20][8/95] Loss_D: 1.7633 Loss_G: 1.8353 D(x): 0.6991 D(G(z)): 0.6582 / 0.2105\n",
      "[2/20][9/95] Loss_D: 1.0176 Loss_G: 1.6469 D(x): 0.5560 D(G(z)): 0.2610 / 0.2476\n",
      "[2/20][10/95] Loss_D: 1.2007 Loss_G: 1.2245 D(x): 0.6076 D(G(z)): 0.4274 / 0.3346\n",
      "[2/20][11/95] Loss_D: 1.2189 Loss_G: 1.8518 D(x): 0.6305 D(G(z)): 0.4569 / 0.2030\n",
      "[2/20][12/95] Loss_D: 1.1587 Loss_G: 1.0889 D(x): 0.5307 D(G(z)): 0.3291 / 0.3796\n",
      "[2/20][13/95] Loss_D: 1.2360 Loss_G: 2.0995 D(x): 0.6779 D(G(z)): 0.5161 / 0.1616\n",
      "[2/20][14/95] Loss_D: 1.4701 Loss_G: 0.4772 D(x): 0.3730 D(G(z)): 0.2710 / 0.6440\n",
      "[2/20][15/95] Loss_D: 1.5952 Loss_G: 3.1741 D(x): 0.8192 D(G(z)): 0.6958 / 0.0704\n",
      "[2/20][16/95] Loss_D: 1.8376 Loss_G: 0.5048 D(x): 0.2706 D(G(z)): 0.1502 / 0.6224\n",
      "[2/20][17/95] Loss_D: 1.5454 Loss_G: 1.9615 D(x): 0.7991 D(G(z)): 0.6936 / 0.1799\n",
      "[2/20][18/95] Loss_D: 1.2802 Loss_G: 1.2100 D(x): 0.4122 D(G(z)): 0.2526 / 0.3254\n",
      "[2/20][19/95] Loss_D: 0.9131 Loss_G: 1.5864 D(x): 0.7396 D(G(z)): 0.4282 / 0.2306\n",
      "[2/20][20/95] Loss_D: 1.0465 Loss_G: 1.5627 D(x): 0.6193 D(G(z)): 0.3784 / 0.2339\n",
      "[2/20][21/95] Loss_D: 1.0388 Loss_G: 1.1263 D(x): 0.5681 D(G(z)): 0.3339 / 0.3427\n",
      "[2/20][22/95] Loss_D: 0.9271 Loss_G: 1.6523 D(x): 0.6686 D(G(z)): 0.3768 / 0.2156\n",
      "[2/20][23/95] Loss_D: 0.9853 Loss_G: 2.6741 D(x): 0.6934 D(G(z)): 0.4189 / 0.0906\n",
      "[2/20][24/95] Loss_D: 1.3949 Loss_G: 0.2639 D(x): 0.3319 D(G(z)): 0.1591 / 0.7812\n",
      "[2/20][25/95] Loss_D: 2.0634 Loss_G: 3.2322 D(x): 0.9497 D(G(z)): 0.8236 / 0.0702\n",
      "[2/20][26/95] Loss_D: 2.4178 Loss_G: 0.5440 D(x): 0.1523 D(G(z)): 0.1036 / 0.6122\n",
      "[2/20][27/95] Loss_D: 1.6158 Loss_G: 1.5367 D(x): 0.7676 D(G(z)): 0.6980 / 0.2465\n",
      "[2/20][28/95] Loss_D: 1.5313 Loss_G: 0.8111 D(x): 0.3733 D(G(z)): 0.3274 / 0.4791\n",
      "[2/20][29/95] Loss_D: 1.1396 Loss_G: 1.4050 D(x): 0.7037 D(G(z)): 0.5157 / 0.2757\n",
      "[2/20][30/95] Loss_D: 1.1844 Loss_G: 0.8186 D(x): 0.4772 D(G(z)): 0.3037 / 0.4557\n",
      "[2/20][31/95] Loss_D: 1.4356 Loss_G: 1.5225 D(x): 0.6772 D(G(z)): 0.6239 / 0.2453\n",
      "[2/20][32/95] Loss_D: 1.5719 Loss_G: 0.5116 D(x): 0.3191 D(G(z)): 0.2944 / 0.6142\n",
      "[2/20][33/95] Loss_D: 1.4148 Loss_G: 1.8964 D(x): 0.7683 D(G(z)): 0.6604 / 0.2122\n",
      "[2/20][34/95] Loss_D: 1.3390 Loss_G: 0.6376 D(x): 0.4037 D(G(z)): 0.2596 / 0.5506\n",
      "[2/20][35/95] Loss_D: 1.2965 Loss_G: 1.6458 D(x): 0.7379 D(G(z)): 0.5940 / 0.2196\n",
      "[2/20][36/95] Loss_D: 1.1124 Loss_G: 1.0290 D(x): 0.5037 D(G(z)): 0.2943 / 0.3796\n",
      "[2/20][37/95] Loss_D: 1.0288 Loss_G: 1.4201 D(x): 0.6829 D(G(z)): 0.4504 / 0.2658\n",
      "[2/20][38/95] Loss_D: 0.9902 Loss_G: 1.0818 D(x): 0.5802 D(G(z)): 0.3332 / 0.3614\n",
      "[2/20][39/95] Loss_D: 0.8150 Loss_G: 1.5304 D(x): 0.7462 D(G(z)): 0.3917 / 0.2311\n",
      "[2/20][40/95] Loss_D: 1.0221 Loss_G: 1.1169 D(x): 0.5756 D(G(z)): 0.3446 / 0.3417\n",
      "[2/20][41/95] Loss_D: 1.0595 Loss_G: 1.4758 D(x): 0.6271 D(G(z)): 0.4182 / 0.2566\n",
      "[2/20][42/95] Loss_D: 1.0101 Loss_G: 0.7915 D(x): 0.5723 D(G(z)): 0.3222 / 0.4731\n",
      "[2/20][43/95] Loss_D: 1.2146 Loss_G: 3.6670 D(x): 0.8169 D(G(z)): 0.6048 / 0.0461\n",
      "[2/20][44/95] Loss_D: 2.3304 Loss_G: 0.3930 D(x): 0.1586 D(G(z)): 0.0768 / 0.6925\n",
      "[2/20][45/95] Loss_D: 1.7141 Loss_G: 1.6764 D(x): 0.8782 D(G(z)): 0.7477 / 0.2119\n",
      "[2/20][46/95] Loss_D: 1.2808 Loss_G: 0.8801 D(x): 0.4279 D(G(z)): 0.2897 / 0.4253\n",
      "[2/20][47/95] Loss_D: 1.1441 Loss_G: 1.3831 D(x): 0.6651 D(G(z)): 0.4866 / 0.2623\n",
      "[2/20][48/95] Loss_D: 0.9871 Loss_G: 1.1202 D(x): 0.5507 D(G(z)): 0.3026 / 0.3410\n",
      "[2/20][49/95] Loss_D: 1.0065 Loss_G: 1.4781 D(x): 0.6754 D(G(z)): 0.4404 / 0.2487\n",
      "[2/20][50/95] Loss_D: 1.3838 Loss_G: 0.5289 D(x): 0.4095 D(G(z)): 0.3430 / 0.6036\n",
      "[2/20][51/95] Loss_D: 1.4529 Loss_G: 2.2094 D(x): 0.7646 D(G(z)): 0.6629 / 0.1697\n",
      "[2/20][52/95] Loss_D: 1.5765 Loss_G: 0.5465 D(x): 0.3038 D(G(z)): 0.2027 / 0.6013\n",
      "[2/20][53/95] Loss_D: 1.4297 Loss_G: 2.0059 D(x): 0.7858 D(G(z)): 0.6653 / 0.1651\n",
      "[2/20][54/95] Loss_D: 1.2608 Loss_G: 0.6200 D(x): 0.3788 D(G(z)): 0.2135 / 0.5630\n",
      "[2/20][55/95] Loss_D: 1.2260 Loss_G: 2.2141 D(x): 0.8176 D(G(z)): 0.5987 / 0.1430\n",
      "[2/20][56/95] Loss_D: 1.4438 Loss_G: 0.5590 D(x): 0.3542 D(G(z)): 0.2125 / 0.5942\n",
      "[2/20][57/95] Loss_D: 1.3217 Loss_G: 2.4533 D(x): 0.8404 D(G(z)): 0.6562 / 0.1045\n",
      "[2/20][58/95] Loss_D: 1.2854 Loss_G: 0.7505 D(x): 0.3823 D(G(z)): 0.1690 / 0.5037\n",
      "[2/20][59/95] Loss_D: 1.2013 Loss_G: 1.7918 D(x): 0.7481 D(G(z)): 0.5726 / 0.1872\n",
      "[2/20][60/95] Loss_D: 1.1085 Loss_G: 0.7101 D(x): 0.4758 D(G(z)): 0.2622 / 0.5112\n",
      "[2/20][61/95] Loss_D: 1.6030 Loss_G: 2.4470 D(x): 0.6968 D(G(z)): 0.6877 / 0.1037\n",
      "[2/20][62/95] Loss_D: 1.6863 Loss_G: 0.3938 D(x): 0.2409 D(G(z)): 0.1404 / 0.6867\n",
      "[2/20][63/95] Loss_D: 1.7901 Loss_G: 1.9649 D(x): 0.8216 D(G(z)): 0.7724 / 0.1555\n",
      "[2/20][64/95] Loss_D: 1.2192 Loss_G: 1.0009 D(x): 0.3901 D(G(z)): 0.2053 / 0.3762\n",
      "[2/20][65/95] Loss_D: 1.1281 Loss_G: 1.2178 D(x): 0.6283 D(G(z)): 0.4591 / 0.3035\n",
      "[2/20][66/95] Loss_D: 1.0277 Loss_G: 1.4116 D(x): 0.6086 D(G(z)): 0.3957 / 0.2602\n",
      "[2/20][67/95] Loss_D: 0.6900 Loss_G: 2.2048 D(x): 0.7902 D(G(z)): 0.3529 / 0.1295\n",
      "[2/20][68/95] Loss_D: 1.3918 Loss_G: 0.4497 D(x): 0.3175 D(G(z)): 0.1740 / 0.6474\n",
      "[2/20][69/95] Loss_D: 1.6977 Loss_G: 2.0337 D(x): 0.7837 D(G(z)): 0.7405 / 0.1718\n",
      "[2/20][70/95] Loss_D: 1.4926 Loss_G: 0.6355 D(x): 0.3352 D(G(z)): 0.2159 / 0.5379\n",
      "[2/20][71/95] Loss_D: 1.2204 Loss_G: 1.6226 D(x): 0.8011 D(G(z)): 0.6178 / 0.2074\n",
      "[2/20][72/95] Loss_D: 1.3879 Loss_G: 0.7276 D(x): 0.3684 D(G(z)): 0.2861 / 0.4998\n",
      "[2/20][73/95] Loss_D: 1.1855 Loss_G: 1.8121 D(x): 0.7065 D(G(z)): 0.5430 / 0.2107\n",
      "[2/20][74/95] Loss_D: 1.1084 Loss_G: 1.2094 D(x): 0.5430 D(G(z)): 0.3224 / 0.3171\n",
      "[2/20][75/95] Loss_D: 1.1672 Loss_G: 1.0679 D(x): 0.5639 D(G(z)): 0.4191 / 0.3679\n",
      "[2/20][76/95] Loss_D: 0.7329 Loss_G: 2.5155 D(x): 0.7911 D(G(z)): 0.3710 / 0.1006\n",
      "[2/20][77/95] Loss_D: 1.8053 Loss_G: 0.2520 D(x): 0.2510 D(G(z)): 0.1924 / 0.7853\n",
      "[2/20][78/95] Loss_D: 2.0499 Loss_G: 2.7386 D(x): 0.8643 D(G(z)): 0.8238 / 0.0866\n",
      "[2/20][79/95] Loss_D: 1.6252 Loss_G: 0.8148 D(x): 0.2667 D(G(z)): 0.1311 / 0.4811\n",
      "[2/20][80/95] Loss_D: 1.2580 Loss_G: 1.2856 D(x): 0.7343 D(G(z)): 0.5709 / 0.2900\n",
      "[2/20][81/95] Loss_D: 1.1033 Loss_G: 1.2139 D(x): 0.5470 D(G(z)): 0.3666 / 0.3100\n",
      "[2/20][82/95] Loss_D: 1.0140 Loss_G: 1.2514 D(x): 0.6151 D(G(z)): 0.3895 / 0.3015\n",
      "[2/20][83/95] Loss_D: 1.0970 Loss_G: 1.1456 D(x): 0.5725 D(G(z)): 0.3949 / 0.3313\n",
      "[2/20][84/95] Loss_D: 1.1668 Loss_G: 1.8549 D(x): 0.6397 D(G(z)): 0.4931 / 0.1680\n",
      "[2/20][85/95] Loss_D: 1.3196 Loss_G: 0.7439 D(x): 0.4049 D(G(z)): 0.2830 / 0.5062\n",
      "[2/20][86/95] Loss_D: 1.3586 Loss_G: 1.9936 D(x): 0.7020 D(G(z)): 0.5799 / 0.1662\n",
      "[2/20][87/95] Loss_D: 1.3965 Loss_G: 0.6179 D(x): 0.3533 D(G(z)): 0.2284 / 0.5613\n",
      "[2/20][88/95] Loss_D: 1.5152 Loss_G: 1.9511 D(x): 0.7943 D(G(z)): 0.6864 / 0.1815\n",
      "[2/20][89/95] Loss_D: 1.2376 Loss_G: 1.1568 D(x): 0.4205 D(G(z)): 0.2573 / 0.3513\n",
      "[2/20][90/95] Loss_D: 1.2183 Loss_G: 1.3745 D(x): 0.6466 D(G(z)): 0.4869 / 0.2882\n",
      "[2/20][91/95] Loss_D: 1.0883 Loss_G: 1.1091 D(x): 0.5275 D(G(z)): 0.3218 / 0.3652\n",
      "[2/20][92/95] Loss_D: 1.1897 Loss_G: 1.5186 D(x): 0.6767 D(G(z)): 0.4981 / 0.2618\n",
      "[2/20][93/95] Loss_D: 1.2363 Loss_G: 1.0030 D(x): 0.5164 D(G(z)): 0.3687 / 0.3935\n",
      "[2/20][94/95] Loss_D: 1.6972 Loss_G: 4.5614 D(x): 0.5689 D(G(z)): 0.6152 / 0.0168\n",
      "[3/20][0/95] Loss_D: 1.9284 Loss_G: 0.5413 D(x): 0.2426 D(G(z)): 0.1543 / 0.6102\n",
      "[3/20][1/95] Loss_D: 1.5889 Loss_G: 1.0961 D(x): 0.7061 D(G(z)): 0.6788 / 0.3521\n",
      "[3/20][2/95] Loss_D: 1.2557 Loss_G: 1.6220 D(x): 0.5736 D(G(z)): 0.4697 / 0.2147\n",
      "[3/20][3/95] Loss_D: 1.0629 Loss_G: 1.0326 D(x): 0.5172 D(G(z)): 0.2887 / 0.3748\n",
      "[3/20][4/95] Loss_D: 1.1696 Loss_G: 1.8581 D(x): 0.7063 D(G(z)): 0.5225 / 0.1883\n",
      "[3/20][5/95] Loss_D: 1.5633 Loss_G: 0.5912 D(x): 0.3349 D(G(z)): 0.2813 / 0.5698\n",
      "[3/20][6/95] Loss_D: 1.4437 Loss_G: 2.4606 D(x): 0.7514 D(G(z)): 0.6513 / 0.1355\n",
      "[3/20][7/95] Loss_D: 1.6497 Loss_G: 0.6906 D(x): 0.3329 D(G(z)): 0.2843 / 0.5687\n",
      "[3/20][8/95] Loss_D: 1.3556 Loss_G: 1.6000 D(x): 0.7483 D(G(z)): 0.5942 / 0.2314\n",
      "[3/20][9/95] Loss_D: 0.9735 Loss_G: 1.4589 D(x): 0.5958 D(G(z)): 0.3272 / 0.2506\n",
      "[3/20][10/95] Loss_D: 0.9056 Loss_G: 1.4402 D(x): 0.6109 D(G(z)): 0.3059 / 0.2676\n",
      "[3/20][11/95] Loss_D: 1.0687 Loss_G: 1.5690 D(x): 0.6533 D(G(z)): 0.4238 / 0.2270\n",
      "[3/20][12/95] Loss_D: 1.1862 Loss_G: 1.0175 D(x): 0.5325 D(G(z)): 0.3780 / 0.3867\n",
      "[3/20][13/95] Loss_D: 1.2939 Loss_G: 1.2888 D(x): 0.6069 D(G(z)): 0.5085 / 0.3036\n",
      "[3/20][14/95] Loss_D: 1.1558 Loss_G: 1.0480 D(x): 0.5552 D(G(z)): 0.3976 / 0.3807\n",
      "[3/20][15/95] Loss_D: 1.0566 Loss_G: 2.2995 D(x): 0.7191 D(G(z)): 0.4915 / 0.1248\n",
      "[3/20][16/95] Loss_D: 1.3696 Loss_G: 0.4416 D(x): 0.3544 D(G(z)): 0.1954 / 0.6683\n",
      "[3/20][17/95] Loss_D: 1.4545 Loss_G: 2.4703 D(x): 0.8753 D(G(z)): 0.6755 / 0.1222\n",
      "[3/20][18/95] Loss_D: 1.3121 Loss_G: 0.8663 D(x): 0.4144 D(G(z)): 0.1864 / 0.4456\n",
      "[3/20][19/95] Loss_D: 1.0398 Loss_G: 1.7587 D(x): 0.8138 D(G(z)): 0.5258 / 0.2101\n",
      "[3/20][20/95] Loss_D: 1.0939 Loss_G: 2.2402 D(x): 0.7075 D(G(z)): 0.4528 / 0.1382\n",
      "[3/20][21/95] Loss_D: 1.2877 Loss_G: 0.7777 D(x): 0.4516 D(G(z)): 0.2394 / 0.4906\n",
      "[3/20][22/95] Loss_D: 2.0565 Loss_G: 2.8318 D(x): 0.6477 D(G(z)): 0.7298 / 0.0913\n",
      "[3/20][23/95] Loss_D: 2.0903 Loss_G: 0.3413 D(x): 0.2027 D(G(z)): 0.2052 / 0.7159\n",
      "[3/20][24/95] Loss_D: 1.4588 Loss_G: 2.1304 D(x): 0.8515 D(G(z)): 0.7075 / 0.1532\n",
      "[3/20][25/95] Loss_D: 1.4108 Loss_G: 0.8006 D(x): 0.3314 D(G(z)): 0.2150 / 0.4596\n",
      "[3/20][26/95] Loss_D: 1.2536 Loss_G: 1.6965 D(x): 0.6424 D(G(z)): 0.5369 / 0.2088\n",
      "[3/20][27/95] Loss_D: 0.9089 Loss_G: 2.5277 D(x): 0.7071 D(G(z)): 0.4157 / 0.1214\n",
      "[3/20][28/95] Loss_D: 1.3454 Loss_G: 0.5791 D(x): 0.3585 D(G(z)): 0.1693 / 0.5699\n",
      "[3/20][29/95] Loss_D: 1.3980 Loss_G: 3.2248 D(x): 0.8727 D(G(z)): 0.6990 / 0.0773\n",
      "[3/20][30/95] Loss_D: 0.6119 Loss_G: 3.0694 D(x): 0.6851 D(G(z)): 0.1703 / 0.1037\n",
      "[3/20][31/95] Loss_D: 2.3328 Loss_G: 0.2513 D(x): 0.2073 D(G(z)): 0.1849 / 0.7872\n",
      "[3/20][32/95] Loss_D: 2.1846 Loss_G: 1.0618 D(x): 0.8198 D(G(z)): 0.8312 / 0.3703\n",
      "[3/20][33/95] Loss_D: 1.6054 Loss_G: 1.2359 D(x): 0.4131 D(G(z)): 0.4655 / 0.3097\n",
      "[3/20][34/95] Loss_D: 1.2746 Loss_G: 0.6959 D(x): 0.4458 D(G(z)): 0.3213 / 0.5162\n",
      "[3/20][35/95] Loss_D: 1.2528 Loss_G: 1.4523 D(x): 0.7418 D(G(z)): 0.5849 / 0.2569\n",
      "[3/20][36/95] Loss_D: 1.0585 Loss_G: 1.0770 D(x): 0.5117 D(G(z)): 0.2943 / 0.3776\n",
      "[3/20][37/95] Loss_D: 0.9206 Loss_G: 1.5668 D(x): 0.7142 D(G(z)): 0.4081 / 0.2424\n",
      "[3/20][38/95] Loss_D: 0.8754 Loss_G: 1.5972 D(x): 0.6692 D(G(z)): 0.3347 / 0.2313\n",
      "[3/20][39/95] Loss_D: 1.2174 Loss_G: 0.9918 D(x): 0.5222 D(G(z)): 0.3836 / 0.3937\n",
      "[3/20][40/95] Loss_D: 1.1924 Loss_G: 2.5459 D(x): 0.7111 D(G(z)): 0.5345 / 0.0936\n",
      "[3/20][41/95] Loss_D: 1.9429 Loss_G: 0.3861 D(x): 0.2196 D(G(z)): 0.2182 / 0.7036\n",
      "[3/20][42/95] Loss_D: 1.6752 Loss_G: 2.0790 D(x): 0.8564 D(G(z)): 0.7213 / 0.1429\n",
      "[3/20][43/95] Loss_D: 1.1452 Loss_G: 1.1843 D(x): 0.4177 D(G(z)): 0.1944 / 0.3229\n",
      "[3/20][44/95] Loss_D: 1.0002 Loss_G: 0.9335 D(x): 0.6229 D(G(z)): 0.3654 / 0.4133\n",
      "[3/20][45/95] Loss_D: 1.2045 Loss_G: 2.1315 D(x): 0.7116 D(G(z)): 0.5405 / 0.1427\n",
      "[3/20][46/95] Loss_D: 1.1257 Loss_G: 0.9824 D(x): 0.4573 D(G(z)): 0.2317 / 0.3840\n",
      "[3/20][47/95] Loss_D: 1.3347 Loss_G: 1.1729 D(x): 0.5914 D(G(z)): 0.5272 / 0.3176\n",
      "[3/20][48/95] Loss_D: 1.3848 Loss_G: 1.0110 D(x): 0.4685 D(G(z)): 0.4413 / 0.3801\n",
      "[3/20][49/95] Loss_D: 0.9760 Loss_G: 2.3233 D(x): 0.7323 D(G(z)): 0.4697 / 0.1209\n",
      "[3/20][50/95] Loss_D: 1.7702 Loss_G: 0.3035 D(x): 0.2273 D(G(z)): 0.1617 / 0.7408\n",
      "[3/20][51/95] Loss_D: 1.6307 Loss_G: 1.9824 D(x): 0.8679 D(G(z)): 0.7652 / 0.1703\n",
      "[3/20][52/95] Loss_D: 1.5053 Loss_G: 0.8433 D(x): 0.3147 D(G(z)): 0.2026 / 0.4458\n",
      "[3/20][53/95] Loss_D: 1.2965 Loss_G: 1.2788 D(x): 0.6667 D(G(z)): 0.5618 / 0.2951\n",
      "[3/20][54/95] Loss_D: 0.9467 Loss_G: 1.4940 D(x): 0.6044 D(G(z)): 0.3379 / 0.2532\n",
      "[3/20][55/95] Loss_D: 1.1237 Loss_G: 0.9300 D(x): 0.5318 D(G(z)): 0.3481 / 0.4137\n",
      "[3/20][56/95] Loss_D: 1.0783 Loss_G: 1.1579 D(x): 0.6367 D(G(z)): 0.4470 / 0.3316\n",
      "[3/20][57/95] Loss_D: 1.2183 Loss_G: 1.5102 D(x): 0.6258 D(G(z)): 0.5033 / 0.2418\n",
      "[3/20][58/95] Loss_D: 1.3137 Loss_G: 0.6314 D(x): 0.4171 D(G(z)): 0.2975 / 0.5458\n",
      "[3/20][59/95] Loss_D: 1.3646 Loss_G: 1.5337 D(x): 0.6946 D(G(z)): 0.6088 / 0.2277\n",
      "[3/20][60/95] Loss_D: 1.2780 Loss_G: 0.8653 D(x): 0.4393 D(G(z)): 0.3214 / 0.4290\n",
      "[3/20][61/95] Loss_D: 1.0716 Loss_G: 1.5085 D(x): 0.6706 D(G(z)): 0.4714 / 0.2305\n",
      "[3/20][62/95] Loss_D: 1.2167 Loss_G: 0.5488 D(x): 0.4228 D(G(z)): 0.2655 / 0.5992\n",
      "[3/20][63/95] Loss_D: 1.5630 Loss_G: 1.8198 D(x): 0.8144 D(G(z)): 0.7065 / 0.1748\n",
      "[3/20][64/95] Loss_D: 1.2898 Loss_G: 0.6896 D(x): 0.3631 D(G(z)): 0.1806 / 0.5259\n",
      "[3/20][65/95] Loss_D: 1.2226 Loss_G: 1.6324 D(x): 0.7609 D(G(z)): 0.5913 / 0.2168\n",
      "[3/20][66/95] Loss_D: 1.0988 Loss_G: 1.0437 D(x): 0.5008 D(G(z)): 0.3044 / 0.3698\n",
      "[3/20][67/95] Loss_D: 1.1029 Loss_G: 1.9057 D(x): 0.7148 D(G(z)): 0.5166 / 0.1680\n",
      "[3/20][68/95] Loss_D: 1.3198 Loss_G: 0.4371 D(x): 0.3655 D(G(z)): 0.2098 / 0.6757\n",
      "[3/20][69/95] Loss_D: 1.6411 Loss_G: 2.1235 D(x): 0.8141 D(G(z)): 0.7335 / 0.1480\n",
      "[3/20][70/95] Loss_D: 1.4965 Loss_G: 0.6126 D(x): 0.3152 D(G(z)): 0.1977 / 0.5683\n",
      "[3/20][71/95] Loss_D: 1.4677 Loss_G: 1.4405 D(x): 0.6959 D(G(z)): 0.6439 / 0.2545\n",
      "[3/20][72/95] Loss_D: 1.1581 Loss_G: 0.8724 D(x): 0.4681 D(G(z)): 0.2946 / 0.4306\n",
      "[3/20][73/95] Loss_D: 1.2145 Loss_G: 1.6594 D(x): 0.6739 D(G(z)): 0.5410 / 0.2071\n",
      "[3/20][74/95] Loss_D: 1.2557 Loss_G: 0.7349 D(x): 0.4354 D(G(z)): 0.2880 / 0.4929\n",
      "[3/20][75/95] Loss_D: 1.2823 Loss_G: 1.4947 D(x): 0.6713 D(G(z)): 0.5741 / 0.2460\n",
      "[3/20][76/95] Loss_D: 1.3753 Loss_G: 0.6840 D(x): 0.4030 D(G(z)): 0.3190 / 0.5148\n",
      "[3/20][77/95] Loss_D: 1.2998 Loss_G: 1.4556 D(x): 0.6711 D(G(z)): 0.5807 / 0.2445\n",
      "[3/20][78/95] Loss_D: 1.1142 Loss_G: 0.9908 D(x): 0.4874 D(G(z)): 0.2997 / 0.3782\n",
      "[3/20][79/95] Loss_D: 1.0909 Loss_G: 1.4653 D(x): 0.6609 D(G(z)): 0.4748 / 0.2459\n",
      "[3/20][80/95] Loss_D: 0.7010 Loss_G: 2.0737 D(x): 0.7362 D(G(z)): 0.3104 / 0.1409\n",
      "[3/20][81/95] Loss_D: 0.9863 Loss_G: 0.5626 D(x): 0.4796 D(G(z)): 0.1815 / 0.5752\n",
      "[3/20][82/95] Loss_D: 1.4156 Loss_G: 1.7326 D(x): 0.7409 D(G(z)): 0.6464 / 0.2060\n",
      "[3/20][83/95] Loss_D: 1.4243 Loss_G: 0.5427 D(x): 0.3526 D(G(z)): 0.2305 / 0.5937\n",
      "[3/20][84/95] Loss_D: 1.2322 Loss_G: 1.5771 D(x): 0.7561 D(G(z)): 0.6021 / 0.2287\n",
      "[3/20][85/95] Loss_D: 0.8859 Loss_G: 2.5838 D(x): 0.7589 D(G(z)): 0.4190 / 0.1040\n",
      "[3/20][86/95] Loss_D: 1.8694 Loss_G: 0.3213 D(x): 0.2331 D(G(z)): 0.1562 / 0.7471\n",
      "[3/20][87/95] Loss_D: 2.0011 Loss_G: 1.4049 D(x): 0.8532 D(G(z)): 0.8089 / 0.2693\n",
      "[3/20][88/95] Loss_D: 1.1467 Loss_G: 1.5609 D(x): 0.5458 D(G(z)): 0.3549 / 0.2338\n",
      "[3/20][89/95] Loss_D: 0.8489 Loss_G: 2.0615 D(x): 0.6961 D(G(z)): 0.3642 / 0.1418\n",
      "[3/20][90/95] Loss_D: 1.7103 Loss_G: 0.4492 D(x): 0.2546 D(G(z)): 0.1791 / 0.6852\n",
      "[3/20][91/95] Loss_D: 1.8559 Loss_G: 1.6819 D(x): 0.8285 D(G(z)): 0.7542 / 0.2187\n",
      "[3/20][92/95] Loss_D: 1.4678 Loss_G: 1.0675 D(x): 0.3991 D(G(z)): 0.3462 / 0.3684\n",
      "[3/20][93/95] Loss_D: 1.1338 Loss_G: 0.9376 D(x): 0.5473 D(G(z)): 0.3840 / 0.4080\n",
      "[3/20][94/95] Loss_D: 0.7414 Loss_G: 2.8029 D(x): 0.8039 D(G(z)): 0.4017 / 0.0808\n",
      "[4/20][0/95] Loss_D: 1.3390 Loss_G: 0.6339 D(x): 0.4027 D(G(z)): 0.2575 / 0.5540\n",
      "[4/20][1/95] Loss_D: 1.5062 Loss_G: 2.4254 D(x): 0.7475 D(G(z)): 0.6614 / 0.1161\n",
      "[4/20][2/95] Loss_D: 1.5868 Loss_G: 0.5369 D(x): 0.3046 D(G(z)): 0.1795 / 0.6006\n",
      "[4/20][3/95] Loss_D: 1.8389 Loss_G: 2.4204 D(x): 0.8142 D(G(z)): 0.7579 / 0.1099\n",
      "[4/20][4/95] Loss_D: 1.8144 Loss_G: 0.7746 D(x): 0.2629 D(G(z)): 0.2508 / 0.4813\n",
      "[4/20][5/95] Loss_D: 1.5694 Loss_G: 1.1012 D(x): 0.6090 D(G(z)): 0.6196 / 0.3554\n",
      "[4/20][6/95] Loss_D: 1.5366 Loss_G: 0.9816 D(x): 0.4410 D(G(z)): 0.4611 / 0.3952\n",
      "[4/20][7/95] Loss_D: 1.1754 Loss_G: 1.3133 D(x): 0.5902 D(G(z)): 0.4429 / 0.2878\n",
      "[4/20][8/95] Loss_D: 1.4376 Loss_G: 0.7009 D(x): 0.4050 D(G(z)): 0.3664 / 0.5108\n",
      "[4/20][9/95] Loss_D: 1.2279 Loss_G: 1.7413 D(x): 0.6925 D(G(z)): 0.5542 / 0.2022\n",
      "[4/20][10/95] Loss_D: 1.0154 Loss_G: 1.2956 D(x): 0.5474 D(G(z)): 0.2867 / 0.2954\n",
      "[4/20][11/95] Loss_D: 0.9699 Loss_G: 1.3011 D(x): 0.6778 D(G(z)): 0.4156 / 0.2830\n",
      "[4/20][12/95] Loss_D: 0.9449 Loss_G: 1.8223 D(x): 0.6778 D(G(z)): 0.3923 / 0.1878\n",
      "[4/20][13/95] Loss_D: 1.2126 Loss_G: 0.6711 D(x): 0.4360 D(G(z)): 0.2518 / 0.5300\n",
      "[4/20][14/95] Loss_D: 1.5397 Loss_G: 2.1136 D(x): 0.8377 D(G(z)): 0.7159 / 0.1513\n",
      "[4/20][15/95] Loss_D: 1.2731 Loss_G: 1.4055 D(x): 0.4337 D(G(z)): 0.2734 / 0.2608\n",
      "[4/20][16/95] Loss_D: 0.8028 Loss_G: 2.0443 D(x): 0.7953 D(G(z)): 0.4191 / 0.1538\n",
      "[4/20][17/95] Loss_D: 2.4993 Loss_G: 0.2358 D(x): 0.1333 D(G(z)): 0.2511 / 0.7959\n",
      "[4/20][18/95] Loss_D: 1.6598 Loss_G: 1.2303 D(x): 0.7052 D(G(z)): 0.6936 / 0.3242\n",
      "[4/20][19/95] Loss_D: 1.5286 Loss_G: 1.8350 D(x): 0.5914 D(G(z)): 0.6017 / 0.2202\n",
      "[4/20][20/95] Loss_D: 1.5771 Loss_G: 0.4794 D(x): 0.3308 D(G(z)): 0.2196 / 0.6352\n",
      "[4/20][21/95] Loss_D: 1.9991 Loss_G: 2.4581 D(x): 0.7132 D(G(z)): 0.7499 / 0.1353\n",
      "[4/20][22/95] Loss_D: 1.6047 Loss_G: 0.8334 D(x): 0.3071 D(G(z)): 0.1986 / 0.4653\n",
      "[4/20][23/95] Loss_D: 1.1805 Loss_G: 0.8494 D(x): 0.6796 D(G(z)): 0.5122 / 0.4415\n",
      "[4/20][24/95] Loss_D: 1.4695 Loss_G: 1.1671 D(x): 0.6276 D(G(z)): 0.6148 / 0.3296\n",
      "[4/20][25/95] Loss_D: 1.4165 Loss_G: 0.6084 D(x): 0.3626 D(G(z)): 0.2451 / 0.5579\n",
      "[4/20][26/95] Loss_D: 1.4725 Loss_G: 1.1390 D(x): 0.7460 D(G(z)): 0.6649 / 0.3295\n",
      "[4/20][27/95] Loss_D: 1.3463 Loss_G: 0.8492 D(x): 0.4375 D(G(z)): 0.3830 / 0.4382\n",
      "[4/20][28/95] Loss_D: 1.1080 Loss_G: 1.1302 D(x): 0.6674 D(G(z)): 0.4937 / 0.3355\n",
      "[4/20][29/95] Loss_D: 1.0009 Loss_G: 1.2659 D(x): 0.5982 D(G(z)): 0.3605 / 0.3001\n",
      "[4/20][30/95] Loss_D: 1.3903 Loss_G: 0.7111 D(x): 0.4654 D(G(z)): 0.4401 / 0.5052\n",
      "[4/20][31/95] Loss_D: 1.1555 Loss_G: 1.1283 D(x): 0.6282 D(G(z)): 0.4718 / 0.3334\n",
      "[4/20][32/95] Loss_D: 1.1066 Loss_G: 1.0096 D(x): 0.5678 D(G(z)): 0.3721 / 0.3751\n",
      "[4/20][33/95] Loss_D: 1.1028 Loss_G: 1.1897 D(x): 0.6234 D(G(z)): 0.4440 / 0.3183\n",
      "[4/20][34/95] Loss_D: 1.2102 Loss_G: 0.9992 D(x): 0.5336 D(G(z)): 0.3915 / 0.3853\n",
      "[4/20][35/95] Loss_D: 1.2017 Loss_G: 1.1583 D(x): 0.6136 D(G(z)): 0.4803 / 0.3287\n",
      "[4/20][36/95] Loss_D: 1.3008 Loss_G: 0.6871 D(x): 0.4496 D(G(z)): 0.3577 / 0.5110\n",
      "[4/20][37/95] Loss_D: 1.3337 Loss_G: 1.5074 D(x): 0.6897 D(G(z)): 0.6039 / 0.2345\n",
      "[4/20][38/95] Loss_D: 1.6820 Loss_G: 0.4263 D(x): 0.2951 D(G(z)): 0.3021 / 0.6657\n",
      "[4/20][39/95] Loss_D: 1.3322 Loss_G: 1.8306 D(x): 0.7950 D(G(z)): 0.6414 / 0.1727\n",
      "[4/20][40/95] Loss_D: 1.4239 Loss_G: 0.6018 D(x): 0.3330 D(G(z)): 0.2145 / 0.5536\n",
      "[4/20][41/95] Loss_D: 1.3973 Loss_G: 1.3394 D(x): 0.6771 D(G(z)): 0.6175 / 0.2689\n",
      "[4/20][42/95] Loss_D: 1.3039 Loss_G: 0.9217 D(x): 0.4259 D(G(z)): 0.3416 / 0.4067\n",
      "[4/20][43/95] Loss_D: 1.3240 Loss_G: 0.9742 D(x): 0.5181 D(G(z)): 0.4643 / 0.3895\n",
      "[4/20][44/95] Loss_D: 1.4772 Loss_G: 1.0451 D(x): 0.5206 D(G(z)): 0.5416 / 0.3709\n",
      "[4/20][45/95] Loss_D: 1.3109 Loss_G: 0.6275 D(x): 0.4273 D(G(z)): 0.3308 / 0.5457\n",
      "[4/20][46/95] Loss_D: 1.3207 Loss_G: 1.5988 D(x): 0.6690 D(G(z)): 0.5859 / 0.2262\n",
      "[4/20][47/95] Loss_D: 0.8902 Loss_G: 1.8753 D(x): 0.6640 D(G(z)): 0.3581 / 0.1779\n",
      "[4/20][48/95] Loss_D: 1.6949 Loss_G: 0.2887 D(x): 0.2847 D(G(z)): 0.2433 / 0.7551\n",
      "[4/20][49/95] Loss_D: 1.8100 Loss_G: 1.1180 D(x): 0.7884 D(G(z)): 0.7632 / 0.3351\n",
      "[4/20][50/95] Loss_D: 0.7467 Loss_G: 2.6516 D(x): 0.7931 D(G(z)): 0.3918 / 0.0835\n",
      "[4/20][51/95] Loss_D: 2.4812 Loss_G: 0.4778 D(x): 0.1271 D(G(z)): 0.0974 / 0.6293\n",
      "[4/20][52/95] Loss_D: 1.3667 Loss_G: 0.7019 D(x): 0.7687 D(G(z)): 0.6528 / 0.5052\n",
      "[4/20][53/95] Loss_D: 1.1569 Loss_G: 1.5122 D(x): 0.7243 D(G(z)): 0.5559 / 0.2411\n",
      "[4/20][54/95] Loss_D: 1.5730 Loss_G: 0.7072 D(x): 0.3369 D(G(z)): 0.2878 / 0.5242\n",
      "[4/20][55/95] Loss_D: 1.2350 Loss_G: 0.9453 D(x): 0.6951 D(G(z)): 0.5469 / 0.4047\n",
      "[4/20][56/95] Loss_D: 1.1895 Loss_G: 1.1446 D(x): 0.5932 D(G(z)): 0.4512 / 0.3434\n",
      "[4/20][57/95] Loss_D: 1.3463 Loss_G: 0.9066 D(x): 0.4774 D(G(z)): 0.4095 / 0.4303\n",
      "[4/20][58/95] Loss_D: 1.1681 Loss_G: 0.9124 D(x): 0.5585 D(G(z)): 0.4133 / 0.4149\n",
      "[4/20][59/95] Loss_D: 1.0852 Loss_G: 1.4880 D(x): 0.6674 D(G(z)): 0.4727 / 0.2516\n",
      "[4/20][60/95] Loss_D: 1.5358 Loss_G: 0.5794 D(x): 0.3490 D(G(z)): 0.3173 / 0.5676\n",
      "[4/20][61/95] Loss_D: 1.4457 Loss_G: 1.1391 D(x): 0.6866 D(G(z)): 0.6369 / 0.3244\n",
      "[4/20][62/95] Loss_D: 1.3810 Loss_G: 0.9103 D(x): 0.4148 D(G(z)): 0.3700 / 0.4161\n",
      "[4/20][63/95] Loss_D: 1.3541 Loss_G: 0.6626 D(x): 0.4858 D(G(z)): 0.4489 / 0.5252\n",
      "[4/20][64/95] Loss_D: 1.3407 Loss_G: 1.6382 D(x): 0.6457 D(G(z)): 0.5844 / 0.2194\n",
      "[4/20][65/95] Loss_D: 1.5447 Loss_G: 0.5226 D(x): 0.3166 D(G(z)): 0.2486 / 0.6048\n",
      "[4/20][66/95] Loss_D: 1.4250 Loss_G: 1.4319 D(x): 0.7442 D(G(z)): 0.6617 / 0.2599\n",
      "[4/20][67/95] Loss_D: 1.3347 Loss_G: 0.7399 D(x): 0.3942 D(G(z)): 0.2827 / 0.4875\n",
      "[4/20][68/95] Loss_D: 1.2823 Loss_G: 1.0068 D(x): 0.5996 D(G(z)): 0.5156 / 0.3764\n",
      "[4/20][69/95] Loss_D: 1.0226 Loss_G: 1.7934 D(x): 0.7375 D(G(z)): 0.4943 / 0.1951\n",
      "[4/20][70/95] Loss_D: 1.8247 Loss_G: 0.3591 D(x): 0.2351 D(G(z)): 0.2256 / 0.7079\n",
      "[4/20][71/95] Loss_D: 1.6143 Loss_G: 1.1099 D(x): 0.7635 D(G(z)): 0.7166 / 0.3381\n",
      "[4/20][72/95] Loss_D: 1.4605 Loss_G: 0.9487 D(x): 0.4312 D(G(z)): 0.4299 / 0.3968\n",
      "[4/20][73/95] Loss_D: 1.3204 Loss_G: 0.9911 D(x): 0.5504 D(G(z)): 0.4974 / 0.3775\n",
      "[4/20][74/95] Loss_D: 1.4896 Loss_G: 0.5000 D(x): 0.3792 D(G(z)): 0.3677 / 0.6144\n",
      "[4/20][75/95] Loss_D: 1.4458 Loss_G: 1.1502 D(x): 0.6981 D(G(z)): 0.6364 / 0.3293\n",
      "[4/20][76/95] Loss_D: 1.2949 Loss_G: 0.9417 D(x): 0.4696 D(G(z)): 0.3904 / 0.3966\n",
      "[4/20][77/95] Loss_D: 1.0615 Loss_G: 1.0087 D(x): 0.5992 D(G(z)): 0.4073 / 0.3732\n",
      "[4/20][78/95] Loss_D: 1.4581 Loss_G: 0.7548 D(x): 0.5301 D(G(z)): 0.5391 / 0.4742\n",
      "[4/20][79/95] Loss_D: 1.1304 Loss_G: 0.8977 D(x): 0.5492 D(G(z)): 0.3939 / 0.4133\n",
      "[4/20][80/95] Loss_D: 1.1668 Loss_G: 0.8490 D(x): 0.5519 D(G(z)): 0.4159 / 0.4374\n",
      "[4/20][81/95] Loss_D: 1.2205 Loss_G: 1.0212 D(x): 0.5966 D(G(z)): 0.4904 / 0.3677\n",
      "[4/20][82/95] Loss_D: 1.1961 Loss_G: 1.1098 D(x): 0.5656 D(G(z)): 0.4464 / 0.3424\n",
      "[4/20][83/95] Loss_D: 0.7341 Loss_G: 2.0290 D(x): 0.7865 D(G(z)): 0.3789 / 0.1492\n",
      "[4/20][84/95] Loss_D: 1.6784 Loss_G: 0.3696 D(x): 0.2565 D(G(z)): 0.2056 / 0.6952\n",
      "[4/20][85/95] Loss_D: 1.6903 Loss_G: 0.9046 D(x): 0.7040 D(G(z)): 0.7230 / 0.4166\n",
      "[4/20][86/95] Loss_D: 1.3885 Loss_G: 1.0788 D(x): 0.4867 D(G(z)): 0.4649 / 0.3545\n",
      "[4/20][87/95] Loss_D: 0.6857 Loss_G: 1.9041 D(x): 0.7930 D(G(z)): 0.3563 / 0.1666\n",
      "[4/20][88/95] Loss_D: 1.9097 Loss_G: 0.2513 D(x): 0.1967 D(G(z)): 0.1875 / 0.7849\n",
      "[4/20][89/95] Loss_D: 1.9836 Loss_G: 1.2554 D(x): 0.8556 D(G(z)): 0.8247 / 0.2996\n",
      "[4/20][90/95] Loss_D: 1.2368 Loss_G: 1.3445 D(x): 0.4602 D(G(z)): 0.3395 / 0.2796\n",
      "[4/20][91/95] Loss_D: 1.3896 Loss_G: 0.6100 D(x): 0.4287 D(G(z)): 0.3840 / 0.5582\n",
      "[4/20][92/95] Loss_D: 1.3656 Loss_G: 1.0725 D(x): 0.6394 D(G(z)): 0.5805 / 0.3514\n",
      "[4/20][93/95] Loss_D: 1.1755 Loss_G: 0.9520 D(x): 0.5229 D(G(z)): 0.3916 / 0.3946\n",
      "[4/20][94/95] Loss_D: 2.7405 Loss_G: 0.5845 D(x): 0.1699 D(G(z)): 0.5859 / 0.5639\n",
      "[5/20][0/95] Loss_D: 1.2449 Loss_G: 1.4808 D(x): 0.7520 D(G(z)): 0.6058 / 0.2428\n",
      "[5/20][1/95] Loss_D: 1.3992 Loss_G: 0.9581 D(x): 0.3820 D(G(z)): 0.2995 / 0.3936\n",
      "[5/20][2/95] Loss_D: 1.4881 Loss_G: 0.7593 D(x): 0.5007 D(G(z)): 0.5029 / 0.4762\n",
      "[5/20][3/95] Loss_D: 1.3850 Loss_G: 0.7796 D(x): 0.5159 D(G(z)): 0.4920 / 0.4690\n",
      "[5/20][4/95] Loss_D: 1.3716 Loss_G: 0.9318 D(x): 0.5486 D(G(z)): 0.5239 / 0.4050\n",
      "[5/20][5/95] Loss_D: 1.5887 Loss_G: 0.7688 D(x): 0.4864 D(G(z)): 0.5524 / 0.4720\n",
      "[5/20][6/95] Loss_D: 1.3951 Loss_G: 0.7279 D(x): 0.4843 D(G(z)): 0.4671 / 0.4911\n",
      "[5/20][7/95] Loss_D: 1.2297 Loss_G: 1.2157 D(x): 0.6332 D(G(z)): 0.5203 / 0.3155\n",
      "[5/20][8/95] Loss_D: 1.3806 Loss_G: 0.8226 D(x): 0.4484 D(G(z)): 0.3988 / 0.4493\n",
      "[5/20][9/95] Loss_D: 0.9234 Loss_G: 1.4196 D(x): 0.7233 D(G(z)): 0.4363 / 0.2503\n",
      "[5/20][10/95] Loss_D: 1.4029 Loss_G: 0.5891 D(x): 0.3891 D(G(z)): 0.3333 / 0.5634\n",
      "[5/20][11/95] Loss_D: 1.4088 Loss_G: 1.0474 D(x): 0.6379 D(G(z)): 0.5967 / 0.3596\n",
      "[5/20][12/95] Loss_D: 1.2387 Loss_G: 0.9377 D(x): 0.4917 D(G(z)): 0.3937 / 0.3985\n",
      "[5/20][13/95] Loss_D: 1.2112 Loss_G: 0.8955 D(x): 0.5440 D(G(z)): 0.4415 / 0.4164\n",
      "[5/20][14/95] Loss_D: 1.2877 Loss_G: 1.1019 D(x): 0.5831 D(G(z)): 0.5137 / 0.3435\n",
      "[5/20][15/95] Loss_D: 1.3151 Loss_G: 0.6150 D(x): 0.4384 D(G(z)): 0.3691 / 0.5489\n",
      "[5/20][16/95] Loss_D: 1.3560 Loss_G: 1.7403 D(x): 0.6702 D(G(z)): 0.6001 / 0.1955\n",
      "[5/20][17/95] Loss_D: 1.5423 Loss_G: 0.4928 D(x): 0.3239 D(G(z)): 0.2871 / 0.6156\n",
      "[5/20][18/95] Loss_D: 1.4201 Loss_G: 1.2423 D(x): 0.6845 D(G(z)): 0.6349 / 0.3045\n",
      "[5/20][19/95] Loss_D: 1.3781 Loss_G: 0.6886 D(x): 0.4167 D(G(z)): 0.3599 / 0.5068\n",
      "[5/20][20/95] Loss_D: 1.4043 Loss_G: 1.0314 D(x): 0.6057 D(G(z)): 0.5877 / 0.3628\n",
      "[5/20][21/95] Loss_D: 1.4008 Loss_G: 0.7696 D(x): 0.4551 D(G(z)): 0.4377 / 0.4673\n",
      "[5/20][22/95] Loss_D: 1.1967 Loss_G: 1.1791 D(x): 0.5906 D(G(z)): 0.4739 / 0.3170\n",
      "[5/20][23/95] Loss_D: 1.3839 Loss_G: 0.7246 D(x): 0.4280 D(G(z)): 0.3883 / 0.4901\n",
      "[5/20][24/95] Loss_D: 1.2535 Loss_G: 0.9206 D(x): 0.6102 D(G(z)): 0.5188 / 0.4038\n",
      "[5/20][25/95] Loss_D: 1.2185 Loss_G: 1.0286 D(x): 0.5516 D(G(z)): 0.4480 / 0.3639\n",
      "[5/20][26/95] Loss_D: 1.2533 Loss_G: 0.9184 D(x): 0.5448 D(G(z)): 0.4519 / 0.4055\n",
      "[5/20][27/95] Loss_D: 1.2690 Loss_G: 0.9652 D(x): 0.5580 D(G(z)): 0.4717 / 0.3884\n",
      "[5/20][28/95] Loss_D: 0.9489 Loss_G: 2.3812 D(x): 0.7631 D(G(z)): 0.4788 / 0.1056\n",
      "[5/20][29/95] Loss_D: 1.5693 Loss_G: 0.3861 D(x): 0.2655 D(G(z)): 0.1473 / 0.6869\n",
      "[5/20][30/95] Loss_D: 1.5840 Loss_G: 1.2011 D(x): 0.7243 D(G(z)): 0.6957 / 0.3286\n",
      "[5/20][31/95] Loss_D: 1.2091 Loss_G: 1.7425 D(x): 0.6505 D(G(z)): 0.5249 / 0.2119\n",
      "[5/20][32/95] Loss_D: 2.1306 Loss_G: 0.3884 D(x): 0.1713 D(G(z)): 0.1895 / 0.6907\n",
      "[5/20][33/95] Loss_D: 1.8571 Loss_G: 0.8073 D(x): 0.7475 D(G(z)): 0.7682 / 0.4773\n",
      "[5/20][34/95] Loss_D: 1.3033 Loss_G: 1.2785 D(x): 0.5150 D(G(z)): 0.4437 / 0.2992\n",
      "[5/20][35/95] Loss_D: 1.6118 Loss_G: 0.6050 D(x): 0.4209 D(G(z)): 0.4692 / 0.5651\n",
      "[5/20][36/95] Loss_D: 1.3377 Loss_G: 1.2278 D(x): 0.7019 D(G(z)): 0.6057 / 0.3112\n",
      "[5/20][37/95] Loss_D: 0.9396 Loss_G: 1.5668 D(x): 0.6549 D(G(z)): 0.3831 / 0.2379\n",
      "[5/20][38/95] Loss_D: 0.7481 Loss_G: 1.5952 D(x): 0.6590 D(G(z)): 0.2620 / 0.2189\n",
      "[5/20][39/95] Loss_D: 1.5628 Loss_G: 0.3095 D(x): 0.2970 D(G(z)): 0.2402 / 0.7424\n",
      "[5/20][40/95] Loss_D: 1.8965 Loss_G: 0.9541 D(x): 0.8031 D(G(z)): 0.7821 / 0.4034\n",
      "[5/20][41/95] Loss_D: 1.3575 Loss_G: 1.3121 D(x): 0.5064 D(G(z)): 0.4622 / 0.2888\n",
      "[5/20][42/95] Loss_D: 1.4307 Loss_G: 0.6973 D(x): 0.3597 D(G(z)): 0.2838 / 0.5095\n",
      "[5/20][43/95] Loss_D: 1.4546 Loss_G: 0.7897 D(x): 0.6302 D(G(z)): 0.6060 / 0.4639\n",
      "[5/20][44/95] Loss_D: 1.2128 Loss_G: 1.2321 D(x): 0.5824 D(G(z)): 0.4708 / 0.3023\n",
      "[5/20][45/95] Loss_D: 1.3233 Loss_G: 0.7515 D(x): 0.4308 D(G(z)): 0.3554 / 0.4849\n",
      "[5/20][46/95] Loss_D: 1.3891 Loss_G: 1.1225 D(x): 0.6461 D(G(z)): 0.5914 / 0.3405\n",
      "[5/20][47/95] Loss_D: 1.3344 Loss_G: 0.8902 D(x): 0.4566 D(G(z)): 0.3904 / 0.4249\n",
      "[5/20][48/95] Loss_D: 1.2255 Loss_G: 0.9221 D(x): 0.5562 D(G(z)): 0.4539 / 0.4098\n",
      "[5/20][49/95] Loss_D: 1.2410 Loss_G: 0.9742 D(x): 0.5612 D(G(z)): 0.4661 / 0.3906\n",
      "[5/20][50/95] Loss_D: 1.2112 Loss_G: 1.4340 D(x): 0.5818 D(G(z)): 0.4734 / 0.2580\n",
      "[5/20][51/95] Loss_D: 1.4336 Loss_G: 0.5285 D(x): 0.4057 D(G(z)): 0.3460 / 0.6017\n",
      "[5/20][52/95] Loss_D: 1.4985 Loss_G: 1.1290 D(x): 0.6517 D(G(z)): 0.6308 / 0.3340\n",
      "[5/20][53/95] Loss_D: 1.2386 Loss_G: 0.8512 D(x): 0.4630 D(G(z)): 0.3541 / 0.4374\n",
      "[5/20][54/95] Loss_D: 1.4461 Loss_G: 1.3849 D(x): 0.6037 D(G(z)): 0.5904 / 0.2678\n",
      "[5/20][55/95] Loss_D: 1.6249 Loss_G: 0.4329 D(x): 0.3224 D(G(z)): 0.3354 / 0.6541\n",
      "[5/20][56/95] Loss_D: 1.7432 Loss_G: 1.2179 D(x): 0.6586 D(G(z)): 0.7202 / 0.3044\n",
      "[5/20][57/95] Loss_D: 1.3694 Loss_G: 0.7186 D(x): 0.3959 D(G(z)): 0.3286 / 0.4918\n",
      "[5/20][58/95] Loss_D: 1.3672 Loss_G: 1.0866 D(x): 0.6243 D(G(z)): 0.5789 / 0.3415\n",
      "[5/20][59/95] Loss_D: 1.2815 Loss_G: 0.8464 D(x): 0.4594 D(G(z)): 0.3845 / 0.4340\n",
      "[5/20][60/95] Loss_D: 1.4081 Loss_G: 1.1222 D(x): 0.5409 D(G(z)): 0.5358 / 0.3323\n",
      "[5/20][61/95] Loss_D: 1.3553 Loss_G: 0.7407 D(x): 0.4283 D(G(z)): 0.3829 / 0.4822\n",
      "[5/20][62/95] Loss_D: 1.3380 Loss_G: 1.3564 D(x): 0.5901 D(G(z)): 0.5394 / 0.2812\n",
      "[5/20][63/95] Loss_D: 0.9843 Loss_G: 1.4417 D(x): 0.5847 D(G(z)): 0.3394 / 0.2510\n",
      "[5/20][64/95] Loss_D: 1.4989 Loss_G: 0.4415 D(x): 0.3563 D(G(z)): 0.3262 / 0.6529\n",
      "[5/20][65/95] Loss_D: 1.6398 Loss_G: 1.4975 D(x): 0.6869 D(G(z)): 0.7033 / 0.2459\n",
      "[5/20][66/95] Loss_D: 1.2330 Loss_G: 1.0341 D(x): 0.4478 D(G(z)): 0.3001 / 0.3780\n",
      "[5/20][67/95] Loss_D: 0.8826 Loss_G: 1.6487 D(x): 0.7361 D(G(z)): 0.4192 / 0.2134\n",
      "[5/20][68/95] Loss_D: 1.7173 Loss_G: 0.3503 D(x): 0.2967 D(G(z)): 0.2920 / 0.7084\n",
      "[5/20][69/95] Loss_D: 1.6213 Loss_G: 1.1635 D(x): 0.7558 D(G(z)): 0.7322 / 0.3344\n",
      "[5/20][70/95] Loss_D: 1.7028 Loss_G: 0.6781 D(x): 0.3743 D(G(z)): 0.4774 / 0.5165\n",
      "[5/20][71/95] Loss_D: 1.7201 Loss_G: 0.6867 D(x): 0.4894 D(G(z)): 0.6066 / 0.5114\n",
      "[5/20][72/95] Loss_D: 1.4064 Loss_G: 0.9030 D(x): 0.5144 D(G(z)): 0.4981 / 0.4175\n",
      "[5/20][73/95] Loss_D: 1.5021 Loss_G: 0.5639 D(x): 0.4401 D(G(z)): 0.4539 / 0.5823\n",
      "[5/20][74/95] Loss_D: 1.3763 Loss_G: 1.1804 D(x): 0.6827 D(G(z)): 0.6149 / 0.3185\n",
      "[5/20][75/95] Loss_D: 1.2822 Loss_G: 1.0284 D(x): 0.4955 D(G(z)): 0.4020 / 0.3710\n",
      "[5/20][76/95] Loss_D: 1.4282 Loss_G: 0.7136 D(x): 0.4489 D(G(z)): 0.4399 / 0.5033\n",
      "[5/20][77/95] Loss_D: 1.2477 Loss_G: 1.1594 D(x): 0.6577 D(G(z)): 0.5432 / 0.3274\n",
      "[5/20][78/95] Loss_D: 1.3461 Loss_G: 0.9002 D(x): 0.4591 D(G(z)): 0.4095 / 0.4175\n",
      "[5/20][79/95] Loss_D: 1.2765 Loss_G: 0.7739 D(x): 0.5219 D(G(z)): 0.4448 / 0.4705\n",
      "[5/20][80/95] Loss_D: 1.3616 Loss_G: 1.1503 D(x): 0.5815 D(G(z)): 0.5390 / 0.3274\n",
      "[5/20][81/95] Loss_D: 1.3107 Loss_G: 0.9183 D(x): 0.4608 D(G(z)): 0.3904 / 0.4095\n",
      "[5/20][82/95] Loss_D: 1.3323 Loss_G: 0.7532 D(x): 0.5115 D(G(z)): 0.4672 / 0.4791\n",
      "[5/20][83/95] Loss_D: 1.2634 Loss_G: 1.1403 D(x): 0.6180 D(G(z)): 0.5264 / 0.3388\n",
      "[5/20][84/95] Loss_D: 1.3217 Loss_G: 0.8348 D(x): 0.4650 D(G(z)): 0.4015 / 0.4477\n",
      "[5/20][85/95] Loss_D: 1.2043 Loss_G: 1.5085 D(x): 0.6562 D(G(z)): 0.5273 / 0.2445\n",
      "[5/20][86/95] Loss_D: 1.4361 Loss_G: 0.5112 D(x): 0.3610 D(G(z)): 0.2867 / 0.6186\n",
      "[5/20][87/95] Loss_D: 1.5158 Loss_G: 1.4254 D(x): 0.7042 D(G(z)): 0.6662 / 0.2635\n",
      "[5/20][88/95] Loss_D: 1.2151 Loss_G: 0.8840 D(x): 0.4419 D(G(z)): 0.2927 / 0.4334\n",
      "[5/20][89/95] Loss_D: 1.2999 Loss_G: 0.9496 D(x): 0.5801 D(G(z)): 0.5071 / 0.4017\n",
      "[5/20][90/95] Loss_D: 1.3755 Loss_G: 1.0434 D(x): 0.5568 D(G(z)): 0.5170 / 0.3677\n",
      "[5/20][91/95] Loss_D: 1.1852 Loss_G: 0.7306 D(x): 0.5152 D(G(z)): 0.3834 / 0.4974\n",
      "[5/20][92/95] Loss_D: 1.2623 Loss_G: 1.3689 D(x): 0.6595 D(G(z)): 0.5502 / 0.2759\n",
      "[5/20][93/95] Loss_D: 1.6871 Loss_G: 0.5512 D(x): 0.3552 D(G(z)): 0.4514 / 0.5839\n",
      "[5/20][94/95] Loss_D: 1.7486 Loss_G: 1.1956 D(x): 0.5037 D(G(z)): 0.6347 / 0.3088\n",
      "[6/20][0/95] Loss_D: 1.3796 Loss_G: 1.4877 D(x): 0.5461 D(G(z)): 0.5104 / 0.2520\n",
      "[6/20][1/95] Loss_D: 1.3383 Loss_G: 0.6735 D(x): 0.4107 D(G(z)): 0.3333 / 0.5242\n",
      "[6/20][2/95] Loss_D: 1.4532 Loss_G: 1.2056 D(x): 0.6046 D(G(z)): 0.5833 / 0.3147\n",
      "[6/20][3/95] Loss_D: 1.4343 Loss_G: 0.8141 D(x): 0.4381 D(G(z)): 0.4139 / 0.4527\n",
      "[6/20][4/95] Loss_D: 1.5394 Loss_G: 0.9690 D(x): 0.5043 D(G(z)): 0.5534 / 0.3861\n",
      "[6/20][5/95] Loss_D: 1.3953 Loss_G: 0.8669 D(x): 0.4617 D(G(z)): 0.4366 / 0.4306\n",
      "[6/20][6/95] Loss_D: 1.4664 Loss_G: 1.1872 D(x): 0.5088 D(G(z)): 0.5275 / 0.3271\n",
      "[6/20][7/95] Loss_D: 1.3618 Loss_G: 0.9280 D(x): 0.4470 D(G(z)): 0.3988 / 0.4190\n",
      "[6/20][8/95] Loss_D: 1.1868 Loss_G: 1.1420 D(x): 0.5812 D(G(z)): 0.4375 / 0.3477\n",
      "[6/20][9/95] Loss_D: 1.2706 Loss_G: 1.0390 D(x): 0.5449 D(G(z)): 0.4453 / 0.3754\n",
      "[6/20][10/95] Loss_D: 1.3141 Loss_G: 0.8960 D(x): 0.5195 D(G(z)): 0.4437 / 0.4247\n",
      "[6/20][11/95] Loss_D: 1.4041 Loss_G: 1.1146 D(x): 0.5841 D(G(z)): 0.5455 / 0.3509\n",
      "[6/20][12/95] Loss_D: 1.3454 Loss_G: 0.8383 D(x): 0.4835 D(G(z)): 0.4194 / 0.4448\n",
      "[6/20][13/95] Loss_D: 1.4884 Loss_G: 0.8263 D(x): 0.5211 D(G(z)): 0.5356 / 0.4487\n",
      "[6/20][14/95] Loss_D: 1.4635 Loss_G: 0.9699 D(x): 0.5225 D(G(z)): 0.5250 / 0.3888\n",
      "[6/20][15/95] Loss_D: 1.4068 Loss_G: 0.9791 D(x): 0.4944 D(G(z)): 0.4852 / 0.3846\n",
      "[6/20][16/95] Loss_D: 1.3367 Loss_G: 0.9063 D(x): 0.4981 D(G(z)): 0.4499 / 0.4097\n",
      "[6/20][17/95] Loss_D: 1.2963 Loss_G: 1.0326 D(x): 0.5340 D(G(z)): 0.4593 / 0.3664\n",
      "[6/20][18/95] Loss_D: 1.4056 Loss_G: 0.9586 D(x): 0.5241 D(G(z)): 0.4987 / 0.3974\n",
      "[6/20][19/95] Loss_D: 1.3924 Loss_G: 0.8253 D(x): 0.4754 D(G(z)): 0.4432 / 0.4509\n",
      "[6/20][20/95] Loss_D: 1.4282 Loss_G: 0.9718 D(x): 0.5582 D(G(z)): 0.5474 / 0.3940\n",
      "[6/20][21/95] Loss_D: 1.3241 Loss_G: 0.9625 D(x): 0.5245 D(G(z)): 0.4643 / 0.4040\n",
      "[6/20][22/95] Loss_D: 1.2799 Loss_G: 1.1188 D(x): 0.5738 D(G(z)): 0.4885 / 0.3442\n",
      "[6/20][23/95] Loss_D: 1.3557 Loss_G: 0.7842 D(x): 0.4885 D(G(z)): 0.4316 / 0.4759\n",
      "[6/20][24/95] Loss_D: 1.4896 Loss_G: 1.4361 D(x): 0.5817 D(G(z)): 0.5849 / 0.2587\n",
      "[6/20][25/95] Loss_D: 1.3892 Loss_G: 0.5542 D(x): 0.4071 D(G(z)): 0.3396 / 0.5872\n",
      "[6/20][26/95] Loss_D: 1.5555 Loss_G: 1.7312 D(x): 0.7002 D(G(z)): 0.6722 / 0.1933\n",
      "[6/20][27/95] Loss_D: 1.7065 Loss_G: 0.3336 D(x): 0.2720 D(G(z)): 0.2471 / 0.7269\n",
      "[6/20][28/95] Loss_D: 1.5788 Loss_G: 2.2575 D(x): 0.9016 D(G(z)): 0.7488 / 0.1150\n",
      "[6/20][29/95] Loss_D: 1.8218 Loss_G: 0.5841 D(x): 0.2130 D(G(z)): 0.1742 / 0.5701\n",
      "[6/20][30/95] Loss_D: 1.4147 Loss_G: 0.9082 D(x): 0.6696 D(G(z)): 0.6173 / 0.4155\n",
      "[6/20][31/95] Loss_D: 1.3243 Loss_G: 1.3086 D(x): 0.5508 D(G(z)): 0.4968 / 0.2895\n",
      "[6/20][32/95] Loss_D: 1.3164 Loss_G: 0.8296 D(x): 0.4584 D(G(z)): 0.3838 / 0.4507\n",
      "[6/20][33/95] Loss_D: 1.3619 Loss_G: 0.9616 D(x): 0.5619 D(G(z)): 0.5219 / 0.3964\n",
      "[6/20][34/95] Loss_D: 1.3410 Loss_G: 1.2327 D(x): 0.5494 D(G(z)): 0.5001 / 0.3160\n",
      "[6/20][35/95] Loss_D: 1.4037 Loss_G: 0.5857 D(x): 0.4425 D(G(z)): 0.3970 / 0.5678\n",
      "[6/20][36/95] Loss_D: 1.6507 Loss_G: 1.3792 D(x): 0.6695 D(G(z)): 0.6889 / 0.2763\n",
      "[6/20][37/95] Loss_D: 1.7659 Loss_G: 0.6128 D(x): 0.2899 D(G(z)): 0.3404 / 0.5550\n",
      "[6/20][38/95] Loss_D: 1.5575 Loss_G: 1.0547 D(x): 0.6022 D(G(z)): 0.6248 / 0.3597\n",
      "[6/20][39/95] Loss_D: 1.4283 Loss_G: 0.9792 D(x): 0.4485 D(G(z)): 0.4345 / 0.3822\n",
      "[6/20][40/95] Loss_D: 1.1471 Loss_G: 0.9071 D(x): 0.5414 D(G(z)): 0.3955 / 0.4166\n",
      "[6/20][41/95] Loss_D: 1.2421 Loss_G: 1.1451 D(x): 0.6226 D(G(z)): 0.5239 / 0.3323\n",
      "[6/20][42/95] Loss_D: 1.2530 Loss_G: 0.8161 D(x): 0.4870 D(G(z)): 0.3847 / 0.4542\n",
      "[6/20][43/95] Loss_D: 1.3800 Loss_G: 1.1487 D(x): 0.5790 D(G(z)): 0.5469 / 0.3295\n",
      "[6/20][44/95] Loss_D: 1.4413 Loss_G: 0.8159 D(x): 0.4180 D(G(z)): 0.4105 / 0.4554\n",
      "[6/20][45/95] Loss_D: 1.4151 Loss_G: 1.1422 D(x): 0.5657 D(G(z)): 0.5531 / 0.3385\n",
      "[6/20][46/95] Loss_D: 1.3936 Loss_G: 0.8119 D(x): 0.4506 D(G(z)): 0.4241 / 0.4558\n",
      "[6/20][47/95] Loss_D: 1.5225 Loss_G: 0.9033 D(x): 0.4924 D(G(z)): 0.5277 / 0.4210\n",
      "[6/20][48/95] Loss_D: 1.3427 Loss_G: 1.4154 D(x): 0.5577 D(G(z)): 0.5126 / 0.2685\n",
      "[6/20][49/95] Loss_D: 1.0458 Loss_G: 1.3994 D(x): 0.5780 D(G(z)): 0.3624 / 0.2662\n",
      "[6/20][50/95] Loss_D: 1.4869 Loss_G: 0.4605 D(x): 0.3753 D(G(z)): 0.3312 / 0.6465\n",
      "[6/20][51/95] Loss_D: 1.5254 Loss_G: 1.6451 D(x): 0.7563 D(G(z)): 0.6865 / 0.2166\n",
      "[6/20][52/95] Loss_D: 1.4127 Loss_G: 0.7288 D(x): 0.3704 D(G(z)): 0.2911 / 0.4943\n",
      "[6/20][53/95] Loss_D: 1.1617 Loss_G: 1.6704 D(x): 0.8355 D(G(z)): 0.6084 / 0.2139\n",
      "[6/20][54/95] Loss_D: 1.5558 Loss_G: 0.6739 D(x): 0.3199 D(G(z)): 0.2652 / 0.5261\n",
      "[6/20][55/95] Loss_D: 1.2790 Loss_G: 1.3701 D(x): 0.7423 D(G(z)): 0.6029 / 0.2730\n",
      "[6/20][56/95] Loss_D: 1.5237 Loss_G: 0.7125 D(x): 0.3557 D(G(z)): 0.3208 / 0.5056\n",
      "[6/20][57/95] Loss_D: 1.5150 Loss_G: 0.7690 D(x): 0.5678 D(G(z)): 0.5863 / 0.4721\n",
      "[6/20][58/95] Loss_D: 1.3818 Loss_G: 1.0427 D(x): 0.5789 D(G(z)): 0.5463 / 0.3649\n",
      "[6/20][59/95] Loss_D: 1.3318 Loss_G: 0.8183 D(x): 0.4665 D(G(z)): 0.3866 / 0.4518\n",
      "[6/20][60/95] Loss_D: 1.4238 Loss_G: 0.8844 D(x): 0.5554 D(G(z)): 0.5416 / 0.4277\n",
      "[6/20][61/95] Loss_D: 1.3396 Loss_G: 0.9332 D(x): 0.5396 D(G(z)): 0.4864 / 0.4133\n",
      "[6/20][62/95] Loss_D: 1.2488 Loss_G: 1.1427 D(x): 0.6149 D(G(z)): 0.5086 / 0.3431\n",
      "[6/20][63/95] Loss_D: 1.2960 Loss_G: 0.9215 D(x): 0.4995 D(G(z)): 0.4018 / 0.4116\n",
      "[6/20][64/95] Loss_D: 1.4228 Loss_G: 1.3096 D(x): 0.5670 D(G(z)): 0.5348 / 0.2796\n",
      "[6/20][65/95] Loss_D: 1.3884 Loss_G: 0.6723 D(x): 0.4066 D(G(z)): 0.3347 / 0.5216\n",
      "[6/20][66/95] Loss_D: 1.2163 Loss_G: 2.1855 D(x): 0.7678 D(G(z)): 0.5969 / 0.1309\n",
      "[6/20][67/95] Loss_D: 1.9226 Loss_G: 0.3784 D(x): 0.2099 D(G(z)): 0.1980 / 0.6928\n",
      "[6/20][68/95] Loss_D: 1.5907 Loss_G: 1.0247 D(x): 0.7443 D(G(z)): 0.7091 / 0.3734\n",
      "[6/20][69/95] Loss_D: 1.3262 Loss_G: 1.2408 D(x): 0.4865 D(G(z)): 0.4182 / 0.3030\n",
      "[6/20][70/95] Loss_D: 1.4095 Loss_G: 0.7722 D(x): 0.4176 D(G(z)): 0.3824 / 0.4735\n",
      "[6/20][71/95] Loss_D: 0.9646 Loss_G: 2.0845 D(x): 0.8261 D(G(z)): 0.5224 / 0.1453\n",
      "[6/20][72/95] Loss_D: 2.0233 Loss_G: 0.4188 D(x): 0.1945 D(G(z)): 0.2495 / 0.6643\n",
      "[6/20][73/95] Loss_D: 1.6421 Loss_G: 0.7756 D(x): 0.6559 D(G(z)): 0.6811 / 0.4691\n",
      "[6/20][74/95] Loss_D: 1.3848 Loss_G: 1.5685 D(x): 0.6013 D(G(z)): 0.5707 / 0.2361\n",
      "[6/20][75/95] Loss_D: 1.5135 Loss_G: 0.6234 D(x): 0.3271 D(G(z)): 0.2502 / 0.5527\n",
      "[6/20][76/95] Loss_D: 1.3860 Loss_G: 0.8281 D(x): 0.6632 D(G(z)): 0.6039 / 0.4475\n",
      "[6/20][77/95] Loss_D: 1.3008 Loss_G: 1.1506 D(x): 0.5781 D(G(z)): 0.5154 / 0.3314\n",
      "[6/20][78/95] Loss_D: 0.8786 Loss_G: 1.4571 D(x): 0.6490 D(G(z)): 0.3441 / 0.2506\n",
      "[6/20][79/95] Loss_D: 1.5174 Loss_G: 0.5412 D(x): 0.3616 D(G(z)): 0.3647 / 0.5875\n",
      "[6/20][80/95] Loss_D: 1.4501 Loss_G: 1.0523 D(x): 0.6828 D(G(z)): 0.6444 / 0.3581\n",
      "[6/20][81/95] Loss_D: 1.4511 Loss_G: 0.8030 D(x): 0.4347 D(G(z)): 0.4269 / 0.4536\n",
      "[6/20][82/95] Loss_D: 1.3344 Loss_G: 0.8349 D(x): 0.5355 D(G(z)): 0.4923 / 0.4387\n",
      "[6/20][83/95] Loss_D: 1.6995 Loss_G: 0.7602 D(x): 0.4731 D(G(z)): 0.5929 / 0.4718\n",
      "[6/20][84/95] Loss_D: 1.3361 Loss_G: 0.8268 D(x): 0.4939 D(G(z)): 0.4459 / 0.4462\n",
      "[6/20][85/95] Loss_D: 1.3719 Loss_G: 1.0562 D(x): 0.5783 D(G(z)): 0.5418 / 0.3585\n",
      "[6/20][86/95] Loss_D: 1.3102 Loss_G: 0.7987 D(x): 0.4539 D(G(z)): 0.3820 / 0.4556\n",
      "[6/20][87/95] Loss_D: 1.3217 Loss_G: 0.9679 D(x): 0.5632 D(G(z)): 0.5030 / 0.3886\n",
      "[6/20][88/95] Loss_D: 1.3147 Loss_G: 0.8803 D(x): 0.5144 D(G(z)): 0.4597 / 0.4191\n",
      "[6/20][89/95] Loss_D: 1.4865 Loss_G: 0.8050 D(x): 0.4784 D(G(z)): 0.5093 / 0.4538\n",
      "[6/20][90/95] Loss_D: 1.3431 Loss_G: 1.0194 D(x): 0.5215 D(G(z)): 0.4859 / 0.3692\n",
      "[6/20][91/95] Loss_D: 1.2537 Loss_G: 1.1180 D(x): 0.5110 D(G(z)): 0.4211 / 0.3418\n",
      "[6/20][92/95] Loss_D: 1.3885 Loss_G: 0.7346 D(x): 0.4633 D(G(z)): 0.4315 / 0.4892\n",
      "[6/20][93/95] Loss_D: 1.3275 Loss_G: 1.1426 D(x): 0.5912 D(G(z)): 0.5386 / 0.3294\n",
      "[6/20][94/95] Loss_D: 1.3612 Loss_G: 0.6884 D(x): 0.4163 D(G(z)): 0.3731 / 0.5097\n",
      "[7/20][0/95] Loss_D: 1.4689 Loss_G: 1.2053 D(x): 0.6309 D(G(z)): 0.5944 / 0.3224\n",
      "[7/20][1/95] Loss_D: 1.3867 Loss_G: 0.6694 D(x): 0.4162 D(G(z)): 0.3471 / 0.5222\n",
      "[7/20][2/95] Loss_D: 1.3700 Loss_G: 1.1938 D(x): 0.6444 D(G(z)): 0.5720 / 0.3233\n",
      "[7/20][3/95] Loss_D: 0.9242 Loss_G: 2.1756 D(x): 0.7249 D(G(z)): 0.4377 / 0.1282\n",
      "[7/20][4/95] Loss_D: 2.1510 Loss_G: 0.4309 D(x): 0.1721 D(G(z)): 0.1755 / 0.6609\n",
      "[7/20][5/95] Loss_D: 1.7499 Loss_G: 0.8060 D(x): 0.7164 D(G(z)): 0.7382 / 0.4524\n",
      "[7/20][6/95] Loss_D: 1.4299 Loss_G: 1.0810 D(x): 0.4975 D(G(z)): 0.4967 / 0.3461\n",
      "[7/20][7/95] Loss_D: 1.3613 Loss_G: 0.7070 D(x): 0.4399 D(G(z)): 0.3879 / 0.5023\n",
      "[7/20][8/95] Loss_D: 1.3398 Loss_G: 1.2934 D(x): 0.6604 D(G(z)): 0.5764 / 0.2931\n",
      "[7/20][9/95] Loss_D: 1.2887 Loss_G: 0.9303 D(x): 0.4509 D(G(z)): 0.3568 / 0.4025\n",
      "[7/20][10/95] Loss_D: 1.2119 Loss_G: 0.8495 D(x): 0.5542 D(G(z)): 0.4360 / 0.4354\n",
      "[7/20][11/95] Loss_D: 1.2145 Loss_G: 1.0539 D(x): 0.6052 D(G(z)): 0.4895 / 0.3575\n",
      "[7/20][12/95] Loss_D: 1.2590 Loss_G: 0.8967 D(x): 0.5152 D(G(z)): 0.4190 / 0.4191\n",
      "[7/20][13/95] Loss_D: 1.2702 Loss_G: 1.1937 D(x): 0.6047 D(G(z)): 0.4989 / 0.3133\n",
      "[7/20][14/95] Loss_D: 1.3952 Loss_G: 0.6557 D(x): 0.4010 D(G(z)): 0.3559 / 0.5249\n",
      "[7/20][15/95] Loss_D: 1.3624 Loss_G: 1.2899 D(x): 0.6999 D(G(z)): 0.6134 / 0.2935\n",
      "[7/20][16/95] Loss_D: 1.3358 Loss_G: 0.8260 D(x): 0.4096 D(G(z)): 0.3215 / 0.4475\n",
      "[7/20][17/95] Loss_D: 1.0375 Loss_G: 1.8730 D(x): 0.8003 D(G(z)): 0.5461 / 0.1727\n",
      "[7/20][18/95] Loss_D: 1.9222 Loss_G: 0.4556 D(x): 0.2062 D(G(z)): 0.1924 / 0.6456\n",
      "[7/20][19/95] Loss_D: 2.0845 Loss_G: 0.6692 D(x): 0.6939 D(G(z)): 0.7976 / 0.5234\n",
      "[7/20][20/95] Loss_D: 1.2257 Loss_G: 1.1791 D(x): 0.5021 D(G(z)): 0.3981 / 0.3178\n",
      "[7/20][21/95] Loss_D: 1.5793 Loss_G: 0.6801 D(x): 0.4276 D(G(z)): 0.4887 / 0.5233\n",
      "[7/20][22/95] Loss_D: 1.2643 Loss_G: 0.8621 D(x): 0.5583 D(G(z)): 0.4773 / 0.4384\n",
      "[7/20][23/95] Loss_D: 1.2670 Loss_G: 0.7927 D(x): 0.5362 D(G(z)): 0.4546 / 0.4597\n",
      "[7/20][24/95] Loss_D: 1.2490 Loss_G: 1.1928 D(x): 0.6815 D(G(z)): 0.5635 / 0.3130\n",
      "[7/20][25/95] Loss_D: 1.4186 Loss_G: 0.7349 D(x): 0.4150 D(G(z)): 0.3837 / 0.4909\n",
      "[7/20][26/95] Loss_D: 1.3265 Loss_G: 0.9147 D(x): 0.6199 D(G(z)): 0.5558 / 0.4089\n",
      "[7/20][27/95] Loss_D: 1.3626 Loss_G: 1.0176 D(x): 0.5101 D(G(z)): 0.4755 / 0.3695\n",
      "[7/20][28/95] Loss_D: 1.3380 Loss_G: 0.8953 D(x): 0.4973 D(G(z)): 0.4391 / 0.4160\n",
      "[7/20][29/95] Loss_D: 1.3446 Loss_G: 1.0508 D(x): 0.5325 D(G(z)): 0.4863 / 0.3631\n",
      "[7/20][30/95] Loss_D: 1.3072 Loss_G: 0.7900 D(x): 0.4653 D(G(z)): 0.3869 / 0.4659\n",
      "[7/20][31/95] Loss_D: 1.3283 Loss_G: 0.9126 D(x): 0.5905 D(G(z)): 0.5301 / 0.4130\n",
      "[7/20][32/95] Loss_D: 1.3711 Loss_G: 1.0024 D(x): 0.5397 D(G(z)): 0.4931 / 0.3789\n",
      "[7/20][33/95] Loss_D: 1.3562 Loss_G: 0.9055 D(x): 0.4889 D(G(z)): 0.4498 / 0.4146\n",
      "[7/20][34/95] Loss_D: 1.0781 Loss_G: 1.3608 D(x): 0.6328 D(G(z)): 0.4450 / 0.2680\n",
      "[7/20][35/95] Loss_D: 1.4239 Loss_G: 0.6266 D(x): 0.3857 D(G(z)): 0.3296 / 0.5423\n",
      "[7/20][36/95] Loss_D: 1.3251 Loss_G: 0.9459 D(x): 0.6342 D(G(z)): 0.5683 / 0.3956\n",
      "[7/20][37/95] Loss_D: 1.2701 Loss_G: 1.1718 D(x): 0.5430 D(G(z)): 0.4672 / 0.3217\n",
      "[7/20][38/95] Loss_D: 1.3770 Loss_G: 0.7036 D(x): 0.4133 D(G(z)): 0.3635 / 0.5037\n",
      "[7/20][39/95] Loss_D: 1.3634 Loss_G: 0.8398 D(x): 0.5884 D(G(z)): 0.5442 / 0.4429\n",
      "[7/20][40/95] Loss_D: 1.2908 Loss_G: 1.2318 D(x): 0.5764 D(G(z)): 0.5052 / 0.3107\n",
      "[7/20][41/95] Loss_D: 1.3910 Loss_G: 0.6877 D(x): 0.4198 D(G(z)): 0.3669 / 0.5123\n",
      "[7/20][42/95] Loss_D: 1.3328 Loss_G: 1.5930 D(x): 0.7036 D(G(z)): 0.6030 / 0.2249\n",
      "[7/20][43/95] Loss_D: 1.5583 Loss_G: 0.6428 D(x): 0.3102 D(G(z)): 0.2685 / 0.5345\n",
      "[7/20][44/95] Loss_D: 1.5202 Loss_G: 0.8723 D(x): 0.5930 D(G(z)): 0.6115 / 0.4322\n",
      "[7/20][45/95] Loss_D: 1.4111 Loss_G: 0.9060 D(x): 0.4645 D(G(z)): 0.4497 / 0.4165\n",
      "[7/20][46/95] Loss_D: 1.0610 Loss_G: 1.5898 D(x): 0.7381 D(G(z)): 0.5150 / 0.2289\n",
      "[7/20][47/95] Loss_D: 1.6039 Loss_G: 0.5605 D(x): 0.3128 D(G(z)): 0.2840 / 0.5800\n",
      "[7/20][48/95] Loss_D: 1.1648 Loss_G: 1.5852 D(x): 0.8817 D(G(z)): 0.6290 / 0.2242\n",
      "[7/20][49/95] Loss_D: 1.6649 Loss_G: 0.6461 D(x): 0.2743 D(G(z)): 0.2498 / 0.5312\n",
      "[7/20][50/95] Loss_D: 1.3823 Loss_G: 0.6533 D(x): 0.6007 D(G(z)): 0.5674 / 0.5278\n",
      "[7/20][51/95] Loss_D: 1.2366 Loss_G: 1.2735 D(x): 0.6878 D(G(z)): 0.5649 / 0.2912\n",
      "[7/20][52/95] Loss_D: 1.3574 Loss_G: 0.8410 D(x): 0.4525 D(G(z)): 0.3930 / 0.4406\n",
      "[7/20][53/95] Loss_D: 1.3451 Loss_G: 0.7463 D(x): 0.5391 D(G(z)): 0.4903 / 0.4888\n",
      "[7/20][54/95] Loss_D: 1.3438 Loss_G: 1.0500 D(x): 0.6033 D(G(z)): 0.5417 / 0.3643\n",
      "[7/20][55/95] Loss_D: 1.3507 Loss_G: 0.9790 D(x): 0.5000 D(G(z)): 0.4455 / 0.3877\n",
      "[7/20][56/95] Loss_D: 1.3132 Loss_G: 0.9229 D(x): 0.5182 D(G(z)): 0.4463 / 0.4051\n",
      "[7/20][57/95] Loss_D: 1.3144 Loss_G: 0.8730 D(x): 0.5212 D(G(z)): 0.4638 / 0.4287\n",
      "[7/20][58/95] Loss_D: 1.3633 Loss_G: 1.1167 D(x): 0.5481 D(G(z)): 0.5189 / 0.3402\n",
      "[7/20][59/95] Loss_D: 1.4986 Loss_G: 0.7278 D(x): 0.4125 D(G(z)): 0.4209 / 0.4937\n",
      "[7/20][60/95] Loss_D: 1.3605 Loss_G: 1.1396 D(x): 0.5909 D(G(z)): 0.5512 / 0.3346\n",
      "[7/20][61/95] Loss_D: 1.5397 Loss_G: 0.6417 D(x): 0.4061 D(G(z)): 0.4362 / 0.5373\n",
      "[7/20][62/95] Loss_D: 1.4730 Loss_G: 1.0522 D(x): 0.5975 D(G(z)): 0.5944 / 0.3640\n",
      "[7/20][63/95] Loss_D: 1.5088 Loss_G: 0.7918 D(x): 0.4140 D(G(z)): 0.4373 / 0.4598\n",
      "[7/20][64/95] Loss_D: 1.4530 Loss_G: 0.8059 D(x): 0.5048 D(G(z)): 0.5126 / 0.4577\n",
      "[7/20][65/95] Loss_D: 1.3543 Loss_G: 1.0727 D(x): 0.5529 D(G(z)): 0.5179 / 0.3518\n",
      "[7/20][66/95] Loss_D: 0.9215 Loss_G: 1.7375 D(x): 0.6747 D(G(z)): 0.3934 / 0.1881\n",
      "[7/20][67/95] Loss_D: 1.5907 Loss_G: 0.4954 D(x): 0.2950 D(G(z)): 0.2535 / 0.6206\n",
      "[7/20][68/95] Loss_D: 1.3647 Loss_G: 1.1018 D(x): 0.7140 D(G(z)): 0.6122 / 0.3460\n",
      "[7/20][69/95] Loss_D: 1.1814 Loss_G: 1.3152 D(x): 0.5845 D(G(z)): 0.4453 / 0.2818\n",
      "[7/20][70/95] Loss_D: 1.3950 Loss_G: 0.7771 D(x): 0.4400 D(G(z)): 0.3952 / 0.4761\n",
      "[7/20][71/95] Loss_D: 1.4472 Loss_G: 1.4932 D(x): 0.6493 D(G(z)): 0.6081 / 0.2441\n",
      "[7/20][72/95] Loss_D: 1.6408 Loss_G: 0.5539 D(x): 0.3023 D(G(z)): 0.3038 / 0.5818\n",
      "[7/20][73/95] Loss_D: 1.5451 Loss_G: 0.8921 D(x): 0.5813 D(G(z)): 0.6136 / 0.4299\n",
      "[7/20][74/95] Loss_D: 1.5241 Loss_G: 0.9660 D(x): 0.5271 D(G(z)): 0.5383 / 0.3991\n",
      "[7/20][75/95] Loss_D: 1.5199 Loss_G: 0.8121 D(x): 0.4326 D(G(z)): 0.4446 / 0.4590\n",
      "[7/20][76/95] Loss_D: 1.3396 Loss_G: 1.2645 D(x): 0.5657 D(G(z)): 0.5100 / 0.3072\n",
      "[7/20][77/95] Loss_D: 1.4228 Loss_G: 0.6800 D(x): 0.4538 D(G(z)): 0.4334 / 0.5136\n",
      "[7/20][78/95] Loss_D: 1.1892 Loss_G: 1.6521 D(x): 0.7482 D(G(z)): 0.5805 / 0.2020\n",
      "[7/20][79/95] Loss_D: 1.8574 Loss_G: 0.4328 D(x): 0.2278 D(G(z)): 0.2489 / 0.6592\n",
      "[7/20][80/95] Loss_D: 1.6466 Loss_G: 1.0476 D(x): 0.6935 D(G(z)): 0.6973 / 0.3602\n",
      "[7/20][81/95] Loss_D: 1.4854 Loss_G: 0.9617 D(x): 0.4181 D(G(z)): 0.4161 / 0.3923\n",
      "[7/20][82/95] Loss_D: 1.2757 Loss_G: 0.8118 D(x): 0.5204 D(G(z)): 0.4423 / 0.4514\n",
      "[7/20][83/95] Loss_D: 1.1372 Loss_G: 1.1341 D(x): 0.6479 D(G(z)): 0.4902 / 0.3310\n",
      "[7/20][84/95] Loss_D: 1.2689 Loss_G: 0.8521 D(x): 0.4729 D(G(z)): 0.3773 / 0.4347\n",
      "[7/20][85/95] Loss_D: 1.2559 Loss_G: 0.9404 D(x): 0.5807 D(G(z)): 0.4913 / 0.4013\n",
      "[7/20][86/95] Loss_D: 1.3078 Loss_G: 1.0440 D(x): 0.5483 D(G(z)): 0.4897 / 0.3633\n",
      "[7/20][87/95] Loss_D: 1.3939 Loss_G: 0.8862 D(x): 0.4681 D(G(z)): 0.4225 / 0.4254\n",
      "[7/20][88/95] Loss_D: 1.4004 Loss_G: 0.8302 D(x): 0.5004 D(G(z)): 0.4857 / 0.4482\n",
      "[7/20][89/95] Loss_D: 1.4743 Loss_G: 0.8081 D(x): 0.5366 D(G(z)): 0.5461 / 0.4603\n",
      "[7/20][90/95] Loss_D: 1.3067 Loss_G: 0.8799 D(x): 0.5344 D(G(z)): 0.4665 / 0.4242\n",
      "[7/20][91/95] Loss_D: 1.3630 Loss_G: 0.9231 D(x): 0.5285 D(G(z)): 0.4971 / 0.4052\n",
      "[7/20][92/95] Loss_D: 1.3244 Loss_G: 0.7413 D(x): 0.4641 D(G(z)): 0.3943 / 0.4906\n",
      "[7/20][93/95] Loss_D: 1.4146 Loss_G: 1.3595 D(x): 0.6167 D(G(z)): 0.5899 / 0.2716\n",
      "[7/20][94/95] Loss_D: 1.4370 Loss_G: 1.2442 D(x): 0.4148 D(G(z)): 0.3925 / 0.3162\n",
      "[8/20][0/95] Loss_D: 1.6808 Loss_G: 0.6447 D(x): 0.4553 D(G(z)): 0.5624 / 0.5321\n",
      "[8/20][1/95] Loss_D: 1.3813 Loss_G: 1.2942 D(x): 0.6021 D(G(z)): 0.5674 / 0.2893\n",
      "[8/20][2/95] Loss_D: 1.5208 Loss_G: 0.6715 D(x): 0.3701 D(G(z)): 0.3342 / 0.5217\n",
      "[8/20][3/95] Loss_D: 1.4550 Loss_G: 1.1545 D(x): 0.6392 D(G(z)): 0.6058 / 0.3276\n",
      "[8/20][4/95] Loss_D: 1.4857 Loss_G: 0.9525 D(x): 0.4438 D(G(z)): 0.4419 / 0.3969\n",
      "[8/20][5/95] Loss_D: 1.4362 Loss_G: 0.7694 D(x): 0.4336 D(G(z)): 0.4244 / 0.4791\n",
      "[8/20][6/95] Loss_D: 1.4590 Loss_G: 1.1601 D(x): 0.6245 D(G(z)): 0.6022 / 0.3307\n",
      "[8/20][7/95] Loss_D: 1.6833 Loss_G: 0.7250 D(x): 0.3524 D(G(z)): 0.4363 / 0.4967\n",
      "[8/20][8/95] Loss_D: 1.3513 Loss_G: 0.7644 D(x): 0.5287 D(G(z)): 0.4855 / 0.4781\n",
      "[8/20][9/95] Loss_D: 1.3444 Loss_G: 1.0587 D(x): 0.5988 D(G(z)): 0.5452 / 0.3616\n",
      "[8/20][10/95] Loss_D: 1.4162 Loss_G: 0.8388 D(x): 0.4433 D(G(z)): 0.4115 / 0.4474\n",
      "[8/20][11/95] Loss_D: 1.3651 Loss_G: 1.0766 D(x): 0.5933 D(G(z)): 0.5505 / 0.3534\n",
      "[8/20][12/95] Loss_D: 1.3980 Loss_G: 0.6921 D(x): 0.4359 D(G(z)): 0.4024 / 0.5139\n",
      "[8/20][13/95] Loss_D: 1.3356 Loss_G: 1.1055 D(x): 0.6321 D(G(z)): 0.5618 / 0.3457\n",
      "[8/20][14/95] Loss_D: 1.3118 Loss_G: 0.8892 D(x): 0.4635 D(G(z)): 0.3799 / 0.4280\n",
      "[8/20][15/95] Loss_D: 1.3534 Loss_G: 0.9509 D(x): 0.5659 D(G(z)): 0.5222 / 0.3992\n",
      "[8/20][16/95] Loss_D: 1.2558 Loss_G: 0.9608 D(x): 0.5274 D(G(z)): 0.4367 / 0.3919\n",
      "[8/20][17/95] Loss_D: 1.3850 Loss_G: 0.8287 D(x): 0.5119 D(G(z)): 0.4891 / 0.4490\n",
      "[8/20][18/95] Loss_D: 1.4020 Loss_G: 0.9293 D(x): 0.5474 D(G(z)): 0.5292 / 0.4088\n",
      "[8/20][19/95] Loss_D: 1.2242 Loss_G: 1.0139 D(x): 0.5469 D(G(z)): 0.4384 / 0.3723\n",
      "[8/20][20/95] Loss_D: 1.2918 Loss_G: 0.9593 D(x): 0.5271 D(G(z)): 0.4423 / 0.3948\n",
      "[8/20][21/95] Loss_D: 1.2369 Loss_G: 1.0273 D(x): 0.5736 D(G(z)): 0.4702 / 0.3671\n",
      "[8/20][22/95] Loss_D: 1.0797 Loss_G: 1.4792 D(x): 0.6725 D(G(z)): 0.4798 / 0.2398\n",
      "[8/20][23/95] Loss_D: 1.3503 Loss_G: 0.7430 D(x): 0.4170 D(G(z)): 0.3505 / 0.4829\n",
      "[8/20][24/95] Loss_D: 1.5412 Loss_G: 1.3068 D(x): 0.6199 D(G(z)): 0.6207 / 0.2812\n",
      "[8/20][25/95] Loss_D: 1.4190 Loss_G: 0.7674 D(x): 0.3808 D(G(z)): 0.3280 / 0.4757\n",
      "[8/20][26/95] Loss_D: 1.1379 Loss_G: 1.4683 D(x): 0.7137 D(G(z)): 0.5293 / 0.2493\n",
      "[8/20][27/95] Loss_D: 1.6378 Loss_G: 0.6347 D(x): 0.3173 D(G(z)): 0.3247 / 0.5445\n",
      "[8/20][28/95] Loss_D: 1.3202 Loss_G: 1.7039 D(x): 0.7658 D(G(z)): 0.6416 / 0.2116\n",
      "[8/20][29/95] Loss_D: 1.7934 Loss_G: 0.6432 D(x): 0.3061 D(G(z)): 0.3694 / 0.5406\n",
      "[8/20][30/95] Loss_D: 0.8314 Loss_G: 1.8437 D(x): 0.8935 D(G(z)): 0.4991 / 0.1837\n",
      "[8/20][31/95] Loss_D: 1.7435 Loss_G: 0.5023 D(x): 0.2715 D(G(z)): 0.2813 / 0.6170\n",
      "[8/20][32/95] Loss_D: 1.5506 Loss_G: 0.9838 D(x): 0.7282 D(G(z)): 0.6862 / 0.3829\n",
      "[8/20][33/95] Loss_D: 0.9895 Loss_G: 1.9087 D(x): 0.7243 D(G(z)): 0.4687 / 0.1616\n",
      "[8/20][34/95] Loss_D: 1.9248 Loss_G: 0.5632 D(x): 0.2235 D(G(z)): 0.2522 / 0.5801\n",
      "[8/20][35/95] Loss_D: 1.3627 Loss_G: 0.6011 D(x): 0.6013 D(G(z)): 0.5543 / 0.5627\n",
      "[8/20][36/95] Loss_D: 1.3480 Loss_G: 1.3409 D(x): 0.6918 D(G(z)): 0.5953 / 0.2779\n",
      "[8/20][37/95] Loss_D: 1.3334 Loss_G: 1.0353 D(x): 0.4441 D(G(z)): 0.3585 / 0.3695\n",
      "[8/20][38/95] Loss_D: 1.1358 Loss_G: 0.9573 D(x): 0.5871 D(G(z)): 0.4286 / 0.3952\n",
      "[8/20][39/95] Loss_D: 1.2376 Loss_G: 0.9625 D(x): 0.5605 D(G(z)): 0.4585 / 0.3922\n",
      "[8/20][40/95] Loss_D: 1.1878 Loss_G: 1.0574 D(x): 0.5527 D(G(z)): 0.4223 / 0.3736\n",
      "[8/20][41/95] Loss_D: 1.3335 Loss_G: 1.1915 D(x): 0.5956 D(G(z)): 0.5287 / 0.3219\n",
      "[8/20][42/95] Loss_D: 1.3952 Loss_G: 0.8252 D(x): 0.4329 D(G(z)): 0.4049 / 0.4470\n",
      "[8/20][43/95] Loss_D: 1.3464 Loss_G: 1.0453 D(x): 0.5576 D(G(z)): 0.5195 / 0.3610\n",
      "[8/20][44/95] Loss_D: 1.1660 Loss_G: 0.9879 D(x): 0.5234 D(G(z)): 0.3783 / 0.3789\n",
      "[8/20][45/95] Loss_D: 1.3157 Loss_G: 0.9955 D(x): 0.5475 D(G(z)): 0.4927 / 0.3813\n",
      "[8/20][46/95] Loss_D: 1.3459 Loss_G: 0.9537 D(x): 0.4925 D(G(z)): 0.4463 / 0.4001\n",
      "[8/20][47/95] Loss_D: 1.3646 Loss_G: 1.0006 D(x): 0.5177 D(G(z)): 0.4753 / 0.3883\n",
      "[8/20][48/95] Loss_D: 1.4211 Loss_G: 0.8535 D(x): 0.4812 D(G(z)): 0.4641 / 0.4427\n",
      "[8/20][49/95] Loss_D: 1.3846 Loss_G: 1.1998 D(x): 0.5476 D(G(z)): 0.5121 / 0.3234\n",
      "[8/20][50/95] Loss_D: 1.3545 Loss_G: 0.8719 D(x): 0.4894 D(G(z)): 0.4213 / 0.4325\n",
      "[8/20][51/95] Loss_D: 1.2720 Loss_G: 1.3196 D(x): 0.6103 D(G(z)): 0.5164 / 0.2864\n",
      "[8/20][52/95] Loss_D: 1.4421 Loss_G: 0.6742 D(x): 0.4028 D(G(z)): 0.3749 / 0.5221\n",
      "[8/20][53/95] Loss_D: 1.3874 Loss_G: 1.3099 D(x): 0.6074 D(G(z)): 0.5615 / 0.2945\n",
      "[8/20][54/95] Loss_D: 1.2797 Loss_G: 1.0525 D(x): 0.4762 D(G(z)): 0.3855 / 0.3695\n",
      "[8/20][55/95] Loss_D: 1.4650 Loss_G: 0.7515 D(x): 0.4457 D(G(z)): 0.4379 / 0.4928\n",
      "[8/20][56/95] Loss_D: 1.3513 Loss_G: 1.3010 D(x): 0.6642 D(G(z)): 0.5876 / 0.2854\n",
      "[8/20][57/95] Loss_D: 1.3969 Loss_G: 0.7628 D(x): 0.4052 D(G(z)): 0.3361 / 0.4737\n",
      "[8/20][58/95] Loss_D: 1.3884 Loss_G: 0.8922 D(x): 0.5901 D(G(z)): 0.5526 / 0.4207\n",
      "[8/20][59/95] Loss_D: 1.4432 Loss_G: 0.9210 D(x): 0.5156 D(G(z)): 0.5181 / 0.4063\n",
      "[8/20][60/95] Loss_D: 1.2466 Loss_G: 0.8950 D(x): 0.5220 D(G(z)): 0.4246 / 0.4178\n",
      "[8/20][61/95] Loss_D: 1.4622 Loss_G: 0.7882 D(x): 0.5028 D(G(z)): 0.5166 / 0.4646\n",
      "[8/20][62/95] Loss_D: 1.5172 Loss_G: 0.7203 D(x): 0.4660 D(G(z)): 0.5095 / 0.4970\n",
      "[8/20][63/95] Loss_D: 1.4582 Loss_G: 1.0765 D(x): 0.5636 D(G(z)): 0.5700 / 0.3479\n",
      "[8/20][64/95] Loss_D: 1.3475 Loss_G: 0.8334 D(x): 0.4616 D(G(z)): 0.4129 / 0.4443\n",
      "[8/20][65/95] Loss_D: 1.3810 Loss_G: 0.7904 D(x): 0.5255 D(G(z)): 0.4987 / 0.4614\n",
      "[8/20][66/95] Loss_D: 1.4182 Loss_G: 0.9830 D(x): 0.5548 D(G(z)): 0.5401 / 0.3835\n",
      "[8/20][67/95] Loss_D: 1.1582 Loss_G: 0.9301 D(x): 0.5114 D(G(z)): 0.3633 / 0.4071\n",
      "[8/20][68/95] Loss_D: 1.1889 Loss_G: 1.3921 D(x): 0.6520 D(G(z)): 0.5141 / 0.2601\n",
      "[8/20][69/95] Loss_D: 1.2526 Loss_G: 0.8638 D(x): 0.4759 D(G(z)): 0.3593 / 0.4366\n",
      "[8/20][70/95] Loss_D: 1.3444 Loss_G: 1.1442 D(x): 0.5840 D(G(z)): 0.5277 / 0.3276\n",
      "[8/20][71/95] Loss_D: 1.2870 Loss_G: 1.2910 D(x): 0.5493 D(G(z)): 0.4523 / 0.2998\n",
      "[8/20][72/95] Loss_D: 1.4770 Loss_G: 0.6048 D(x): 0.4262 D(G(z)): 0.4050 / 0.5565\n",
      "[8/20][73/95] Loss_D: 1.1806 Loss_G: 1.6944 D(x): 0.7912 D(G(z)): 0.5952 / 0.2000\n",
      "[8/20][74/95] Loss_D: 0.7049 Loss_G: 2.1427 D(x): 0.6621 D(G(z)): 0.2367 / 0.1328\n",
      "[8/20][75/95] Loss_D: 2.0353 Loss_G: 0.2741 D(x): 0.2039 D(G(z)): 0.2751 / 0.7679\n",
      "[8/20][76/95] Loss_D: 1.8744 Loss_G: 0.9094 D(x): 0.7405 D(G(z)): 0.7700 / 0.4218\n",
      "[8/20][77/95] Loss_D: 0.9877 Loss_G: 2.0493 D(x): 0.7708 D(G(z)): 0.5015 / 0.1546\n",
      "[8/20][78/95] Loss_D: 1.9417 Loss_G: 0.6994 D(x): 0.2144 D(G(z)): 0.1937 / 0.5265\n",
      "[8/20][79/95] Loss_D: 1.2969 Loss_G: 0.6157 D(x): 0.6462 D(G(z)): 0.5530 / 0.5524\n",
      "[8/20][80/95] Loss_D: 1.5716 Loss_G: 1.2689 D(x): 0.7234 D(G(z)): 0.6827 / 0.3064\n",
      "[8/20][81/95] Loss_D: 1.4728 Loss_G: 0.8943 D(x): 0.3653 D(G(z)): 0.2956 / 0.4228\n",
      "[8/20][82/95] Loss_D: 1.3514 Loss_G: 0.9754 D(x): 0.5935 D(G(z)): 0.5430 / 0.3870\n",
      "[8/20][83/95] Loss_D: 1.2734 Loss_G: 1.1144 D(x): 0.5462 D(G(z)): 0.4643 / 0.3404\n",
      "[8/20][84/95] Loss_D: 1.3509 Loss_G: 0.8112 D(x): 0.4800 D(G(z)): 0.4164 / 0.4581\n",
      "[8/20][85/95] Loss_D: 1.2689 Loss_G: 1.0680 D(x): 0.5755 D(G(z)): 0.4906 / 0.3607\n",
      "[8/20][86/95] Loss_D: 1.2185 Loss_G: 0.9415 D(x): 0.5337 D(G(z)): 0.4199 / 0.4042\n",
      "[8/20][87/95] Loss_D: 1.2598 Loss_G: 0.8737 D(x): 0.5519 D(G(z)): 0.4559 / 0.4273\n",
      "[8/20][88/95] Loss_D: 1.1958 Loss_G: 1.3128 D(x): 0.6505 D(G(z)): 0.5132 / 0.2878\n",
      "[8/20][89/95] Loss_D: 1.3547 Loss_G: 0.7431 D(x): 0.4326 D(G(z)): 0.3753 / 0.4872\n",
      "[8/20][90/95] Loss_D: 1.5306 Loss_G: 1.3981 D(x): 0.5918 D(G(z)): 0.6087 / 0.2655\n",
      "[8/20][91/95] Loss_D: 1.4956 Loss_G: 0.6838 D(x): 0.3539 D(G(z)): 0.3315 / 0.5168\n",
      "[8/20][92/95] Loss_D: 1.5320 Loss_G: 1.1259 D(x): 0.5813 D(G(z)): 0.6007 / 0.3468\n",
      "[8/20][93/95] Loss_D: 1.5154 Loss_G: 0.8526 D(x): 0.4176 D(G(z)): 0.4438 / 0.4361\n",
      "[8/20][94/95] Loss_D: 1.4000 Loss_G: 1.1698 D(x): 0.5161 D(G(z)): 0.4983 / 0.3328\n",
      "[9/20][0/95] Loss_D: 1.3341 Loss_G: 0.7687 D(x): 0.4874 D(G(z)): 0.4227 / 0.4698\n",
      "[9/20][1/95] Loss_D: 1.4561 Loss_G: 1.3283 D(x): 0.5717 D(G(z)): 0.5743 / 0.2761\n",
      "[9/20][2/95] Loss_D: 1.4856 Loss_G: 0.6616 D(x): 0.3804 D(G(z)): 0.3657 / 0.5271\n",
      "[9/20][3/95] Loss_D: 1.2679 Loss_G: 1.9086 D(x): 0.7492 D(G(z)): 0.6007 / 0.1753\n",
      "[9/20][4/95] Loss_D: 1.6085 Loss_G: 0.5294 D(x): 0.2834 D(G(z)): 0.2490 / 0.5960\n",
      "[9/20][5/95] Loss_D: 1.5278 Loss_G: 1.1173 D(x): 0.6877 D(G(z)): 0.6615 / 0.3473\n",
      "[9/20][6/95] Loss_D: 1.3272 Loss_G: 1.2689 D(x): 0.5175 D(G(z)): 0.4474 / 0.2940\n",
      "[9/20][7/95] Loss_D: 1.3427 Loss_G: 0.8155 D(x): 0.4354 D(G(z)): 0.3669 / 0.4532\n",
      "[9/20][8/95] Loss_D: 1.3383 Loss_G: 1.0201 D(x): 0.5982 D(G(z)): 0.5383 / 0.3750\n",
      "[9/20][9/95] Loss_D: 1.2845 Loss_G: 1.2359 D(x): 0.5767 D(G(z)): 0.4944 / 0.3062\n",
      "[9/20][10/95] Loss_D: 1.3945 Loss_G: 0.7549 D(x): 0.4354 D(G(z)): 0.4029 / 0.4818\n",
      "[9/20][11/95] Loss_D: 1.3225 Loss_G: 1.2913 D(x): 0.6234 D(G(z)): 0.5358 / 0.2964\n",
      "[9/20][12/95] Loss_D: 0.7930 Loss_G: 1.8301 D(x): 0.7395 D(G(z)): 0.3694 / 0.1835\n",
      "[9/20][13/95] Loss_D: 1.5692 Loss_G: 0.4391 D(x): 0.2972 D(G(z)): 0.2391 / 0.6639\n",
      "[9/20][14/95] Loss_D: 1.7051 Loss_G: 1.3184 D(x): 0.7680 D(G(z)): 0.7343 / 0.2831\n",
      "[9/20][15/95] Loss_D: 1.2587 Loss_G: 1.2060 D(x): 0.4501 D(G(z)): 0.3218 / 0.3132\n",
      "[9/20][16/95] Loss_D: 1.5037 Loss_G: 0.5929 D(x): 0.4245 D(G(z)): 0.4438 / 0.5635\n",
      "[9/20][17/95] Loss_D: 1.6257 Loss_G: 1.0333 D(x): 0.5856 D(G(z)): 0.6479 / 0.3704\n",
      "[9/20][18/95] Loss_D: 1.3497 Loss_G: 1.0748 D(x): 0.4013 D(G(z)): 0.3270 / 0.3750\n",
      "[9/20][19/95] Loss_D: 1.4230 Loss_G: 0.9878 D(x): 0.6067 D(G(z)): 0.5809 / 0.3892\n",
      "[9/20][20/95] Loss_D: 1.3665 Loss_G: 0.9522 D(x): 0.5078 D(G(z)): 0.4764 / 0.3949\n",
      "[9/20][21/95] Loss_D: 1.4302 Loss_G: 0.7920 D(x): 0.4810 D(G(z)): 0.4683 / 0.4752\n",
      "[9/20][22/95] Loss_D: 1.2624 Loss_G: 1.4679 D(x): 0.6859 D(G(z)): 0.5661 / 0.2454\n",
      "[9/20][23/95] Loss_D: 1.4460 Loss_G: 1.1062 D(x): 0.4790 D(G(z)): 0.4569 / 0.3453\n",
      "[9/20][24/95] Loss_D: 1.5327 Loss_G: 0.5672 D(x): 0.3903 D(G(z)): 0.3795 / 0.5841\n",
      "[9/20][25/95] Loss_D: 1.4833 Loss_G: 1.5499 D(x): 0.7132 D(G(z)): 0.6472 / 0.2274\n",
      "[9/20][26/95] Loss_D: 1.4087 Loss_G: 0.7959 D(x): 0.3814 D(G(z)): 0.3058 / 0.4608\n",
      "[9/20][27/95] Loss_D: 1.2739 Loss_G: 1.3378 D(x): 0.7058 D(G(z)): 0.5772 / 0.2760\n",
      "[9/20][28/95] Loss_D: 1.2994 Loss_G: 1.4526 D(x): 0.4722 D(G(z)): 0.3856 / 0.2419\n",
      "[9/20][29/95] Loss_D: 1.5258 Loss_G: 0.6192 D(x): 0.3707 D(G(z)): 0.3802 / 0.5467\n",
      "[9/20][30/95] Loss_D: 1.5205 Loss_G: 1.7579 D(x): 0.6388 D(G(z)): 0.6377 / 0.1980\n",
      "[9/20][31/95] Loss_D: 1.4796 Loss_G: 0.6007 D(x): 0.3566 D(G(z)): 0.2957 / 0.5569\n",
      "[9/20][32/95] Loss_D: 1.3637 Loss_G: 1.3206 D(x): 0.6780 D(G(z)): 0.6024 / 0.2906\n",
      "[9/20][33/95] Loss_D: 1.4259 Loss_G: 0.8054 D(x): 0.4127 D(G(z)): 0.3763 / 0.4709\n",
      "[9/20][34/95] Loss_D: 1.5138 Loss_G: 0.9011 D(x): 0.5500 D(G(z)): 0.5742 / 0.4238\n",
      "[9/20][35/95] Loss_D: 1.4114 Loss_G: 1.4170 D(x): 0.5472 D(G(z)): 0.5228 / 0.2696\n",
      "[9/20][36/95] Loss_D: 1.4629 Loss_G: 0.6445 D(x): 0.3874 D(G(z)): 0.3604 / 0.5387\n",
      "[9/20][37/95] Loss_D: 1.5140 Loss_G: 1.0079 D(x): 0.6095 D(G(z)): 0.6216 / 0.3756\n",
      "[9/20][38/95] Loss_D: 1.3514 Loss_G: 1.0409 D(x): 0.4976 D(G(z)): 0.4490 / 0.3626\n",
      "[9/20][39/95] Loss_D: 1.4750 Loss_G: 0.6517 D(x): 0.4435 D(G(z)): 0.4556 / 0.5341\n",
      "[9/20][40/95] Loss_D: 1.3396 Loss_G: 1.2451 D(x): 0.6613 D(G(z)): 0.5824 / 0.3031\n",
      "[9/20][41/95] Loss_D: 1.3603 Loss_G: 0.8080 D(x): 0.4339 D(G(z)): 0.3689 / 0.4620\n",
      "[9/20][42/95] Loss_D: 1.3915 Loss_G: 1.1542 D(x): 0.6187 D(G(z)): 0.5697 / 0.3305\n",
      "[9/20][43/95] Loss_D: 1.3735 Loss_G: 0.9899 D(x): 0.5015 D(G(z)): 0.4409 / 0.3853\n",
      "[9/20][44/95] Loss_D: 1.4330 Loss_G: 0.9294 D(x): 0.5261 D(G(z)): 0.5129 / 0.4073\n",
      "[9/20][45/95] Loss_D: 1.4514 Loss_G: 1.0939 D(x): 0.5286 D(G(z)): 0.5275 / 0.3467\n",
      "[9/20][46/95] Loss_D: 1.5302 Loss_G: 0.5579 D(x): 0.4104 D(G(z)): 0.4278 / 0.5831\n",
      "[9/20][47/95] Loss_D: 1.6540 Loss_G: 1.0056 D(x): 0.5955 D(G(z)): 0.6530 / 0.3748\n",
      "[9/20][48/95] Loss_D: 1.2927 Loss_G: 0.8853 D(x): 0.4921 D(G(z)): 0.4212 / 0.4181\n",
      "[9/20][49/95] Loss_D: 1.4317 Loss_G: 0.9062 D(x): 0.5450 D(G(z)): 0.5369 / 0.4149\n",
      "[9/20][50/95] Loss_D: 1.2184 Loss_G: 0.9463 D(x): 0.5326 D(G(z)): 0.4162 / 0.4019\n",
      "[9/20][51/95] Loss_D: 1.2897 Loss_G: 1.0278 D(x): 0.5702 D(G(z)): 0.4932 / 0.3746\n",
      "[9/20][52/95] Loss_D: 1.3729 Loss_G: 1.2296 D(x): 0.5627 D(G(z)): 0.5166 / 0.3096\n",
      "[9/20][53/95] Loss_D: 1.3056 Loss_G: 0.6756 D(x): 0.4489 D(G(z)): 0.3677 / 0.5181\n",
      "[9/20][54/95] Loss_D: 1.3514 Loss_G: 1.2414 D(x): 0.6406 D(G(z)): 0.5677 / 0.3063\n",
      "[9/20][55/95] Loss_D: 1.3235 Loss_G: 0.9149 D(x): 0.4696 D(G(z)): 0.3912 / 0.4143\n",
      "[9/20][56/95] Loss_D: 1.4132 Loss_G: 0.8506 D(x): 0.5128 D(G(z)): 0.4967 / 0.4357\n",
      "[9/20][57/95] Loss_D: 1.2992 Loss_G: 1.6226 D(x): 0.6294 D(G(z)): 0.5407 / 0.2160\n",
      "[9/20][58/95] Loss_D: 1.3137 Loss_G: 0.8700 D(x): 0.3948 D(G(z)): 0.2729 / 0.4344\n",
      "[9/20][59/95] Loss_D: 1.5066 Loss_G: 1.2805 D(x): 0.5411 D(G(z)): 0.5694 / 0.3008\n",
      "[9/20][60/95] Loss_D: 1.3833 Loss_G: 1.0064 D(x): 0.4509 D(G(z)): 0.3962 / 0.3868\n",
      "[9/20][61/95] Loss_D: 1.1122 Loss_G: 1.5433 D(x): 0.6301 D(G(z)): 0.4501 / 0.2406\n",
      "[9/20][62/95] Loss_D: 1.4531 Loss_G: 0.4631 D(x): 0.3661 D(G(z)): 0.2939 / 0.6376\n",
      "[9/20][63/95] Loss_D: 1.3424 Loss_G: 2.5467 D(x): 0.8982 D(G(z)): 0.6879 / 0.0922\n",
      "[9/20][64/95] Loss_D: 1.9873 Loss_G: 0.6743 D(x): 0.1834 D(G(z)): 0.1443 / 0.5212\n",
      "[9/20][65/95] Loss_D: 1.4134 Loss_G: 0.6727 D(x): 0.6349 D(G(z)): 0.5956 / 0.5215\n",
      "[9/20][66/95] Loss_D: 1.4333 Loss_G: 1.3810 D(x): 0.6375 D(G(z)): 0.6120 / 0.2671\n",
      "[9/20][67/95] Loss_D: 1.6623 Loss_G: 0.5767 D(x): 0.3091 D(G(z)): 0.3272 / 0.5756\n",
      "[9/20][68/95] Loss_D: 1.4426 Loss_G: 0.9171 D(x): 0.6548 D(G(z)): 0.6226 / 0.4102\n",
      "[9/20][69/95] Loss_D: 1.4041 Loss_G: 0.9563 D(x): 0.5130 D(G(z)): 0.4939 / 0.3948\n",
      "[9/20][70/95] Loss_D: 1.4509 Loss_G: 0.6719 D(x): 0.4027 D(G(z)): 0.3845 / 0.5219\n",
      "[9/20][71/95] Loss_D: 1.2245 Loss_G: 1.2781 D(x): 0.7122 D(G(z)): 0.5684 / 0.2935\n",
      "[9/20][72/95] Loss_D: 1.4568 Loss_G: 0.7056 D(x): 0.3601 D(G(z)): 0.3173 / 0.5043\n",
      "[9/20][73/95] Loss_D: 1.2166 Loss_G: 1.1961 D(x): 0.7728 D(G(z)): 0.5992 / 0.3116\n",
      "[9/20][74/95] Loss_D: 1.5203 Loss_G: 0.7472 D(x): 0.3443 D(G(z)): 0.3290 / 0.4784\n",
      "[9/20][75/95] Loss_D: 1.3065 Loss_G: 0.6886 D(x): 0.5387 D(G(z)): 0.4836 / 0.5090\n",
      "[9/20][76/95] Loss_D: 1.3867 Loss_G: 0.9143 D(x): 0.5990 D(G(z)): 0.5644 / 0.4130\n",
      "[9/20][77/95] Loss_D: 1.1901 Loss_G: 1.0439 D(x): 0.5445 D(G(z)): 0.4202 / 0.3642\n",
      "[9/20][78/95] Loss_D: 1.3619 Loss_G: 0.7620 D(x): 0.4867 D(G(z)): 0.4476 / 0.4750\n",
      "[9/20][79/95] Loss_D: 1.3176 Loss_G: 0.9150 D(x): 0.5909 D(G(z)): 0.5298 / 0.4075\n",
      "[9/20][80/95] Loss_D: 1.2474 Loss_G: 0.8278 D(x): 0.5104 D(G(z)): 0.4190 / 0.4479\n",
      "[9/20][81/95] Loss_D: 1.3546 Loss_G: 0.9924 D(x): 0.5732 D(G(z)): 0.5319 / 0.3786\n",
      "[9/20][82/95] Loss_D: 1.3795 Loss_G: 0.7243 D(x): 0.4304 D(G(z)): 0.3890 / 0.4916\n",
      "[9/20][83/95] Loss_D: 1.2971 Loss_G: 0.8922 D(x): 0.5830 D(G(z)): 0.5109 / 0.4163\n",
      "[9/20][84/95] Loss_D: 0.9854 Loss_G: 1.6891 D(x): 0.7528 D(G(z)): 0.4959 / 0.1980\n",
      "[9/20][85/95] Loss_D: 1.8072 Loss_G: 0.4662 D(x): 0.2362 D(G(z)): 0.2432 / 0.6367\n",
      "[9/20][86/95] Loss_D: 1.4745 Loss_G: 0.8517 D(x): 0.6952 D(G(z)): 0.6451 / 0.4345\n",
      "[9/20][87/95] Loss_D: 1.4003 Loss_G: 1.1860 D(x): 0.5216 D(G(z)): 0.5100 / 0.3165\n",
      "[9/20][88/95] Loss_D: 1.4204 Loss_G: 0.6699 D(x): 0.3834 D(G(z)): 0.3294 / 0.5225\n",
      "[9/20][89/95] Loss_D: 1.4233 Loss_G: 0.9561 D(x): 0.5935 D(G(z)): 0.5699 / 0.3918\n",
      "[9/20][90/95] Loss_D: 1.3298 Loss_G: 0.9976 D(x): 0.4976 D(G(z)): 0.4526 / 0.3783\n",
      "[9/20][91/95] Loss_D: 1.2898 Loss_G: 0.7894 D(x): 0.4805 D(G(z)): 0.4000 / 0.4610\n",
      "[9/20][92/95] Loss_D: 1.3534 Loss_G: 0.9672 D(x): 0.5754 D(G(z)): 0.5415 / 0.3940\n",
      "[9/20][93/95] Loss_D: 1.2980 Loss_G: 0.8247 D(x): 0.4893 D(G(z)): 0.4298 / 0.4473\n",
      "[9/20][94/95] Loss_D: 1.0231 Loss_G: 1.3262 D(x): 0.5694 D(G(z)): 0.3510 / 0.2697\n",
      "[10/20][0/95] Loss_D: 1.4623 Loss_G: 0.7804 D(x): 0.5784 D(G(z)): 0.5570 / 0.4716\n",
      "[10/20][1/95] Loss_D: 1.4018 Loss_G: 0.9916 D(x): 0.5439 D(G(z)): 0.5298 / 0.3815\n",
      "[10/20][2/95] Loss_D: 1.4717 Loss_G: 0.6741 D(x): 0.4132 D(G(z)): 0.4174 / 0.5183\n",
      "[10/20][3/95] Loss_D: 1.3561 Loss_G: 0.9331 D(x): 0.5937 D(G(z)): 0.5506 / 0.4043\n",
      "[10/20][4/95] Loss_D: 1.3818 Loss_G: 0.8919 D(x): 0.4853 D(G(z)): 0.4647 / 0.4181\n",
      "[10/20][5/95] Loss_D: 1.4665 Loss_G: 0.7355 D(x): 0.4603 D(G(z)): 0.4734 / 0.4863\n",
      "[10/20][6/95] Loss_D: 1.1542 Loss_G: 1.7822 D(x): 0.7200 D(G(z)): 0.5410 / 0.1790\n",
      "[10/20][7/95] Loss_D: 1.5762 Loss_G: 0.6478 D(x): 0.2784 D(G(z)): 0.2182 / 0.5283\n",
      "[10/20][8/95] Loss_D: 1.3218 Loss_G: 0.8006 D(x): 0.6181 D(G(z)): 0.5567 / 0.4541\n",
      "[10/20][9/95] Loss_D: 1.4291 Loss_G: 1.3444 D(x): 0.5750 D(G(z)): 0.5690 / 0.2716\n",
      "[10/20][10/95] Loss_D: 1.2516 Loss_G: 0.8683 D(x): 0.4210 D(G(z)): 0.3056 / 0.4262\n",
      "[10/20][11/95] Loss_D: 1.2529 Loss_G: 0.7712 D(x): 0.5538 D(G(z)): 0.4725 / 0.4691\n",
      "[10/20][12/95] Loss_D: 1.2187 Loss_G: 1.2277 D(x): 0.6222 D(G(z)): 0.5099 / 0.3051\n",
      "[10/20][13/95] Loss_D: 1.2278 Loss_G: 0.8651 D(x): 0.4786 D(G(z)): 0.3457 / 0.4329\n",
      "[10/20][14/95] Loss_D: 1.3653 Loss_G: 0.8258 D(x): 0.5729 D(G(z)): 0.5388 / 0.4466\n",
      "[10/20][15/95] Loss_D: 1.3038 Loss_G: 1.2261 D(x): 0.6207 D(G(z)): 0.5433 / 0.3053\n",
      "[10/20][16/95] Loss_D: 1.4396 Loss_G: 0.5690 D(x): 0.3611 D(G(z)): 0.3027 / 0.5766\n",
      "[10/20][17/95] Loss_D: 1.1057 Loss_G: 1.9692 D(x): 0.9180 D(G(z)): 0.6269 / 0.1487\n",
      "[10/20][18/95] Loss_D: 1.8542 Loss_G: 0.5919 D(x): 0.2169 D(G(z)): 0.1919 / 0.5625\n",
      "[10/20][19/95] Loss_D: 1.1279 Loss_G: 1.1428 D(x): 0.8445 D(G(z)): 0.5985 / 0.3283\n",
      "[10/20][20/95] Loss_D: 1.5785 Loss_G: 1.0006 D(x): 0.4476 D(G(z)): 0.5129 / 0.3801\n",
      "[10/20][21/95] Loss_D: 1.4464 Loss_G: 0.5838 D(x): 0.3847 D(G(z)): 0.3481 / 0.5652\n",
      "[10/20][22/95] Loss_D: 1.4570 Loss_G: 0.9098 D(x): 0.6827 D(G(z)): 0.6297 / 0.4142\n",
      "[10/20][23/95] Loss_D: 1.3346 Loss_G: 0.8584 D(x): 0.4837 D(G(z)): 0.4401 / 0.4347\n",
      "[10/20][24/95] Loss_D: 1.2298 Loss_G: 0.9199 D(x): 0.5950 D(G(z)): 0.4854 / 0.4077\n",
      "[10/20][25/95] Loss_D: 1.1393 Loss_G: 1.1755 D(x): 0.5954 D(G(z)): 0.4416 / 0.3189\n",
      "[10/20][26/95] Loss_D: 1.4407 Loss_G: 0.7532 D(x): 0.4294 D(G(z)): 0.4208 / 0.4804\n",
      "[10/20][27/95] Loss_D: 1.1264 Loss_G: 1.0646 D(x): 0.6412 D(G(z)): 0.4844 / 0.3531\n",
      "[10/20][28/95] Loss_D: 1.2296 Loss_G: 1.0998 D(x): 0.5558 D(G(z)): 0.4583 / 0.3427\n",
      "[10/20][29/95] Loss_D: 1.1557 Loss_G: 0.8546 D(x): 0.5163 D(G(z)): 0.3733 / 0.4379\n",
      "[10/20][30/95] Loss_D: 1.3542 Loss_G: 1.0482 D(x): 0.5983 D(G(z)): 0.5517 / 0.3620\n",
      "[10/20][31/95] Loss_D: 1.3461 Loss_G: 0.7168 D(x): 0.4417 D(G(z)): 0.3845 / 0.4961\n",
      "[10/20][32/95] Loss_D: 1.2524 Loss_G: 1.5763 D(x): 0.7138 D(G(z)): 0.5824 / 0.2159\n",
      "[10/20][33/95] Loss_D: 1.4461 Loss_G: 0.6705 D(x): 0.3388 D(G(z)): 0.2577 / 0.5254\n",
      "[10/20][34/95] Loss_D: 1.4299 Loss_G: 1.1982 D(x): 0.6836 D(G(z)): 0.6341 / 0.3116\n",
      "[10/20][35/95] Loss_D: 1.4576 Loss_G: 0.8542 D(x): 0.4117 D(G(z)): 0.3999 / 0.4346\n",
      "[10/20][36/95] Loss_D: 1.3350 Loss_G: 0.8211 D(x): 0.5259 D(G(z)): 0.4771 / 0.4497\n",
      "[10/20][37/95] Loss_D: 1.4448 Loss_G: 1.3940 D(x): 0.5645 D(G(z)): 0.5695 / 0.2630\n",
      "[10/20][38/95] Loss_D: 1.2632 Loss_G: 0.8057 D(x): 0.4369 D(G(z)): 0.3084 / 0.4571\n",
      "[10/20][39/95] Loss_D: 1.5369 Loss_G: 0.9643 D(x): 0.5278 D(G(z)): 0.5782 / 0.3980\n",
      "[10/20][40/95] Loss_D: 1.3477 Loss_G: 1.2975 D(x): 0.5322 D(G(z)): 0.4785 / 0.2931\n",
      "[10/20][41/95] Loss_D: 1.4168 Loss_G: 0.6778 D(x): 0.4379 D(G(z)): 0.3897 / 0.5197\n",
      "[10/20][42/95] Loss_D: 1.3135 Loss_G: 1.4340 D(x): 0.6605 D(G(z)): 0.5707 / 0.2578\n",
      "[10/20][43/95] Loss_D: 1.2355 Loss_G: 0.9089 D(x): 0.4914 D(G(z)): 0.3703 / 0.4176\n",
      "[10/20][44/95] Loss_D: 1.3337 Loss_G: 0.7980 D(x): 0.5368 D(G(z)): 0.4874 / 0.4598\n",
      "[10/20][45/95] Loss_D: 1.2841 Loss_G: 1.3763 D(x): 0.6557 D(G(z)): 0.5604 / 0.2740\n",
      "[10/20][46/95] Loss_D: 1.4934 Loss_G: 0.7170 D(x): 0.4187 D(G(z)): 0.4148 / 0.4972\n",
      "[10/20][47/95] Loss_D: 1.4474 Loss_G: 1.1018 D(x): 0.5895 D(G(z)): 0.5714 / 0.3461\n",
      "[10/20][48/95] Loss_D: 1.3248 Loss_G: 1.0320 D(x): 0.4868 D(G(z)): 0.4214 / 0.3668\n",
      "[10/20][49/95] Loss_D: 1.2828 Loss_G: 1.1086 D(x): 0.5618 D(G(z)): 0.4763 / 0.3410\n",
      "[10/20][50/95] Loss_D: 1.0877 Loss_G: 1.1749 D(x): 0.5898 D(G(z)): 0.3981 / 0.3229\n",
      "[10/20][51/95] Loss_D: 1.3842 Loss_G: 1.0372 D(x): 0.4976 D(G(z)): 0.4662 / 0.3660\n",
      "[10/20][52/95] Loss_D: 0.7849 Loss_G: 2.9400 D(x): 0.8807 D(G(z)): 0.4650 / 0.0640\n",
      "[10/20][53/95] Loss_D: 2.2408 Loss_G: 0.3456 D(x): 0.1361 D(G(z)): 0.0993 / 0.7166\n",
      "[10/20][54/95] Loss_D: 1.5478 Loss_G: 1.2625 D(x): 0.8333 D(G(z)): 0.7261 / 0.3016\n",
      "[10/20][55/95] Loss_D: 1.0788 Loss_G: 1.9836 D(x): 0.6194 D(G(z)): 0.4232 / 0.1574\n",
      "[10/20][56/95] Loss_D: 1.8394 Loss_G: 0.5218 D(x): 0.2652 D(G(z)): 0.3003 / 0.6093\n",
      "[10/20][57/95] Loss_D: 1.5727 Loss_G: 0.9210 D(x): 0.6074 D(G(z)): 0.6265 / 0.4193\n",
      "[10/20][58/95] Loss_D: 1.4829 Loss_G: 1.4028 D(x): 0.5338 D(G(z)): 0.5356 / 0.2731\n",
      "[10/20][59/95] Loss_D: 1.7246 Loss_G: 0.5805 D(x): 0.3059 D(G(z)): 0.3652 / 0.5706\n",
      "[10/20][60/95] Loss_D: 1.5635 Loss_G: 0.9780 D(x): 0.6455 D(G(z)): 0.6591 / 0.3946\n",
      "[10/20][61/95] Loss_D: 1.4556 Loss_G: 0.7997 D(x): 0.4098 D(G(z)): 0.3974 / 0.4671\n",
      "[10/20][62/95] Loss_D: 1.2524 Loss_G: 0.9067 D(x): 0.5665 D(G(z)): 0.4773 / 0.4157\n",
      "[10/20][63/95] Loss_D: 1.2948 Loss_G: 1.1963 D(x): 0.6318 D(G(z)): 0.5551 / 0.3129\n",
      "[10/20][64/95] Loss_D: 1.2335 Loss_G: 0.9079 D(x): 0.4987 D(G(z)): 0.3915 / 0.4128\n",
      "[10/20][65/95] Loss_D: 1.0473 Loss_G: 0.9340 D(x): 0.5929 D(G(z)): 0.3992 / 0.4052\n",
      "[10/20][66/95] Loss_D: 1.2374 Loss_G: 1.1088 D(x): 0.6359 D(G(z)): 0.5288 / 0.3393\n",
      "[10/20][67/95] Loss_D: 1.3309 Loss_G: 0.9516 D(x): 0.4793 D(G(z)): 0.4212 / 0.3940\n",
      "[10/20][68/95] Loss_D: 1.2538 Loss_G: 1.0617 D(x): 0.5773 D(G(z)): 0.4768 / 0.3586\n",
      "[10/20][69/95] Loss_D: 1.3609 Loss_G: 1.0758 D(x): 0.5062 D(G(z)): 0.4575 / 0.3551\n",
      "[10/20][70/95] Loss_D: 1.3573 Loss_G: 1.0783 D(x): 0.5202 D(G(z)): 0.4678 / 0.3502\n",
      "[10/20][71/95] Loss_D: 1.1894 Loss_G: 1.5453 D(x): 0.6085 D(G(z)): 0.4764 / 0.2265\n",
      "[10/20][72/95] Loss_D: 1.6550 Loss_G: 0.5112 D(x): 0.2970 D(G(z)): 0.2789 / 0.6192\n",
      "[10/20][73/95] Loss_D: 1.8449 Loss_G: 1.7531 D(x): 0.7225 D(G(z)): 0.7518 / 0.1891\n",
      "[10/20][74/95] Loss_D: 1.0333 Loss_G: 1.4414 D(x): 0.4625 D(G(z)): 0.2116 / 0.2515\n",
      "[10/20][75/95] Loss_D: 1.2063 Loss_G: 0.5241 D(x): 0.4595 D(G(z)): 0.3228 / 0.6109\n",
      "[10/20][76/95] Loss_D: 1.4196 Loss_G: 1.6255 D(x): 0.7902 D(G(z)): 0.6672 / 0.2188\n",
      "[10/20][77/95] Loss_D: 1.2994 Loss_G: 1.1049 D(x): 0.4348 D(G(z)): 0.3202 / 0.3584\n",
      "[10/20][78/95] Loss_D: 0.9360 Loss_G: 1.7263 D(x): 0.7637 D(G(z)): 0.4678 / 0.1977\n",
      "[10/20][79/95] Loss_D: 1.8964 Loss_G: 0.6278 D(x): 0.2997 D(G(z)): 0.4530 / 0.5477\n",
      "[10/20][80/95] Loss_D: 1.7763 Loss_G: 0.4873 D(x): 0.3840 D(G(z)): 0.5228 / 0.6285\n",
      "[10/20][81/95] Loss_D: 1.5830 Loss_G: 1.0000 D(x): 0.6093 D(G(z)): 0.6347 / 0.3856\n",
      "[10/20][82/95] Loss_D: 1.5199 Loss_G: 1.0348 D(x): 0.4665 D(G(z)): 0.4960 / 0.3748\n",
      "[10/20][83/95] Loss_D: 1.5119 Loss_G: 0.8210 D(x): 0.4521 D(G(z)): 0.4898 / 0.4591\n",
      "[10/20][84/95] Loss_D: 1.3680 Loss_G: 0.8178 D(x): 0.5067 D(G(z)): 0.4611 / 0.4521\n",
      "[10/20][85/95] Loss_D: 1.1538 Loss_G: 1.1980 D(x): 0.6245 D(G(z)): 0.4718 / 0.3188\n",
      "[10/20][86/95] Loss_D: 1.2748 Loss_G: 0.9301 D(x): 0.4958 D(G(z)): 0.3992 / 0.4110\n",
      "[10/20][87/95] Loss_D: 1.3293 Loss_G: 1.2292 D(x): 0.6045 D(G(z)): 0.5283 / 0.3149\n",
      "[10/20][88/95] Loss_D: 1.3779 Loss_G: 0.7558 D(x): 0.4480 D(G(z)): 0.4136 / 0.4794\n",
      "[10/20][89/95] Loss_D: 1.3181 Loss_G: 0.8284 D(x): 0.5658 D(G(z)): 0.5035 / 0.4438\n",
      "[10/20][90/95] Loss_D: 1.5344 Loss_G: 0.8817 D(x): 0.4866 D(G(z)): 0.5354 / 0.4194\n",
      "[10/20][91/95] Loss_D: 1.2983 Loss_G: 0.9442 D(x): 0.5054 D(G(z)): 0.4359 / 0.3945\n",
      "[10/20][92/95] Loss_D: 1.2631 Loss_G: 0.9934 D(x): 0.5667 D(G(z)): 0.4789 / 0.3785\n",
      "[10/20][93/95] Loss_D: 1.2700 Loss_G: 1.1125 D(x): 0.5715 D(G(z)): 0.4903 / 0.3368\n",
      "[10/20][94/95] Loss_D: 1.6415 Loss_G: 1.1070 D(x): 0.4438 D(G(z)): 0.5031 / 0.3395\n",
      "[11/20][0/95] Loss_D: 1.4010 Loss_G: 0.8498 D(x): 0.4465 D(G(z)): 0.4013 / 0.4378\n",
      "[11/20][1/95] Loss_D: 1.3800 Loss_G: 0.8481 D(x): 0.5510 D(G(z)): 0.5250 / 0.4395\n",
      "[11/20][2/95] Loss_D: 1.3397 Loss_G: 0.9965 D(x): 0.5306 D(G(z)): 0.4867 / 0.3763\n",
      "[11/20][3/95] Loss_D: 1.2737 Loss_G: 0.9028 D(x): 0.5102 D(G(z)): 0.4355 / 0.4126\n",
      "[11/20][4/95] Loss_D: 1.1600 Loss_G: 1.6589 D(x): 0.6703 D(G(z)): 0.5187 / 0.2046\n",
      "[11/20][5/95] Loss_D: 1.1885 Loss_G: 0.7325 D(x): 0.4426 D(G(z)): 0.2635 / 0.4948\n",
      "[11/20][6/95] Loss_D: 1.3445 Loss_G: 0.8777 D(x): 0.5736 D(G(z)): 0.5247 / 0.4298\n",
      "[11/20][7/95] Loss_D: 1.4042 Loss_G: 1.3980 D(x): 0.5978 D(G(z)): 0.5626 / 0.2688\n",
      "[11/20][8/95] Loss_D: 1.4872 Loss_G: 0.6866 D(x): 0.3782 D(G(z)): 0.3534 / 0.5155\n",
      "[11/20][9/95] Loss_D: 1.3475 Loss_G: 1.1772 D(x): 0.6337 D(G(z)): 0.5737 / 0.3195\n",
      "[11/20][10/95] Loss_D: 1.3905 Loss_G: 0.6952 D(x): 0.4282 D(G(z)): 0.3956 / 0.5106\n",
      "[11/20][11/95] Loss_D: 1.1577 Loss_G: 1.9541 D(x): 0.7245 D(G(z)): 0.5515 / 0.1564\n",
      "[11/20][12/95] Loss_D: 1.4559 Loss_G: 0.4743 D(x): 0.3194 D(G(z)): 0.2250 / 0.6291\n",
      "[11/20][13/95] Loss_D: 1.5235 Loss_G: 1.2890 D(x): 0.7070 D(G(z)): 0.6810 / 0.2831\n",
      "[11/20][14/95] Loss_D: 1.2438 Loss_G: 1.0918 D(x): 0.4400 D(G(z)): 0.3254 / 0.3578\n",
      "[11/20][15/95] Loss_D: 1.3939 Loss_G: 0.7144 D(x): 0.4880 D(G(z)): 0.4733 / 0.5049\n",
      "[11/20][16/95] Loss_D: 1.3365 Loss_G: 1.4860 D(x): 0.6555 D(G(z)): 0.5831 / 0.2408\n",
      "[11/20][17/95] Loss_D: 1.4840 Loss_G: 0.4524 D(x): 0.3492 D(G(z)): 0.3019 / 0.6428\n",
      "[11/20][18/95] Loss_D: 1.5587 Loss_G: 1.8739 D(x): 0.7202 D(G(z)): 0.6850 / 0.1645\n",
      "[11/20][19/95] Loss_D: 1.4848 Loss_G: 0.6985 D(x): 0.3377 D(G(z)): 0.2689 / 0.5099\n",
      "[11/20][20/95] Loss_D: 1.1856 Loss_G: 1.2858 D(x): 0.7126 D(G(z)): 0.5502 / 0.2909\n",
      "[11/20][21/95] Loss_D: 1.1080 Loss_G: 1.3219 D(x): 0.5517 D(G(z)): 0.3730 / 0.2768\n",
      "[11/20][22/95] Loss_D: 1.3572 Loss_G: 0.5532 D(x): 0.4296 D(G(z)): 0.3595 / 0.5862\n",
      "[11/20][23/95] Loss_D: 1.5588 Loss_G: 1.4171 D(x): 0.6636 D(G(z)): 0.6542 / 0.2647\n",
      "[11/20][24/95] Loss_D: 0.7554 Loss_G: 2.3869 D(x): 0.7291 D(G(z)): 0.3401 / 0.1128\n",
      "[11/20][25/95] Loss_D: 1.7823 Loss_G: 0.2824 D(x): 0.2218 D(G(z)): 0.1651 / 0.7595\n",
      "[11/20][26/95] Loss_D: 1.9908 Loss_G: 0.7185 D(x): 0.7510 D(G(z)): 0.7916 / 0.4918\n",
      "[11/20][27/95] Loss_D: 1.4540 Loss_G: 1.2225 D(x): 0.5069 D(G(z)): 0.5267 / 0.3030\n",
      "[11/20][28/95] Loss_D: 0.7688 Loss_G: 1.5541 D(x): 0.7059 D(G(z)): 0.3341 / 0.2177\n",
      "[11/20][29/95] Loss_D: 1.3758 Loss_G: 0.5623 D(x): 0.3564 D(G(z)): 0.2753 / 0.5823\n",
      "[11/20][30/95] Loss_D: 2.1856 Loss_G: 0.5616 D(x): 0.6267 D(G(z)): 0.7924 / 0.5761\n",
      "[11/20][31/95] Loss_D: 1.2972 Loss_G: 0.8842 D(x): 0.4655 D(G(z)): 0.3933 / 0.4214\n",
      "[11/20][32/95] Loss_D: 1.4291 Loss_G: 0.6631 D(x): 0.4751 D(G(z)): 0.4775 / 0.5263\n",
      "[11/20][33/95] Loss_D: 1.3588 Loss_G: 1.0657 D(x): 0.6116 D(G(z)): 0.5656 / 0.3556\n",
      "[11/20][34/95] Loss_D: 1.3289 Loss_G: 0.8260 D(x): 0.4545 D(G(z)): 0.4007 / 0.4530\n",
      "[11/20][35/95] Loss_D: 1.4167 Loss_G: 0.9711 D(x): 0.5551 D(G(z)): 0.5512 / 0.3933\n",
      "[11/20][36/95] Loss_D: 1.2117 Loss_G: 0.8142 D(x): 0.4915 D(G(z)): 0.3731 / 0.4539\n",
      "[11/20][37/95] Loss_D: 1.3685 Loss_G: 0.9412 D(x): 0.6341 D(G(z)): 0.5886 / 0.3969\n",
      "[11/20][38/95] Loss_D: 1.2401 Loss_G: 1.0242 D(x): 0.5325 D(G(z)): 0.4465 / 0.3649\n",
      "[11/20][39/95] Loss_D: 1.2489 Loss_G: 0.6874 D(x): 0.4478 D(G(z)): 0.3455 / 0.5104\n",
      "[11/20][40/95] Loss_D: 1.4983 Loss_G: 0.9951 D(x): 0.6300 D(G(z)): 0.6266 / 0.3769\n",
      "[11/20][41/95] Loss_D: 1.1417 Loss_G: 1.2008 D(x): 0.5464 D(G(z)): 0.4044 / 0.3100\n",
      "[11/20][42/95] Loss_D: 1.3739 Loss_G: 0.7361 D(x): 0.4573 D(G(z)): 0.4270 / 0.4905\n",
      "[11/20][43/95] Loss_D: 1.2890 Loss_G: 0.9499 D(x): 0.5666 D(G(z)): 0.4948 / 0.3910\n",
      "[11/20][44/95] Loss_D: 1.2964 Loss_G: 1.0636 D(x): 0.5502 D(G(z)): 0.4869 / 0.3521\n",
      "[11/20][45/95] Loss_D: 0.7565 Loss_G: 1.8006 D(x): 0.7613 D(G(z)): 0.3789 / 0.1748\n",
      "[11/20][46/95] Loss_D: 1.5798 Loss_G: 0.4457 D(x): 0.2663 D(G(z)): 0.1997 / 0.6473\n",
      "[11/20][47/95] Loss_D: 1.6655 Loss_G: 1.5027 D(x): 0.7686 D(G(z)): 0.7403 / 0.2368\n",
      "[11/20][48/95] Loss_D: 1.5406 Loss_G: 0.7830 D(x): 0.3172 D(G(z)): 0.2860 / 0.4673\n",
      "[11/20][49/95] Loss_D: 1.2323 Loss_G: 0.8811 D(x): 0.6095 D(G(z)): 0.5070 / 0.4233\n",
      "[11/20][50/95] Loss_D: 1.3021 Loss_G: 1.0098 D(x): 0.5399 D(G(z)): 0.4836 / 0.3704\n",
      "[11/20][51/95] Loss_D: 1.1567 Loss_G: 1.0605 D(x): 0.5407 D(G(z)): 0.4024 / 0.3564\n",
      "[11/20][52/95] Loss_D: 1.1992 Loss_G: 0.8596 D(x): 0.5190 D(G(z)): 0.4060 / 0.4320\n",
      "[11/20][53/95] Loss_D: 1.2332 Loss_G: 1.1578 D(x): 0.6254 D(G(z)): 0.5199 / 0.3255\n",
      "[11/20][54/95] Loss_D: 1.2549 Loss_G: 0.9578 D(x): 0.4733 D(G(z)): 0.3694 / 0.3946\n",
      "[11/20][55/95] Loss_D: 1.1944 Loss_G: 0.8511 D(x): 0.5504 D(G(z)): 0.4291 / 0.4354\n",
      "[11/20][56/95] Loss_D: 1.2440 Loss_G: 1.2285 D(x): 0.6111 D(G(z)): 0.5088 / 0.3102\n",
      "[11/20][57/95] Loss_D: 1.2063 Loss_G: 0.8948 D(x): 0.4870 D(G(z)): 0.3619 / 0.4178\n",
      "[11/20][58/95] Loss_D: 1.2464 Loss_G: 0.8967 D(x): 0.5614 D(G(z)): 0.4698 / 0.4157\n",
      "[11/20][59/95] Loss_D: 1.1763 Loss_G: 1.5861 D(x): 0.6624 D(G(z)): 0.5200 / 0.2143\n",
      "[11/20][60/95] Loss_D: 1.4241 Loss_G: 0.5730 D(x): 0.3677 D(G(z)): 0.2936 / 0.5759\n",
      "[11/20][61/95] Loss_D: 1.4112 Loss_G: 1.4188 D(x): 0.7196 D(G(z)): 0.6399 / 0.2529\n",
      "[11/20][62/95] Loss_D: 1.3134 Loss_G: 0.9247 D(x): 0.4234 D(G(z)): 0.3247 / 0.4043\n",
      "[11/20][63/95] Loss_D: 1.2994 Loss_G: 0.8731 D(x): 0.5717 D(G(z)): 0.5040 / 0.4267\n",
      "[11/20][64/95] Loss_D: 1.3427 Loss_G: 1.2436 D(x): 0.5507 D(G(z)): 0.5086 / 0.3009\n",
      "[11/20][65/95] Loss_D: 1.2985 Loss_G: 0.8662 D(x): 0.4802 D(G(z)): 0.4035 / 0.4347\n",
      "[11/20][66/95] Loss_D: 1.3206 Loss_G: 1.0581 D(x): 0.5764 D(G(z)): 0.5193 / 0.3570\n",
      "[11/20][67/95] Loss_D: 1.3880 Loss_G: 0.6739 D(x): 0.4472 D(G(z)): 0.4200 / 0.5254\n",
      "[11/20][68/95] Loss_D: 1.3576 Loss_G: 1.9358 D(x): 0.6978 D(G(z)): 0.6102 / 0.1619\n",
      "[11/20][69/95] Loss_D: 1.5143 Loss_G: 0.5505 D(x): 0.3278 D(G(z)): 0.2454 / 0.5850\n",
      "[11/20][70/95] Loss_D: 1.3165 Loss_G: 1.5082 D(x): 0.7523 D(G(z)): 0.6292 / 0.2377\n",
      "[11/20][71/95] Loss_D: 1.1752 Loss_G: 1.0604 D(x): 0.4780 D(G(z)): 0.3275 / 0.3584\n",
      "[11/20][72/95] Loss_D: 1.3076 Loss_G: 0.9202 D(x): 0.5568 D(G(z)): 0.4918 / 0.4079\n",
      "[11/20][73/95] Loss_D: 1.2096 Loss_G: 1.2422 D(x): 0.5950 D(G(z)): 0.4846 / 0.2999\n",
      "[11/20][74/95] Loss_D: 1.2791 Loss_G: 1.0488 D(x): 0.5124 D(G(z)): 0.4289 / 0.3601\n",
      "[11/20][75/95] Loss_D: 1.1174 Loss_G: 1.2701 D(x): 0.5921 D(G(z)): 0.4381 / 0.2903\n",
      "[11/20][76/95] Loss_D: 0.7499 Loss_G: 2.0680 D(x): 0.7605 D(G(z)): 0.3678 / 0.1366\n",
      "[11/20][77/95] Loss_D: 1.4669 Loss_G: 0.5295 D(x): 0.3068 D(G(z)): 0.1943 / 0.6044\n",
      "[11/20][78/95] Loss_D: 1.5019 Loss_G: 1.6621 D(x): 0.7914 D(G(z)): 0.6898 / 0.1980\n",
      "[11/20][79/95] Loss_D: 1.2732 Loss_G: 0.9250 D(x): 0.4136 D(G(z)): 0.2828 / 0.4111\n",
      "[11/20][80/95] Loss_D: 1.2854 Loss_G: 1.2384 D(x): 0.6570 D(G(z)): 0.5578 / 0.3000\n",
      "[11/20][81/95] Loss_D: 1.5910 Loss_G: 1.1756 D(x): 0.4777 D(G(z)): 0.5460 / 0.3238\n",
      "[11/20][82/95] Loss_D: 1.6719 Loss_G: 0.5065 D(x): 0.3138 D(G(z)): 0.3580 / 0.6300\n",
      "[11/20][83/95] Loss_D: 1.4718 Loss_G: 1.4292 D(x): 0.8367 D(G(z)): 0.7024 / 0.2699\n",
      "[11/20][84/95] Loss_D: 1.4776 Loss_G: 1.1367 D(x): 0.4520 D(G(z)): 0.4606 / 0.3359\n",
      "[11/20][85/95] Loss_D: 1.2206 Loss_G: 0.7680 D(x): 0.4679 D(G(z)): 0.3314 / 0.4878\n",
      "[11/20][86/95] Loss_D: 1.2505 Loss_G: 1.4680 D(x): 0.7442 D(G(z)): 0.5911 / 0.2630\n",
      "[11/20][87/95] Loss_D: 1.1933 Loss_G: 0.8541 D(x): 0.4565 D(G(z)): 0.2916 / 0.4435\n",
      "[11/20][88/95] Loss_D: 1.2622 Loss_G: 1.3045 D(x): 0.6625 D(G(z)): 0.5383 / 0.2866\n",
      "[11/20][89/95] Loss_D: 1.2986 Loss_G: 0.9468 D(x): 0.4785 D(G(z)): 0.4076 / 0.4024\n",
      "[11/20][90/95] Loss_D: 1.1269 Loss_G: 0.8162 D(x): 0.5423 D(G(z)): 0.3850 / 0.4505\n",
      "[11/20][91/95] Loss_D: 1.5826 Loss_G: 1.5519 D(x): 0.7120 D(G(z)): 0.6998 / 0.2242\n",
      "[11/20][92/95] Loss_D: 1.5704 Loss_G: 0.5631 D(x): 0.3067 D(G(z)): 0.2829 / 0.5798\n",
      "[11/20][93/95] Loss_D: 1.5942 Loss_G: 1.5600 D(x): 0.6964 D(G(z)): 0.6812 / 0.2175\n",
      "[11/20][94/95] Loss_D: 1.4337 Loss_G: 0.9268 D(x): 0.3477 D(G(z)): 0.2933 / 0.3991\n",
      "[12/20][0/95] Loss_D: 1.2567 Loss_G: 0.7628 D(x): 0.5573 D(G(z)): 0.4726 / 0.4746\n",
      "[12/20][1/95] Loss_D: 1.2883 Loss_G: 1.2103 D(x): 0.6077 D(G(z)): 0.5223 / 0.3085\n",
      "[12/20][2/95] Loss_D: 1.2500 Loss_G: 0.9296 D(x): 0.5014 D(G(z)): 0.4098 / 0.4040\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, niter, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu,\n",
    "                    '%s/real_samples.png' % outf,\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
    "                    normalize=True)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
